<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>Kubernetes map</title>
<!--
 Q:Note what the attribute { and } do:
 A:Those attributes are ignored by the browser but are helpful to fold/unfold text in some
   editors (Vim, Emacs,...)
-->
<!--
TABLE TEMPLATE
<table { >
<tr {>
  <th colspan=3 header_delimit {   >topic1</th>
</tr }>
<tr {>
  <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
</tr }>
<tr {>
  <td col1 colspan=6 >
    <ul>
      <li>
      </li>
    </ul>
  </td>  
  <td col2 colspan=6 >
  </td>  
</tr }>
</table } >
-->

<head>
<script>
var zoomDivDOM
function onZoomDivDoubleClick() { zoomDivDOM.innerHTML = ''; }
var zoomDivFW = true; // FW Full Width
var zoomDivFH = true; // FW Full Height 
var zoomDivTop = true; 
var zoomDivLft = true; 
function onTDDoubleClick(e)      { zoomDivDOM.innerHTML = 
     "('Esc' to close) <br/>" + this.outerHTML; 
   e.stopPropagation();
}

function removeToLeftMarginInPre() {
  // TODO:(0) Not working
  // nodeList = document.querySelectorAll('pre')
  // for (idx in nodeList) { 
  //   var node = nodeList[idx]
  //   var html = node.innerHTML
  //   var pattern = html.match(/^\s*[|]/)
  //   var regEx = new RegExp(pattern, "")
  //   console.log(html)
  //   node.innerHTML = html.replace(regEx,''))
  //    
  // }
}


function onPageLoaded() {
  zoomDivDOM = document.getElementById('zoomDiv')
  document.addEventListener('keyup',function(e) { if (e.code !== "Escape") return; onZoomDivDoubleClick(); })
  // Change default a.target to blank. Ussually this is bad practice 
  // but this is the exception to the rule
  var nodeList = document.querySelectorAll('a')
  for (idx in nodeList) { 
      if (!nodeList[idx].href) { continue; }
      if (nodeList[idx].href && !nodeList[idx].href.startsWith("http")) continue;
      nodeList[idx].target='_blank'; 
  }
  nodeList = document.querySelectorAll('td')
  for (idx in nodeList) { 
     if (!!! nodeList[idx].addEventListener) continue;
     nodeList[idx].addEventListener('dblclick',onTDDoubleClick, false)
  }
  nodeList = document.querySelectorAll('*[zoom]')
  for (idx in nodeList) { 
     if (!!! nodeList[idx].addEventListener) continue;
     nodeList[idx].addEventListener('dblclick',onTDDoubleClick, false)
  }

  setTimeout(onZoomDivDoubleClick, 3000);
  removeToLeftMarginInPre();
}
</script>
<style { >
b { color: #0A9}
*[mono]         { font-family: monospace; white-space: pre; }
pre { background-color:#EEEEEE; outline:1px dotted grey; margin: 0; }
*[cite]         { font-style: italic; }
*[TODO]         { color:red; font-weight: bold; }
*[TODO]:before  { content: "TODO:"; }
*[xxxsmall]{ font-size:0.1rem; }
img[xxxsmall]{ max-width:10rem; }
*[xxsmall] { font-size:0.3rem; }
*[xsmall]  { font-size:0.7rem; }
*[small]   { font-size:0.9rem; }
*[xxbig]  { font-size:1.7em; font-weight: bold; color:#007733;}
*[xbig]  { font-size:1.5em; }
*[hidden]  { display:none; }
ul,ol { margin-left: 1.0em; padding-left: 0rem; }
#zoomDiv [xxxsmall] , #zoomDiv * [xxxsmall], #zoomDiv * * [xxxsmall], #zoomDiv * * * [xxxsmall]{ font-size:1em; } 
#zoomDiv img[xxxsmall] , #zoomDiv * img[xxxsmall], #zoomDiv * * img[xxxsmall], #zoomDiv * * * img[xxxsmall]{ max-width:100%; } 

/* REF: https://stackoverflow.com/questions/4910077/select-all-child-elements-recursively-in-css */
#zoomDiv * [small], #zoomDiv * [xsmall], #zoomDiv * [xxsmall] { font-size:1em; }
#zoomDiv *[small], #zoomDiv *[xsmall], #zoomDiv *[xxsmall] { font-size:1em; }
#zoomDiv * td { font-size:1em; }

body      { font-family:sans-serif; font-size:16px; padding: 0; margin: 0; }
#zoomDiv  { 
   position:fixed; top:0.1%; left:0.1%; width:auto; height:auto;
   max-height: 98%; max-width: 98%; overflow: auto;
   background-color:#FFFFFF; color:#000; border-radius: 0.5rem; border: 4px solid black; font-size: 2rem;
   box-shadow: 5px 5px 30px black;
   padding: 0.5rem;
}

a            { text-decoration:none; font-family:monospace; padding:0.0;}
a[href^="#"]:before /* mark internal anchor */ {  content: ">"; }
a[href^="#"]:after  /* mark internal anchor */ {  content: "<"; }
a:visited { color:blue; }
td { 
   font-size: 0.8rem;
   vertical-align: top;
   outline: 1px solid grey; 
}
td,th               {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col0] ,th[col1]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col2] ,th[col2]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col3] ,th[col3]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col4] ,th[col4]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col5] ,th[col5]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col6] ,th[col6]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col7] ,th[col7]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col8] ,th[col8]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col9] ,th[col9]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col10],th[col10] {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col11],th[col11] {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col12],th[col12] {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
tr[header_delimit] > *{background-color:#000000; color:#FFFFFF; font-size:2em; color: white; }
tr[header_delimit] > td > a{color:inherit; text-decoration: underline; }
div[subtable1] { max-width: 95%; overflow: auto; padding:0; margin: 0;}

table { width:100% border:0; margin: 0;}
</style }>
</head>
<body onLoad='onPageLoaded()'>
<div id='zoomDiv'>Hint: double-click on cell to zoom!!</div>
<br/>
<table { >
<tr {>
  <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
</tr }>
<tr {>
  <td col1 colspan=3 >
     <ul>
       <li>Kubernetes orchestates pools of CPUs, storage and networks</li>
       <li>The <b>Kubernet Master</b> is responsible for managing the cluster, coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates</li>
       <li>A <b>node</b> is a (VM) computer serving as a worker machine. Each node has a Kubelet agent plus tools like Docker or rkt.</li>
       <li>A cluster handling <b>production traffic</b> should have a <b>minimum of three nodes</b>(3,5,..."odd" number) since <a href="https://raft.github.io/">Raft("voting")</a> consensus is used.</li>
     </ul>
     See also: <a href="https://www.youtube.com/watch?v=PH-2FfFD2PU">Desired State management"</a>
  </td>  
  <td col3 colspan=8 >
       <span xxbig>kubectl &lt;action&gt; &lt;resource&gt;</span>
<pre xsmall zoom {>
<a href='https://github.com/kubernetes/kubernetes/tree/master/docs/user-guide/kubectl'>kubectl manual</a> command line interface to Kubernetes API
 <b>get     </b>: list resources
 <b>describe</b>: show detailed info for resource
 <b>logs    </b>: print container logs 
 <b>exec    </b>: exec command on container



    clusters            │podtemplates               │statefulsets
(cs)componentstatuses   │(rs)replicasets            │(pvc)persistentvolumeclaims
(cm)configmaps          │(rc)replicationcontrollers │(pv) persistentvolumes
(ds)daemonsets          │(quota)resourcequotas      │(po) pods
(deploy)deployments     │cronjob                    │(psp)podsecuritypolicies
(ep)endpoints           │jobs                       │secrets
(ev)event               │(limits)limitranges        │(sa)serviceaccount
(hpa)horizon...oscalers │(ns)namespaces             │(svc)services
(ing)ingresses          │networkpolicies            │storageclasses
                        │(no)nodes                  │thirdpartyresources
</pre } >
  </td>
  <td col3 colspan=1 >
    <span xbig>Pod</span>
<pre xxxsmall zoom {>
apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: gcr.io/google_containers/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache    &lt;-- where to mount
      name: cache-volume   &lt;-- volume (name) to mount
    - mountPath: /test-pd
      name: test-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
  - name: test-volume
    hostPath:
      # directory location on host
      path: /data
      # this field is optional
      type: Directory
</pre } >


    <span xbig>Deployment</span>
<pre xxxsmall zoom {>
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  # Change the name
  name: ws-coordinates-be
  # Set it to the production environment
  namespace: nightswatch-pro
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        # Change the name
        app: ws-coordinates-be
    spec:
      containers:
      # Change the name
      - name: ws-coordinates-be
        # Change the URL of the docker image
        image: registry.nw.kube.everis.com/nightswatch/ws-coordinates-be
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            # Change to Application Path (see note below)
            path: /graphreader/healthz
            port: 8080
            scheme: HTTP                           :
          initialDelaySeconds: 30
        env:

        - name: MONGO_HOST
          value: mongodb
        - name: MONGO_PORT
          value: "27017"
        - name: MONGO_DATABASE
          value: nightswatch
      imagePullSecrets:
      - name: nwregistrykey
</pre }>

    <span xbig>ReplicationController</span>
<pre xxxsmall zoom {>
apiVersion: v1
kind: ReplicationController
metadata:
  # Change name
  name: ws-coordinates-be
  # Set to dev namespace
  namespace: nightswatch-dev
spec:
  replicas: 1
  selector:
    # Change selectior
    app: ws-coordinates-be
  template:
    metadata:
      labels:
        # Change label
        app: tcp-graph-reader
    spec:
      containers:
        # Change container name
      - name: tcp-graph-reader
        # Change docker registry path
        image: nwregistry-on.azurecr.io/nightswatch/ws-coordinates-be
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            # Change to Application Path
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 30
         env:
        - name: MONGO_HOST
          value: mongodb
                               - name: MONGO_PORT
          value: "27017"
        - name: MONGO_DATABASE
          value: nightswatch
      imagePullSecrets:
      - name: registrykey
</pre }>

    <span xbig>Service</span>
<pre xxxsmall zoom { >
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  selector:     &gt;--  will be evaluated continuously and Endpoints notified
    app: MyApp
  ports:
  type: ClusterIP   &gt;-- ClusterIP, NodePort, LoadBalancer, ExternalName
  externalIPs:
  - 80.11.12.10
  externalIPs:
  - 80.11.12.10
  - name: http-port
    protocol: TCP      &gt;-- Incomming port
    port: 80           &gt;-- Target    port
    targetPort: 9376
  - name: https-port
    protocol: TCP
    port: 443
    targetPort: 9377
</pre } >

    <span xbig>PersistentVolume</span><br/>
(using local volume):
<pre xxxsmall zoom { >
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-pv
  annotations:
    "volume.alpha.kubernetes.io/node-affinity": '{
      "requiredDuringSchedulingIgnoredDuringExecution": {
        "nodeSelectorTerms": [
          { "matchExpressions": [
            { "key": "kubernetes.io/hostname",
              "operator": "In",
              "values": ["example-node"]
            }
          ]}
         ]}
        }'
spec:
  capacity:
    storage: 100Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /mnt/disks/ssd1
</pre } >

  </td>
  <td col3 colspan=2 >
  </td>
</tr }>
</table } >

<table { >
<tr {>
  <th colspan=12 header_delimit {   ><a href='https://kubernetes.io/docs/concepts/'>Building Blocks</a></th>
</tr }>
<tr {>
  <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
</tr }>
<tr {>
  <td col4 colspan=3 >
    <span xxbig><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">Namespace</span>
     <ul xxxsmall>
       <li TODO><a href='https://kubernetes.io/docs/tasks/administer-cluster/namespaces/'>
         Admin Guide for Namespaces</a>
       </li>
       <li>Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces</li>
       <li>Provie a scope for names</li>
       <li>Namespaces are intended for use in environments with many users spread across multiple teams, or projects. For clusters with a few to tens of users, you should not need to create or think about namespaces at all. Start using namespaces when you need the features they provide.</li>
       <li>use labels, not namespaces, to distinguish resources within the same namespace</li>
       <li>Services are created with DNS entry
           "service-name"."namespace".svc.cluster.local</li>
     </ul>
  <hr/>
     <ul xxxsmall>
       <li> Initial namespaces:
         <pre xxxsmall { >
$ kubectl get namespaces
NAME          STATUS    AGE
default       Active    1d 
kube-system   Active    1d 
       </li>
       <li>create namespace:
         <pre { >
$ kubectl create namespace my-namespace
         </pre>
       </li>
       <li>temporarily set the NS for a request:
         <pre { >
$ kubectl --namespace=my-namespace \
    run nginx --image=nginx
         </pre } >
       </li>
       <li>permanently save the NS:
         <pre { >
$ kubectl config set-context \
    $(kubectl config current-context) \
    --namespace=MyFavouriteNS
$ kubectl config view | \
    grep namespace: # Validate
         </pre } >
       </li>
         </pre } >
     </ul>
  </td>
  <td col1 colspan=3 >
            
    <span xxbig><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pods</a></span> 
     <ul xxxsmall>
       <li>Kubernetes abstraction that represents a group of one or more application containers (such as Docker or rkt), and some shared resources for those containers. Those resources include:
         <ul>
           <li>Shared storage, as Volumes</li>
           <li>Networking, as a unique cluster IP address</li>
           <li>Information about how to run each container, such as the container image version or specific ports to use</li>
         </ul>
       </li>
       <li>A Pod models an application-specific "logical host" and can contain different application containers which are relatively tightly coupled. For example, a Pod might include both the container with your Node.js app as well as a different container that feeds the data to be published by the Node.js webserver. The containers in a Pod share an IP Address and port space, are always co-located and co-scheduled, and run in a shared context on the same Node.</li>
       <li>Pods are the atomic unit on the Kubernetes platform. When we create a Deployment on Kubernetes, that Deployment creates Pods with containers inside them (as opposed to creating containers directly). Each Pod is tied to the Node where it is scheduled, and remains there until termination (according to restart policy) or deletion. In case of a Node failure, identical Pods are scheduled on other available Nodes in the cluster.</li>
       <li>The containers in a Pod are automatically co-located and co-scheduled on the same physical or virtual machine in the cluster. The containers can share resources and dependencies, communicate with one another, and coordinate when and how they are terminated.</li>
       <li>Note that grouping multiple co-located and co-managed containers in a single Pod is a relatively advanced use case. You should use this pattern only in specific instances in which your containers are tightly coupled. The one container per pod is the recomended use-case.</li>

       <li>Pods do not, by themselves, self-heal. Thus, while it is possible to use Pod directly, 
           it’s far more common in Kubernetes to manage your pods using a Controller to 
           implement Pod scaling and healing.
       </li>

     </ul>
  </td>
  </td>  
  <td col2 colspan=3 >
  <span xxbig><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a></span> 
     <ul xxxsmall>
       <li>abstraction defining a logical set of Pods and a policy by which to access them.<br/></li>
       <li>The set of Pods targeted by a Service is (usually) determined by a Label Selector</li>
       <li>Kubernetes-native applications: Kubernetes offers a simple Endpoints API
           non-native        applications: Kubernetes offers virtual-IP-based-2-Service bridge</li>
       <li>For some parts of your application (e.g. frontends) you may want to expose a
           Service onto an external (outside of your cluster) IP address.<br/>
           ServiceTypes allow you to specify what kind of service you want.
           <ul>
             <li>ClusterIP: (default) Exposes the service on a cluster-internal IP.<br/>
                 Service only reachable from within the cluster.</li>
             <li>NodePort: Exposes service on each Node’s IP @ static NodePort.<br/>
                 Externably visible by requesting &lt;NodeIP&gt;:&lt;NodePort&gt;
             </li>
             <li>LoadBalancer: Exposes service externally using a cloud provider load balancer.
                 Externably visible by requesting &lt;ClusterIP&gt;:&lt;NodePort&gt;
             </li>
             <li>ExternalName: Maps the service to the contents of the "externalName" field
                 (e.g. foo.bar.example.com), by returning a CNAME record.
                 requires version 1.7 or higher of kube-dns
             </li>
           </ul>
       <li><p>externalIPs:  Traffic that ingresses into the cluster with the external IP (as destination IP),
              on the service port, will be routed to one of the service endpoints. 
              externalIPs can be specified along with any of the ServiceTypes. 
           </p>
       </li>
     </ul>

     <ul xxxsmall>
       <li>As of Kubernetes v1.0, Services are a “layer 4” (TCP/UDP over IP) construct.
          In Kubernetes v1.1 the Ingress API was added (beta) to represent “layer 7” (HTTP) services.</li>
       <li>By default, the choice of backend is round robin. Client-IP based session affinity can be selected
           by setting service.spec.sessionAffinity to "ClientIP" (the default is "None"), and you can set
           the max session sticky time by setting the field service.spec.sessionAffinityConfig.clientIP.timeoutSeconds
           if you have already set service.spec.sessionAffinity to "ClientIP" (the default is “10800”). </li>
       <li>ou can specify your own cluster IP address as part of a Service creation request. To do this, set the spec.clusterIP field </li>
       <li>When a Pod is run on a Node, the kubelet adds a set of environment variables for each active Service.<br/>
           example, Service "redis-master" exposing TCP:6379 allocated to cluster IP address 10.0.0.11:
         <pre xxxsmall { >
REDIS_MASTER_SERVICE_HOST=10.0.0.11
REDIS_MASTER_SERVICE_PORT=6379
REDIS_MASTER_PORT=tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP_PROTO=tcp
REDIS_MASTER_PORT_6379_TCP_PORT=6379
REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11
         </pre } >
       </li>
       <li>DNS server: optional (strongly recommended) add-on.
         The DNS server watches the Kubernetes API for new Services and creates a set of DNS records for each.
         For example, if you have a Service called "my-service" in Kubernetes Namespace "my-ns" a DNS record 
         "my-service.my-ns" is created. 
       </li>
       <li>Sometimes you don’t need or want load-balancing and a single service IP.
           In this case, you can create "headless" services by specifying "None" in spec.clusterIP
       </li>
       <li>This does imply an ordering requirement - any Service that a Pod wants to access
            must be created before the Pod itself, or else the environment variables will not be populated.
            DNS does not have this restriction.
DNS
</li>
     </ul>


  </td>  
  <td col3 colspan=3 >
  <span xxbig><a href="https://kubernetes.io/docs/concepts/storage/volumes/">Volume</a></span> 
     <ul xxxsmall>
       <li>A Kubernetes volume (vs a Docker volume)  has the lifetime of the pod. Consequently, a volume outlives any containers that run within the Pod, and data is preserved across Container restarts. </li>
       <li>Kubernetes supports many types of volumes, and a Pod can use any number of them simultaneously.</li>
       <li>a pod specifies what volumes to provide for the pod (spec.volumes) and where to mount those into containers(spec.containers.volumeMounts).</li>
       <li>Each container in the Pod must independently specify where to mount each volume</li>
       <li>Kubernetes supports several types of Volumes:</p>
        <ul xxxsmall { >
          <li>emptyDir</li>
          <li>hostPath: mounts from hots node's filesystem. Types
              Permissions: Those of the kubelet user
              <ul { >
                <li>DirectoryOrCreate: </li>
                <li>Directory:</li>
                <li>FileOrCreate:</li>
                <li>File:</li>
                <li>Socket:</li>
                <li>CharDevice:</li>
                <li>BlockDevice:</li>
              </ul } >
          </li>
          <li>local: represents a mounted local storage device such as a disk, partition or directory. <br/> 
              Local volumes can only be used as a statically created PersistentVolume.<br/>
              Compared to HostPath volumes, local volumes can be used in a durable manner without manually scheduling pods to nodes, as the system is aware of the volume’s node constraints.
          </li>
          <li>awsElasticBlockStore
          <pre xxxsmall {>
  # STEP 1:
  aws ec2 create-volume \
     --availability-zone=eu-west-1a \
     --size=10 --volume-type=gp2

  # STEP 2:
  kind: Pod
    ...
    volumes:
    - name: test-volume
    # This AWS EBS volume must already exist.
    awsElasticBlockStore:
      volumeID: <volume-id>
      fsType: ext4
          </pre }>

          </li>
          <li>nfs</li>
          <li>iscsi</li>
          <li>glusterfs</li>
          <li>gitRepo</li>

          <li TODO >persistenVolumeClaim</br>
              https://kubernetes.io/docs/concepts/storage/persistent-volumes/
          </li>
          <li>...</li>
        </ul }>
       </li>
       <li>Sometimes, it is useful to share one volume for 
           multiple uses in a single pod. The volumeMounts.subPath
           property can be used to specify a sub-path inside the
           referenced volume instead of its root.
       </li>
     </ul>

  </td>

</tr }>
</table } >

<table { >
<tr {>
  <th colspan=12 header_delimit {   >Controllers (higher-level abstractions build upon building blocks)</th>
</tr }>
<tr {>
  <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
</tr }>
<tr {>
  <td col1 colspan=2 >
    <span xxbig><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a></span>
     <ul xxxsmall>
       <li> If you want to scale your application horizontally (e.g., run multiple instances), you should use multiple Pods, one for each instance.</li>
       <li>In Kubernetes, this is generally referred to as replication. Replicated Pods are usually created and managed as a group by an abstraction called a Controller.</li>
       <li>A ReplicaSet ensures that a specified number of pod replicas are running at any given time. However, a Deployment is a higher-level concept that manages ReplicaSets and provides declarative updates to pods along with a lot of other useful features. Therefore, we recommend using Deployments instead of directly using ReplicaSets, unless you require custom update orchestration or don’t require updates at all.</li>
     </ul>
  </td>  
  <td col2 colspan=2 >
    <span xxbig ><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment</a></span>
    <ul xxxsmall>
      <li>A Deployment controller provides declarative updates for Pods and ReplicaSets.</li>
      <li>Ex. Deployment:
<pre xxxsmall zoomm {>
# for versions before 1.7.0 use apps/v1beta1
apiVersion: apps/v1beta2 
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3                  &lt;-- 3 replicated Pods
  strategy: 
   - type : Recreate           &lt;-- Recreate | RollingUpdate*
  selector:
    matchLabels:
      app: nginx
  template:                    &lt;-- pod template
    metadata:
      labels:
        app: nginx
    spec:                      &lt;-- template pod spec
      containers:                change triggers new rollout
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80

$ kubectl create -f nginx-deployment.yaml

$ kubectl get deployments
NAME             DESIRED CURRENT  ...
nginx-deployment 3       0       

$ kubectl rollout status deployment/nginx-deployment
  Waiting for rollout to finish: 2 out of 3 new replicas
  have been updated...
  deployment "nginx-deployment" successfully rolled out

$ kubectl get deployments
NAME             DESIRED CURRENT ...
nginx-deployment 3       3       
</pre }>
      </li>
      <li>To see the ReplicaSet (rs) created by the deployment:
<pre { >
$ kubectl get rs
NAME                     DESIRED ...
nginx-deployment-...4211 3       
^*1
</pre }>
*1:format [deployment-name]-[pod-template-hash-value]
      </li>
      <li>To see the labels automatically generated for each pod
<pre {>
$ kubectl get pods --show-labels
NAME          ... LABELS
nginx-..7ci7o ... app=nginx,...,
nginx-..kzszj ... app=nginx,...,
nginx-..qqcnn ... app=nginx,...,
</pre }>
      </li>
      <li>Update nginx Pods from nginx:1.7.9 to nginx:1.9.1:
<pre {>
$ kubectl set image deployment/nginx-deployment \
   nginx=nginx:1.9.1
</pre }>
      </li>
      <li>Check the revisions of deployment:
<pre {>
$ kubectl rollout history deployment/nginx-deployment
deployments "nginx-deployment"
R CHANGE-CAUSE
1 kubectl create -f nginx-deployment.yaml ---record
2 kubectl set image deployment/nginx-deployment \
                    nginx=nginx:1.9.1
3 kubectl set image deployment/nginx-deployment \
                    nginx=nginx:1.91 

$ kubectl rollout undo deployment/nginx-deployment \
   --to-revision=2
</pre }>
      </li>
      <li>Scale Deployment:
<pre {>
$ kubectl scale deployment \
  nginx-deployment --replicas=10

$ kubectl autoscale deployment nginx-deployment \
  --min=10 --max=15 --cpu-percent=80
</pre }>
      </li>
     </ul>
  </td>
  <td col3 colspan=2 >
  <span xxbig><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a><br/>
  <span TODO></span>
  </td>
  <td col4 colspan=2 >
  <span xxbig><a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a><br/>
  <span TODO></span>
  </td>
  <td colspan=2>
    <span xxbig><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">Job</span><br/>
  <span TODO></span>
  </td>
  <td colspan=2>
  <span xxbig><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors/">Working with objects</a></span><br/>
  <span TODO></span>
  </td>
</tr }>
</table } >


<table { >
<tr {>
  <th colspan=12 header_delimit {   >Non-ordered notes</th>
</tr }>
<tr {>
  <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
</tr }>
<tr {>
  <td col1 colspan=6 >
    <pre xsmall { >
Kubectl Autocomplete

$ source <(kubectl completion bash)
$ source <(kubectl completion zsh)
# use multiple kubeconfig files 
$ KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 \ 
kubectl config view # Show Merged kubeconfig settings.

$ kubectl config current-context
$ kubectl config use-context my-cluster-name 

$ kubectl run nginx --image=nginx
$ kubectl explain pods,svc

    <pre } >
    <hr/>

    <pre xxxsmall { >
INTERACTING WITH RUNNING PODS:
$ kubectl logs my-pod (-c my-container) (-f)
                                         ^"tail -f"
$ kubectl run -i --tty busybox --image=busybox -- sh
$ kubectl attach my-pod -i
$ kubectl port-forward my-pod 5000:6000  # Forward port 6000 of Pod -> 5000 local machine
$ kubectl exec my-pod (-c my-container) -- ls / # Run command in existing pod 
$ kubectl top pod POD_NAME --containers

    <pre } >

    <pre xxxsmall { >
# GET COMMANDS WITH BASIC OUTPUT
$ kubectl (get   | describe) (services|pods|deployment)
           ^basic  ^verbose
    --all-namespaces
    -o wide   
    --include-uninitialized
    --sort-by=.metadata.name
    --sort-by='.status.containerStatuses[0].restartCount'
    --selector=app=cassandra  # filter

EDITING RESOURCES
$ KUBE_EDITOR="nano" kubectl edit svc/my-service-1
    <pre } >

    <pre xxxsmall { >
# Get ExternalIPs of all nodes
$ kubectl get nodes -o jsonpath=\
    '{.items[*].status.addresses[?(@.type=="ExternalIP")].address}'
    <pre } >

  </td>  
  <td col2 colspan=6 >
   <span TODO xxbig><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors">label selectors</a></span> 
   <hr/>
   <span TODO xxbig><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a></span>
     A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.
     
     A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., can be mounted once read/write or many times read-only).

 PV contains max size, PVC contains min size. PVC size must be < PV size
   <hr/>
  </td>  
</tr }>
</table } >

</body>
<!--


https://kubernetes.io/docs/tutorials/object-management-kubectl/object-management/
___________________________________
https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/
___________________________________
TODO:(1) Kubernetes + Photon Platform? 
_________________________________
GPU and Kubernetes
https://www.infoq.com/news/2018/01/gpu-workflows-kubernetes  
_________________________________
Running storage services on Kubernetes (GlusterFS, iSCSI, ....)
https://opensource.com/article/17/12/storage-services-kubernetes?elqTrackId=6b7560db7aa24ea28978ac2a7e110c4c&elq=b9bc524fe6af48e38828609c30c593bc&elqaid=45485&elqat=1&elqCampaignId=148699
______________________
https://github.com/kubernetes/kops/blob/master/README.md

KOPS - KUBERNETES OPERATIONS  """The easiest way to get a production grade Kubernetes cluster up and running."""
What is kops?  """We like to think of it as kubectl for clusters."""

kops helps you create, destroy, upgrade and maintain production-grade, highly available, Kubernetes clusters from the command line. 
AWS (Amazon Web Services) is currently officially supported, with GCE in beta support,
and VMware vSphere in alpha, and other platforms planned.
_________________
Ericsson HEML https://HELM.sh: Package manager for Kubernetes

https://kubeapps.com/:  The Easiest Way to Deploy Applications in Your Kubernetes Cluster 
__________________
SIG-Apps. https://github.com/kubernetes/community/blob/master/sig-apps/README.md

SIG-Apps is a Special Interest Group for deploying and operating apps in Kubernetes. They meet each week to demo and discuss tools and projects.
""" Covers deploying and operating applications in Kubernetes. We focus on the developer and devops experience of running applications in Kubernetes. We discuss how to define and run apps in Kubernetes, demo relevant tools and projects, and discuss areas of friction that can lead to suggesting improvements or feature requests."""

_______________
https://www.digitalocean.com/community/tutorials/an-introduction-to-kubernetes

Kubernetes Cluster: 

  - Etcd : distributed key-value store (can be distributed across multiple nodes).

  - API Server: main management point of the entire cluster
     + allows users to configure many of Kubernetes' workloads and organizational units. 
     + implements a RESTful interface (kubecfg)

  - Controller Manager Service: 
     + general service with responsibilities handling a 
       a number of controllers that regulate the state 
       of the cluster and perform routine tasks 
       (ensures number of replicas for a service, ...)

  - Scheduler Service
k    + Assigns workloads to nodes: 
     + It is responsible for tracking resource utilization on each host.
     + It must know the total resources available on each server
       as well as the resources allocated to existing workloads 
       assigned on each server. 

  - Nodes

______________
Kube-proxy: 

When a change is seen, the controller reads the new information and implements the procedure that fulfills the desired state. This can involve scaling an application up or down, adjusting endpoints, etc.
______________
Services offered by kubernetes orchestation :

    Load balancing a set of containers with or without session affinity

    Mounting persistent storage inside of the containers

    Placement and scheduling of containers on the infrastructure

    Rolling deployments and other operational considerations that traditional developers are not experts on

________________

REF:   https://www.infoq.com/news/2018/03/skaffold-kubernetes
  Google Releases “Skaffold”, a Tool That Facilitates Continuous Development with Kubernetes:

https://www.infoq.com/news/2018/03/skaffold-kubernetes?utm_source=infoqEmail&utm_medium=SpecialNL_EditorialContent&utm_campaign=04052018_SpecialNL&forceSponsorshipId=1598
_________________
6 Tips for Running Scalable Workloads on Kubernetes:
    https://www.infoq.com/articles/tips-running-scalable-workloads-kubernetes
_________________
K&A with Kubernetes ...
https://www.infoq.com/news/2018/02/dist-system-patterns-burns?utm_source=infoqEmail&utm_medium=SpecialNL_EditorialContent&utm_campaign=04052018_SpecialNL&forceSponsorshipId=1598gtgt
Distributed Systems programming is not for the faint of heart, and despite the evolution of platforms and tools from COM, CORBA, RMI, Java EE, Web Services, Services Oriented Architecture (SOA) and so on, it's more of an art than a science.

Brendan Burns outlined many of the patterns that enables distributed systems programming in the blog he wrote in 2015. He and David Oppenheimer, both original contributors for Kubernetes, presented a paper at Usenix based around design patterns and containers shortly after.

InfoQ caught up with Burns, who recently authored an ebook titled Designing Distributed Systems, Patterns and Paradigms for Scaleable Microservices. He talks about distributed systems patterns and how containers enable it.
________________

https://www.infoq.com/news/2018/02/kubecon-kafka-clusters-kubernete?utm_source=infoqEmail&utm_medium=SpecialNL_EditorialContent&utm_campaign=04052018_SpecialNL&forceSponsorshipId=1598

They use Kafka for log and events collection as well as a streaming platform. Each broker in the Kafka cluster has an identity which can be used to find other brokers in the cluster. The brokers also need some type of a database to store partition logs. It's important to configure a Persistent Volume (PV) for Kafka, otherwise you will lose the logs.

______________


-->
</html>
