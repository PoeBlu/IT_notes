<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>Linux Administration Map (v1.0)</title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>

<body>
<span xsmall>
<a href="https://linux.die.net/man/">[Man Pages]</a>,
<a href="https://linux.die.net/Linux-CLI/">[Command-line Tools  Summary]</a>,
<a href="https://en.wikipedia.org/wiki/Linux_Standard_Base">[Linux Standard Base]</a>,
(<a href="https://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/index.html">Full FS Hierarchy</a>)</li>

</span>
<hr xxxsmall/>
<table style='width:100%'>
<tbody>
<tr>
<td colsep>Basics</td>
<td>
  <span>Linux Basics</span>
<pre xxxsmall zoom>
- Linux itself is just an OS kernel in charge of sharing the (limited) hardware
  resources amongst potentially many running tasks and users working simultaneously
  on the systems. More preciselly, the main tasks in charge of kernel control are:

  - Orchestate(schedule) how much time each running-task is allowed to
    run on each CPU before such task is put on stand-by to let
    another task proffit from such CPU. 

  - Assign which process has access to the (limited)
    RAM memory on the system and move data on RAM used by stand-by processes
    to secondory storage (disks) in case of RAM space shortage. 

  - Provide support for users and permissions, so that different users will
    be able to isolate and protect its data from other users.

  Kernel control is transparent to running tasks or processes, so user-space task
  will run with the perception that they run alone in its own CPU and with
  all available memory for themself. When the kernel puts them on-hold 
  such tasks will be freezed and once restarted it will NOT notice any 
  change to the state before being put on-hold. Only the kernel is aware of
  the complex trickeries needed to make tasks run in parallel and isolated
  from each other. 

  Other important tasks offered by the kernel are:
  
 - Abstract the running hardware into standarized interfaces, so 
   user application will not need to work differently with different hardware.
   For example an application will ask the kernel to write data to the disk and
   the kernel will take care of the internal difference between the miriads
   of diferent disk hardware technologies.

 - Provide an easy-to-use file-system to work with data on disk, so that apps
   can orginized data in terms of files and directories, instead of just
   bunch-of-bytes on the hard-disk.

 - Provide network communication and support for standard network protocols
   like TCP/UP, bluetooth, WiFI, ... so that each app does not need to reimplement
   them.

 - Provide mechanisms to allow two running tasks to communicate with each other
   at will.
  
<b>Kernel mode vs User mode</b>
- When the CPU is executing kernel code it's running with elevated privileges.
  The software has full control of the hardware and can do "anything" on 
  the system and access all RAM, disk, network resources at will.

- Standard applications will run in user-mode and will have limited access
  to only the RAM memory assigned by the kernel. They will not be able to
  inspect the memory of other processes running on the system. In fact they
  are not aware of such memory due to the many trickeries done by the kernel
  to isolate each task.

<b>Files, files and more files</b>
- Any running process needs some incomming data to work with and
  produced new data that must be stored somewhere.
   This data can be provided by some storage system (hard-disk,
  usb, tape, ...), arrive (continuosly) from the network,
  or be generated by another concurrent process.
   Linux (UNIX actually) treats all input data sources and
  output data sinks as <b>"file devices"</b>.
  Internally there can be many differences (block devices with
  random access vs char devices with just sequential access), but
  running processes mostly always use the file methaphor to access
  all of them.
   Any running process will have 3 devices available "for free":
  - STDIN : The standard input  file.
  - STDOUT: The standard output file
  - STDERR: The standard error  file 
   The standard shell provides many utilities to juggle with those
  three standard files. In particular it allows to easely forward
  the STDOUT output from a running-process to the STDIN input of
  another running process using the "|" pipe syntax:
  $ command1 <b>|</b>command2  # ← Send STDOUT output from command1 to
                                        STDIN   input   of command2     

  STDOUT and STDERR by default are assigned to the running-process
  associated terminal (the console where the user has been logged).
  The shell allows also to redirect STDOUT/STDERR to any other
  file in our file system. Ex:
  $ command1 1>output.log         2>error.log
             ^^^^^^^^^^^^         ^^^^^^^^^^^ 
             redirects STDOUT(1)  redirects STDERR
             to output.log        to error.log

  $ command1 1>output.log         2>&1
             ^^^^^^^^^^^^         ^^^^
             redirects STDOUT(1)  redirects STDERR
             to output.log        to STDOUT (&1, aka output.log)
</pre>

  <span>Process model</span>
<pre xxxsmall zoom>
- Linux follows a parent-child process model.

- Once loaded and initialized during the boot process,
  the kernel will launch an initial user-space process in 
  charge of reading system configuration and (re)start 
  all other user-space processes that builds a running system.

- Normally this initial process is systemd in modern 
  systems (or initd in older or embedded ones).

- Each process can optionally launch new children processes
  up to the resource limits established on the running system.

- By default a child-process inherits the same user (and so, permissions)
  than its parent process. Some processes like the remote
  login "sshd" service (ssh is an acronymn for secure-shell) will
  change the child-process user/permission to a less privileged
  account.

- A simplified process-tree of a running-system will look like:
 
    PROCESS                                       USER    PROCESS   PARENT-ID
                                                         UNIQUE-ID  
    systemd·······································root       1         0
          └─crond·································root      23         1
          |-cupsd·································root      70         1<span orange>
          |-rtkit-daemon··························rtkit    100         1</span>
          |-sshd··································root      10         1<span green>
          |    └─sshd·····························mike     300        10
          |         └─bash························mike     301       300
          |              └─firefox················mike     302       301</span><span brown>
          |-systemd·······························alice    705         1
          |       └─at-spi-bus-laun···············alice    706       705
          |       |···············└─dbus-daemon···alice    707       706
          |       |-gnome-terminal················alice    883       705
          |                       ─bash-+·········alice    884       883
          |                             └─top·····alice    885       884</span>
          |-systemd-journal·······················root      10         1
          ...                                             
    Notice for example that the same process "bash" runs as a user or another
    (<span green>mike</span> or <span brown>alice</span>) depending on the "path"
    followed until the process is executed.
 
    - The initial sshd running as root user, will span a new sshd child process
      with restricted <span green>"mike"</span> privileges/permissions once the user
      has introduced its correct user and password in the remote ssh session, and
      from there on, all children will just be able to run with <span green>"mike"</span>
      privileges/permissions.

    - Similarly the root systemd process will span a new child process will
      restricted <span brown>"alice"</span> privileges/permissions once logged in
      the local console, and from there on, all children will just be able to 
      run with <span brown>"alice"</span> privileges/permissions.
</pre>
  <span>executable file vs in-memory process
<pre xxxsmall zoom>
- Applications are stored on disk drives as files or "bunch-of-instructions and initial data".

- When the kernel executes and application it will read the executable file, load
  the "bunch-of-instructions" into RAM memory, setup the initial data, assign 
  restricted privileges and finally allow the program-in-memory to be executed by
  any free-available CPU on the system.
</pre>
  <span>Basic file permissions:</span>
<pre xxxsmall zoom>
Standar file permissions allows to assign different access permissions to
the owner of the file, the group owner of the file and anyone else.

$ ls -l myFileOfInterest.db

-rw?-r-?---? john accountDepartment ....  myFileOfInterest.db
└┼┘│└┼┘│└┼┘│  └┬─┘ └──────┬────────┘                                                     
 │ │ │ │ │ │   │          │
 │ │ │ │ │ │   │          └─ group owner
 │ │ │ │ │ │   └──────────── user  owner
 │ │ │ │ │ │                            
 │ │ │ │ │ └──────────────── sticky bit (hidden if not set)
 │ │ │ │ │                                                 
 │ │ │ │ └────────────────── permissions allowed to others: read           access
 │ │ │ │ 
 │ │ │ └──────────────────── SUID bit   (hidden if not set)
 │ │ │ 
 │ │ └────────────────────── permissions allowed to group : read           access
 │ │                                                                             
 │ └──────────────────────── SUID bit   (hidden if not set)
 │                                                         
 └────────────────────────── permissions allowed to user  : read&amp;write access 

Previous line can be read as:
"""Allow read and write permissions to file-owner "john",
       read permissions to group-owner "accountDepartment"
   and no   permissions to anyone-else """

            ┌──────┬─────────────────────────────┬─────────────────────────────┐
Permissions │Symbol│      FILE                   │     DIRECTORY               │ 
┌───────────┼──────┼─────────────────────────────┼─────────────────────────────┤
│       read│  r   │ Allows to read the content  │ Allows to list the files in │
│           │      │ of the file                 │ and file-attributes in the  │
│           │      │                             │ directory                   │
├───────────┼──────┼─────────────────────────────┼─────────────────────────────┤
│      write│  w   │ Allows to write, modify,    │ Allows to add and delete    │
│           │      │ append or delete the file   │ files into the directory and│
│           │      │ content.                    │ modify metadata (access     │
│           │      │                             │ or modification time, ...)  │
├───────────┼──────┼─────────────────────────────┼─────────────────────────────┤
│    execute│  x   │ Allows to execute the       │ Allows to enter into the    │
│           │      │ program or script           │ directory                   │
├───────────┼──────┼─────────────────────────────┴─────────────────────────────┤
│    sticky │  T   │ Only the person that created the file/dir. can change it, │
│           │      │ even if other people have write permissions to file/dir.  │
│           │      │ turn on: $ chmod +t someFileOrDir                         │
│           │      │ Normal /tmp (temporary user files) is an sticky directory │
├───────────┼──────┼───────────────────────────────────────────────────────────┤
│       suid│  S   │ Allow SUID/SGID (switch user/group ID). When executed it  │
│           │      │ it will be executed with creator/group of file, instead of│
│           │      │ current user.                                             │
│           │      │ turn on: $ chmod +s someFileOrDir                         │
└───────────┴──────┴───────────────────────────────────────────────────────────┘
</pre>
</td>
<td colsep></td>
<td colsep>User&nbsp;Mng</td>
<td>
  <span xsmall>Create new user:</span>
<pre xxxsmall zoom>
$ useradd [options] LOGIN : creates new user with default+specified values

$ useradd -D  #  display default values
(ex.output)
  GROUP=100
  HOME=/home
  INACTIVE=-1
  EXPIRE=
  SHELL=/bin/bash
  SKEL=/etc/skel
  CREATE_MAIL_SPOOL=yes

$ useradd -D [options] # update default values
----- next opts have defaults if not indicated ----------
  --base-dir BASE_DIR  :  (default to /home) Ignored if --home-dir set
  --expiredate EXPIRE_DATE
  --inactive INACTIVE  :  day # after pass.expiration before disabling
  --gid GROUP: existing group name or ID for initial group (when --no-user-group used)
  --shell SHELL
--------------------------------------------------------
  --groups group1,group2,... supplementary groups
  --skel SKEL_DIR :  skel. dir. to be copied in the user's home directory
  --key KEY=VALUE : Overrides /etc/login.defs defaults 
                    (UID_MIN, UID_MAX, UMASK, PASS_MAX_DAYS and others).
                    Example: -K PASS_MAX_DAYS=-1 can be used when creating 
                      system account to turn off password ageing, even though 
                      system account has no password at all.
  --no-log-init   : Do not add user to lastlog and faillog databases
  --create-home   : Create the user's home directory if it does not exist.
                    By default no home directories are created
  --no-create-home: Do not create the user's home directory if enabled in defaults
  --no-user-group : Do not create a group. Initial group indicated by --gid 
  --non-unique    : Allow duplicate (non-unique) existing UID in --uid
  --password PASS : (disabled by default)
  --system        : Create system account (no aging, uid chosen in
                     SYS_UID_MIN-SYS_UID_MAX range)
  --root CHROOTDIR: Apply changes in chrooted directory 
  --uid UID       : numerical value for user's ID.
  --user-group    : Create group with the same name as user, and use as initial group
  --selinux-user SEUSER : SELinux user for the user's login
</pre>

  <span xsmall>basic user audit:</span>
<pre xxxsmall zoom>
$ who     ← Displays current users logged into the system and the  logged-in time
$ w       ← Displays who is logged into the system and <b>what they are doing</b> (procs. they are running). 
$ users   ← Displays only user names who are currently logged in
$ last    ← Displays records of users-logged-in time, <b>remote IP or PTTY</b>, reboot time, 
$ lastlog ← Displays list of users and what day/time they logged into the system.
$ whoami  ← Tells the user who they are currently logged in as
$ ac      ← Tell how much time users are logged in.
            (sudo apt install acct, sudo dnf install psacct, ...)
            It pulls its data from the current wtmp file.
            Ex:
            $ <b>ac</b>
            → total     1261.72
            $ <b>ac -p</b>  ← total hours by user
            → shark        5.24
            → nemo         5.52
            → shs       1251.00
            → total     1261.76
            $ <b>$ ac -d | tail -10</b>  ← daily counts of how many hours users were logged in
            → Jan 11  total        0.05
            → Jan 12  total        1.36
            → Jan 13  total       16.39
            → Jan 15  total       55.33
            → Jan 16  total       38.02
            → Jan 17  total       28.51
            → Jan 19  total       48.66
            → Jan 20  total        1.37
            → Jan 22  total       23.48
            → Today   total        9.83
</pre>
  <hr xxxsmall />

  <span xsmall>basic process audit/control</span>
<pre xxxsmall zoom bgorange>
$ <b>ps</b>   ← shows list of the processes running. i
         Without options: processes belonging to current user&amp;with a controlling terminal
  Ex. options include:
   -a: all processes from all users
   -u: add user names, %cpu usage, and %mem usage,...
   -x: add also processes without controlling terminals
   -l: add information including UID and nice value
   --forest: show process hierarchy.

$ <b>pstree</b> ← show parent/children process tree (-p flag show pid)

$ <b>top -n 1</b> ← Display top by cpu processes once and finish
$ <b>top</b>      ← real-time display processes ordered by memory/CPU/...(as in CPU usage)

  Z,B,E,e   Global: 'Z' colors; 'B' bold; 'E'/'e' summary/task memory scale
  l,t,m     Toggle Summary: 'l' load avg; 't' task/cpu stats; 'm' memory info
  0,1,2,3,I Toggle: '0' zeros; '1/2/3' cpus or numa node views; 'I' Irix mode
  f,F,X     Fields: 'f'/'F' add/remove/order/sort; 'X' increase fixed-width

  L,&,<,> . Locate: 'L'/'&' find/again; Move sort column: '<'/'>' left/right
  R,H,V,J . Toggle: 'R' Sort; 'H' Threads; 'V' Forest view; 'J' Num justify
  c,i,S,j . Toggle: 'c' Cmd name/line; 'i' Idle; 'S' Time; 'j' Str justify
  x,y     . Toggle highlights: 'x' sort field; 'y' running tasks
  z,b     . Toggle: 'z' color/mono; 'b' bold/reverse (only if 'x' or 'y')
  u,U,o,O . Filter by: 'u'/'U' effective/any user; 'o'/'O' other criteria
  n,#,^O  . Set: 'n'/'#' max tasks displayed; Show: Ctrl+'O' other filter(s)
  C,...   . Toggle scroll coordinates msg for: up,down,left,right,home,end

  k,r       Manipulate tasks: 'k' kill; 'r' renice
  d or s    Set update interval
  W,Y       Write configuration file 'W'; Inspect other output 'Y'
  q         Quit

$ <b>iotop</b>    # ← Simple top-like I/O monitor
(<a href="https://linux.die.net/man/1/iotop">man 1 iotop<a>)

$ <b>kill -l</b>   ← Display existing signals (Default to SIGTERM that most of the times
              will just terminate the process "cleanely")
→  1) SIGHUP   2) SIGINT   3) SIGQUIT  4) SIGILL   5) SIGTRAP
→  6) SIGABRT  7) SIGBUS   8) SIGFPE   9) SIGKILL 10) SIGUSR1
→ 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM
→ 16) SIGSTKFLT   17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP
→ 21) SIGTTIN 22) SIGTTOU 23) SIGURG  24) SIGXCPU 25) SIGXFSZ
→ 26) SIGVTALRM   27) SIGPROF 28) SIGWINCH    29) SIGIO   30) SIGPWR
→ 31) SIGSYS  34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
→ 38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
→ 43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
→ 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
→ 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
→ 58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
→ 63) SIGRTMAX-1  64) SIGRTMAX    
 
$ <b>kill [ -s (signal name)] 'process_id'</b> ← Send signal to process. kill -9 kills unconditionally
$ killall "process_name"  ← send signal to all processes matching full name
$ pkill "process_name"    ← send signal to all processes matching part of the name
$ skill  ← send a particular signal to command/username/tty.
        -L --- list the various signals that can be sent
        -u --- specify a username;
        -p --- process id (followed by the process id)
        -c --- command name (this is the same as killall)
        -t --- (tty number)
        -v --- verbose mode
        -i --- interactive mode.

PAUSE AND CONTINUE A PROCESS:
$ <b>kill -STOP "pid"</b> # Pauses
$ <b>kill -CONT "pid"</b> # Continues

$ <b>nice -20 make</b> ← Sets make priority to -20 
                  -20 is maximum priority   (negative only allowed to root)
                   20 is the minimum priority.
$ <b>renice 10 "pid"</b> ← Changes priority of running process.
</pre>
  <span xsmall>su/sudo: Switch user</span>
<pre xxxsmall zoom>
- su and sudo are mostly used to allow temporal root/superuser access
  to standard users for administrative tasks like installing new applications,
  re-configuring the network, ...

- sudo is ussually considered safer than su. Ubuntu was the first
  distribution to allow sudo-only. Others distributions are also
  changing to sudo-only as time passes.

- sudo offers also a plugable architecture not offered by su
  to provide different authentication and audit mechanisms. 
  REF:
  - <a href="https://www.sudo.ws/">Sudo Home page</a> 
  - <a href="https://www.sudo.ws/plugins.html">sudo Third-party plugins</a>.

<a href="https://linux.die.net/man/1/su">man 1 su</a>
<a href="https://linux.die.net/man/8/sudo">man 8 sudo</a>
Ex. ussage:
$ sudo vim /etc/passwd # edit /etc/passwd as root
 $ su  # Change to root user
 #

</pre>

</td>
<td colsep></td>
<td colsep>Network</td>
<td>
  
  <span xsmall>basic network audit/control:</span>
<pre xxxsmall zoom>
<b>Socket Statistics (ss)</b>
<a href="https://linux.die.net/man/8/ss">man 8 ss</a>  (ss: socket statistics) 

ss USAGE EXAMPLES

<b>$ sudo ss -ntlp</b>  
^^^^^^^^^^^^^^^
Display TCP (-t) ports listening (-l) for remote
request and show also the process that
opened the port (-p): -p requires sudo-permissions
-n: Do not reverse-resolve IPs to DNS names
(example output)
→ State      Recv-Q Send-Q  Local Address:Port   Peer Address:Port
→ LISTEN     0      128     *:80                 *:*                users:(("lighttpd",pid=23515,fd=4))
→ LISTEN     0      128     *:22                 *:*                users:(("sshd",pid=571,fd=3))

<b>$ sudo ss -t -a -p </b>
^^^^^^^^^^^^^^^^^^ 
Display all (-a) non-listening (no -l provided)
TCP (-t) sockets and processes using them (-p)
→ STATE       ... ADDRESS:PORT              PEER ADDRESS:PORT                
→ ESTABLISHED ... 127.0.0.1:postgres        127.0.0.1:46404        users:(("postgres",pid=64032,fd=11))
→ ESTABLISHED ... 10.0.0.5:idonix-metanet   81.61.178.46:51003     users:(("sshd",pid=61411,fd=3),("sshd",pid=61407,fd=3))
→ ESTABLISHED ... 127.0.0.1:37200           127.0.0.1:50004        users:(("sshd",pid=61411,fd=10))
→ ESTABLISHED ... 127.0.0.1:postgres        127.0.0.1:45086        users:(("postgres",pid=43553,fd=11))
→ TIME_WAIT   ...

<b>$ ss -o state established '( dport = :ssh or sport = :ssh )'</b>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Display all established ssh connections.

<b>$ ss -x src /tmp/.X11-unix/*</b>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Find all local processes connected to X server.


<b>$ ss -o state fin-wait-2 '( sport =  :http  or  sport  =  :https  )'  dst 193.233.7/24</b>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
List  all  the tcp sockets in state FIN-WAIT-1 for our apache to
network 193.233.7/24 and look at their timers.


<b>DISPLAY IP Routing Table</b>
$ ip route list
→ <b>default via 10.0.0.1 dev eth0</b>
→ 10.0.0.0/24     dev eth0    proto kernel scope link src 10.0.0.5 
→ 169.254.0.0/16  dev eth0                 scope link metric 1002 
→ 172.17.0.0/16   dev docker0 proto kernel scope link src 172.17.0.1 
→ 168.63.129.16   via 10.0.0.1 dev eth0 proto static 
→ 169.254.169.254 via 10.0.0.1 dev eth0 proto static 
→ ...

<b>DISPLAY IP Routing Table</b>
1: lo:     <LOOPBACK,           UP,LOWER_UP> ...  state UNKNOWN mode DEFAULT ...
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0:   <BROADCAST,MULTICAST,UP,LOWER_UP> ...  state UP      mode DEFAULT ...
    link/ether    00:0d:3a:26:bb:2b brd ff:ff:ff:ff:ff:ff
...

<b>SNIFF network traffic</b>
$ sudo tcpdump -i eth0 port 8090  -n -A  ←  "snif" IP traffic  in network interface eth0
                                        with IP packets to/from port 8090 
                                        -A: Show in text/ASCII format
                                        -n: Do not convert IPs to host-names
                                            (Avoiding slow dns reverse lookups)

<b>Show IP route from source to destination ("hop" path)</b>
$ sudo traceroute "destination_IP_or_host" ← (attempts to ) show the route of a packet. 

<b>Examine open ports in remote machine</b>
$ sudo nmap -nt remote_machine    ← (try to) query remote machine for open ports 
</pre>


  <span xsmall>basic network traffic shaping:</span>
<pre xxxsmall zoom>
<b> Network interface shaping with <a href="https://github.com/magnific0/wondershaper/">Wondershaper</a></b>
$ sudo ./wondershaper -a eth0 -u 4096 -d 8192 ← limit upload: 4Mbps, download:8Mbs

<b>Process network shaping with <a href="https://www.pcsuggest.com/bandwidth-traffic-shaping-in-linux-with-firejail/">Firejail</a></b>
$ firejail  --net=enp2s0 firefox [/bash] 
$ firejail --list | grep 'firefox' | awk -F: '{print$1}'
$ firejail  --bandwidth=PID set interface-name down-speed up-speed
</pre>
  
  <span xsmall>Internet Utility commands</span>
<pre xxxsmall zoom>
$ <b>host (ip_address|domain_name)</b>  ← Performs lookup of an internet address (using the Domain Name System, DNS). Simply type:
or
<b></b>
$ <b>dig</b>    www.amazon.com  ←        query to DNS
$ dig -x 10.10.10.10     ← revers query to DNS 
(check man page for more options)

$ <b>wget</b> www.myDomain.com/myPage  ← HTTP client
    Options: 
    -m: archive/"m"irrow single web-site
    -nc: (no clobber) avoid overwriting local files 

$   wget --spider \    ← parse bookmarks.html for links
    --force-html \
    -i bookmarks.html
(see man page for more info)

$ <b>curl</b>  ← Script oriented HTTP client.
          It can access dictionary servers (dict), 
          ldap servers, ftp, http, gopher, ...

$ curl -M : To access the full/huge manual 
$ curl -u username:password http://www.placetodownload/file
</pre>

</td>
<td>
  Remote access
  <hr xxxsmall />
  <span xsmall>ssh (text console)</span>
<pre xxxsmall zoom>
- <a href="https://en.wikipedia.org/wiki/Secure_Shell">ssh protocol</a> is the
  standard way to access Linux remotely.
  A running "sshd" (ssh daemon) must be instaled and running 
  on the remote machine.

<b>Quickly connect to remote machine runnin sshd</b>
  (Remote machine must allow passwords login)
  $ ssh myUser@myRemoteMachine  
 → myUser@mYRemoteMachine's password:
  (enter password to log-in to text terminal)
 
<b>Advanced connection options</b> 
Using the ~/.ssh/config  is the recommended option for all
by the simplest scenarios. the ~/.ssh/config file allows
for complex tunning allowing for tcp tunneling, proxy-by-pass,
...
Example ~/.ssh/config
01 Host remoteHostAlias1 remoteHostAlias2 ... remoteHostAliasN 
02    HostName 10.230.11.10
03    ProxyCommand /usr/bin/corkscrew 10.10.10.10 8080 %h %p
04    Port 12345
05    User myRemoteUser
06    LocalForward   5555 localhost:3333
07    RemoteForward 13389 localhost:3389
08    TCPKeepAlive true

Line 01 defines different aliases that can be used to refer
to the remote machine.
Line 02 defines the real hostname or IP of the remote sshd server.
Line 03 is an example of a command that can be used to
        bypass local firewalls using our company HTTP proxy
Line 04 allows to connect to a non default ssh-server port
        (It's always recomended NOT to use the default port 22)
Line 05 Indicates our remote user id (needed if it's different
        to our local one).
Line 06 forwards any local IP request to our local port 5555 to
        the remote host and port (localhost:3333) accesible
        in the remote machine     ^^^^^^^^^
                                  localhost as seen by the
                                  remote machine. That is
                                  the remote machine itself

        Ex: If the remote machine has a web server configured 
        to just listen connection to port 3333 locally, the 
        the previous option allows to also connect to the
        server once the ssh authentication has worked properly.
        The remote web server will see a local-connection from
        its local sshd server on the remote machine.
        The local ssh client and remote ssh server will forward
        any local request to port 5555 to the port 3333 on the
        remote machine.
Line 07 Any program running on the remote machine doing requests
        to 13389 will be forwarded to our localhost:3389 port
        in our local machine.
        In this example localhost:3389 is the address of the
        local Windows Remote Desktop service. This allows to
        connect remotely to our remote desktop by connecting
        to port 13389 in the remote server 
        (once the ssh client has authenticated properly to the
        sshd server).

<b>Passwordless authentication</b>
- Useful to execute remote task automatically.
# STEP 01: generate local private secret (key) and associated public key.
$ ssh-keygen
(WARN: leave passphrase blank to allow for automated task)


# STEP 02: Copy associated public key to remote machine 
#          at  /home/myRemoteUser/.ssh/authorized-keys
$ ssh-copy-id myRemoteUser@myRemoteMachine

Now it must be possible to ssh into the remote machine with no password
$ ssh myRemoteUser@myRemoteMachine

Troubleshooting passwordless access:
local  $ chmod go-rw ~/.ssh/*  # Fix permission. ssh is paranoid about it.
remote $ chmod go-rw ~/.ssh/*  # Fix permission. ssh is paranoid about it.


See <a href="https://linux.die.net/man/1/ssh">man 1 ssh</a> and
    <a href="https://linux.die.net/man/8/sshd">man 8 sshd</a> 
for full list options. SSH, being the core security method to access
Linux server has a lot of simple and advanced options and different
configurations use different (paranoid) security options.
</pre>

  
  <span xsmall>VNC<br/>(Remote Desktop)</span>
<pre xxxsmall zoom>
- The VNC protocol allows to launch a graphical system in a
  remote system using the VNC server and access it remotely
  using the VNC clients.

- Running programs in the remote machine will "draw" to a
  local memory buffer shared by the VNC server.
  When a remote VNC client connects, the VNC server will 
  transmit to the client the graphic buffer and finally
  the VNC client will show the buffer in the local display.
- Modern VNC client←→server protocols are highly optimized
  to save bandwith and allows for high-resolution displays
  with around 1Megabit of bandwidth.

- There is no limit to the number of remote VNC servers that
  can run in parallel, just limited by memory access.
  This <a href="https://github.com/earizon/tigervnc_remote_desktop">github repository</a> offers an example of how to run many different
  VNC servers in parallel. 
</pre>

   <span xsmall bgorange>Knockd ("Invisible Linux")</span>
<pre xxxsmall zoom>
<a href="https://www.maketecheasier.com/make-linux-server-invisible-knockd/">REF(Michael Aboagye @ MakeTechEasier.com)</a>

- port-knock server:
  - It listens to all traffic on an network interface
    waiting for special sequences of port-hits.

- clients (telnet, socat, ...) initiate port-hits by
  sending a TCP or packet to a port on the server.

<b>PRE-SETUP</b>
- Install and Configure Iptables
  $ sudo apt-get install iptables iptables-persistent
                                  ^^^^^^^^^^^^^^^^^^^
                                  takes over automatic
                                  loading of saved tables


<b> Knockd Install</b>
$ sudo apt-get install knockd  # apt like
$ sudo dnf     install knockd  # rpm like

<b>hide ssh service until "Knocked"</b>
$ iptables -A INPUT \
        -m conntrack \                        STEP 1
        --ctstate ESTABLISHED, RELATED \    ← Allow established/current
        -j  ACCEPT                          ← Allow

$ iptables  -A  INPUT \                       STEP 2
        -p tcp  --dport  22 \               ← block incomming con. to 22 (SSH)
        -j  REJECT 

                                              STEP 3
$ netfilter-persistent save                 ← s save the firewall rules
$ netfilter-persistent reload             


Configure  Knockd
$ sudo "vim" /etc/knockd.conf
  | [options]
  |   UseSyslog
  | 
  | [openSSH]
  |   sequence = 7000,8000,9000
  |   seq_timeout = 5
  |   command = /sbin/iptables -A INPUT -s %IP% -p tcp --dport 22 -j ACCEPT
  |   tcpflags = syn
  | 
  | [closeSSH]
  |   sequence = 8000,9000,7000
  |   seq_timeout = 5
  |   command = /sbin/iptables -D INPUT -s %IP% -p tcp --dport 22 -j ACCEPT
  |   tcpflags = syn

- command will be executed once the client-sequence  is recognised.
- tcpflags must be set on the client "knocks"

NOTE: Adding iptables "-A" flag (appned) causes the rule to be appended
to the end of th INPUT chain, causing all remaining connections to drop.
Replace by:
  command = /sbin/iptables -I INPUT 1 -s %IP% -p tcp --dport 22 -j ACCEPT

  "-I" flag (insert) ensures that the new rule is added to the top of the
  input chain to accept ssh connections.

<b>Enable Knockd Service</b>
- Add/edit START_KNOCKD option in /etc/default/knock lo look like:
  START_KNOCKD=1
$ sudo systemctl enable knockd
$ sudo systemctl start knockd

<b>Testing</b>

$ knock -v my-server-ip  7000 8000 9000
$ ssh my-server-ip
...
$ knock -v my-server-ip 9000 8000 7000
</pre>



</td>
<td colsep> </td>
<td colsep>System&nbsp;Info</td>
<td>
   Basic info
<pre xxxsmall zoom>
$ <b>uptime</b>  ← shows how long the computer has been "up" since last reboot. 
           number of users and the processor load
$ <b>date</b>    ← current date/time
$ <b>cal</b>     ← display calendar
$ <b>uname</b>   ← print information on the system such as OS type, kernel version...
    -a --- print all the available information
    -m --- print only information related to the machine itself
    -n --- print only the machine hostname
    -r --- print the release number of the current kernel
    -s --- print the operating system name
    -p --- print the processor type

$ <b></b>cat /etc/*release* | sort | uniq</b> ← Shows OS identification 
                                       (Distribution, major, minor,patch version, flavour, ...)
$ <b>free -g</b>  ← human-readable memory report (-g: Gigabytes)
              total        used        free      shared  buff/cache   available
Mem:        6102476      812244     4090752       13112     1199480     4984140
Swap:       2097148           0     2097148
$ <b>getconf -ag</b>  ← Get all system config. parameters
→ ...
→ PAGESIZE                           4096
→ ..
→ ULONG_MAX                          18446744073709551615
→ USHRT_MAX                          65535
→ ...
→ _POSIX_...
→ ...
→ LFS_CFLAGS
→ LFS_LDFLAGS
→ LFS_LIBS
→ LFS_LINTFLAGS
→ LFS64_CFLAGS                       -D_LARGEFILE64_SOURCE
→ LFS64_LDFLAGS
→ LFS64_LIBS
→ LFS64_LINTFLAGS                    -D_LARGEFILE64_SOURCE
→ ...
→ GNU_LIBC_VERSION                   glibc 2.28
→ GNU_LIBPTHREAD_VERSION             NPTL 2.28
→ POSIX2_SYMLINKS                    1
→ LEVEL1_ICACHE_SIZE                 32768
→ LEVEL1_ICACHE_ASSOC                8
→ LEVEL2_CACHE_SIZE                  262144
→ LEVEL2_CACHE_ASSOC                 8
→ LEVEL2_CACHE_LINESIZE              64
→ LEVEL3_CACHE_SIZE                  3145728
→ LEVEL3_CACHE_ASSOC                 12
→ LEVEL3_CACHE_LINESIZE              64
→ LEVEL4_CACHE_SIZE                  0
→ LEVEL4_CACHE_ASSOC                 0
→ LEVEL4_CACHE_LINESIZE              0
→ ...



<b>dmidecode types</b>
 0   BIOS                 11   OEM Strings                       22   Portable Battery          33   64-bit Memory Error
 1   System               12   System Configuration Options      23   System Reset              34   Management Device
 2   Baseboard            13   BIOS Language                     24   Hardware Security         35   Management Device Component
 3   Chassis              14   Group Associations                25   System Power Controls     36   Management Device Threshold Data
 4   Processor            15   System Event Log                  26   Voltage Probe             37   Memory Channel
 5   Memory Controller    16   Physical Memory Array             27   Cooling Device            38   IPMI Device
 6   Memory Module        17   Memory Device                     28   Temperature Probe         39   Power Supply
 7   Cache                18   32-bit Memory Error               29   Electrical Current Probe  40   Additional Information
 8   Port Connector       19   Memory Array Mapped Address       30   Out-of-band Remote Access 41   Onboard Devices Extended Information
 9   System Slots         20   Memory Device Mapped Address      31   Boot Integrity Services   42   Management Controller Host Interface
10   On Board Devices     21   Built-in Pointing Device          32   System Boot

Show physical mem.banks
$ sudo dmidecode -t 17
| OUPUT PHYSICAL MACHINE                      | OUPUT VIRTUAL MACHINE (Manufacturer: QUEMU,...)
| # dmidecode 3.2                             | # dmidecode 3.0
| Getting SMBIOS data from sysfs.             | Getting SMBIOS data from sysfs.
| SMBIOS 2.7 present.                         | SMBIOS 2.8 present.
|                                             | 
| Handle 0x0008, DMI type 17, 34 bytes        | Handle 0x1100, DMI type 17, 40 bytes
| Memory Device                               | Memory Device
|     Array Handle: 0x0007                    |         Array Handle: 0x1000
|     Error Information Handle: Not Provided  |         Error Information Handle: Not Provided
|     Total Width: 64 bits                    |         Total Width: Unknown
|     Data Width: 64 bits                     |         Data Width: Unknown
|     Size: 8192 MB                           |         Size: 4096 MB
|     Form Factor: SODIMM                     |         Form Factor: DIMM    
|     Set: None                               |         Set: None
|     Locator: ChannelA-DIMM0                 |         Locator: DIMM 0
|     Bank Locator: BANK 0                    |         Bank Locator: Not Specified
|     Type: DDR3                              |         Type: RAM
|     Type Detail: Synchronous                |         Type Detail: Other
|     Speed: 1333 MT/s                        |         Speed: Unknown
|     Manufacturer: Samsung                   |         Manufacturer: QEMU
|     Serial Number: 939BED25                 |         Serial Number: Not Specified
|     Asset Tag: None                         |         Asset Tag: Not Specified
|     Part Number: M471B1G73DB0-YK0           |         Part Number: Not Specified
|     Rank: Unknown                           |         Rank: Unknown
|     Configured Memory Speed: 1333 MT/s      |         Configured Clock Speed: Unknown
|                                             |         Minimum Voltage: Unknown
| Handle 0x0009, DMI type 17, 34 bytes        |         Maximum Voltage: Unknown
| Memory Device                               |         Configured Voltage: Unknown
|     Array Handle: 0x0007                    |
|     Error Information Handle: Not Provided  |
|     Total Width: 64 bits                    |
|     Data Width: 64 bits                     |<b>
|     Size: 8192 MB                           |
|     Form Factor: SODIMM                     |
|     Set: None                               |
|     Locator: ChannelB-DIMM0                 |
|     Bank Locator: BANK 2                    |
|     Type: DDR3                              |
|     Type Detail: Synchronous                |
|     Speed: 1333 MT/s                        |
|     Manufacturer: 04CB                      |</b>
|     Serial Number: A8750300                 |
|     Asset Tag: None                         |
|     Part Number:                            |
|     Rank: Unknown                           |
|     Configured Memory Speed: 1333 MT/s      |
</pre>



  <span xsmall>vmstat(global stats)</span>
<pre xxxsmall zoom bgorange>
<a href="https://linux.die.net/man/8/vmstat">man 8vmstat</a>display real-time stats of procs.,mem, paging, block IO, traps, disks and cpu activity.
Ussage:
  $ vmstat [options] [delay [count]]
The first report produced gives averages since the last reboot.
Additional reports give information on a sampling period of length delay.
The process and memory reports are instantaneous in either case.

 -a --active: Display active and inactive memory
              FROM:<a href="https://unix.stackexchange.com/questions/305606/linux-inactive-memory">REF</a>
              * active memory are pages which have been accessed "recently"
              * inactive memory are pages which have not been accessed "recently"
              """A high ratio of active to innactive memory can indicate
                 memory pressure, but that condition is usually accompanied by
                 pagin/swapping which is easier to understand"""
 -f --forks : display number of forks (fork,vfork,clone) since boot. This
 -m --slabs : Display <a href="https://en.wikipedia.org/wiki/Slab_allocation">slabinfo</a>
              (memory assigned to kernel objects)
 -s --stats : Displays a table of various event counters and memory statis‐
            tics. (without repeating)
 -d --disk  : Report disk statistics
 -D --disk-sum: Report some summary statistics about disk activity.
 -p --partition device: Detailed statistics about partition
 -S --unit  :=  1000 (k), 1024 (K), 1000000 (m), 1048576 (M) bytes.
            swap (si/so) and block (bi/bo) not affected
 -t --timestamp: Append timestamp to each line
 <b>-w --wide  : Wide output mode</b> (Recomended)

OUTPUT FIELD DESCRIPTION 
<b>VM MODE</b>                                         | <b>DISK MODE(--disk)</b>
Procs                                           | Reads
  r: # of runnable procs(running|waiting for)   |   total  :   Total reads completed successfully
  b: # of processes <b red>in uninterruptible sleep</b>    |   merged : grouped reads(resulting in 1 I/O)
                                                |   sectors: Sectors read successfully
Memory *1                                       |        ms: milliseconds spent reading 
(inactiv,cache,buff can be freed if needed)     |
  swpd  : virtual memory used                   | 
  free  : idle (ready to use) memory            | Writes
  buff  : memory used as disk buffers           |     total:   Total writes completed successfully
  cache : memory used as cache                  |    merged: grouped writes (resulting in 1 I/O)
  inact : inactive memory (-a option)           |   sectors: Sectors written successfully
          (still cached for possible reuse)     |        ms: milliseconds spent writing
  active: memory Used by processes              |
                                                | IO
 Swap                                           |   cur: I/O in progress
   si: Amount of memory swapped in from disk(/s)|     s: seconds spent for I/O
   so: Amount of memory swapped to disk(/s)     +--------------------------------------------------------

IO                                              | <b>DISK PARTITION MODE (--partition)</b>
  bi: Blocks received from block device         |           reads: Total # of reads issued to part.
  bo: Blocks     sent   to block device         |    read sectors: Total read sectors for partition
                                                |          writes: Total # of writes issued to part.
System                                          |requested writes: Total # of write requests made for part
  in: interrupts per second, including the clock+---------------------------------------------------------
  cs: <b red>context switches per second</b>
                                                | <b>SLAB MODE (--slabs)</b>
CPU (percentages of total CPU time)             |   cache: Cache name
  us: Time spent running non-kernel code(user  )|     num: # of currently active objects
  sy: Time spent running     kernel code(system)|   total: Total # of available objects
  id: Time spent idle                           |    size: Size of each object
  wa: <b red>Time spent waiting for IO</b>                 |   pages: # of pages with at least one active object

  st: Time stolen from a virtual machine        +---------------------------------------------------------

<b>All linux blocks are currently 1024 bytes.</b>

SEE ALSO
    free(1), iostat(1), mpstat(1), ps(1), sar(1), top(1)

* 1: <a href="https://stackoverflow.com/questions/6345020/what-is-the-difference-between-buffer-vs-cache-memory-in-linux">REF</a>
    - buffers are associated with a specific block device, 
      caching filesystem metadata(dir contents, file permissions),
      as tracking in-flight pages (what's being written
      from or read to for a particular block device). 
    - cache only contains parked file data (file content)
</pre>

  
  <span xsmall>Accurate mem.use</span>
<pre xxxsmall zoom>
<a href="https://github.com/pixelb/ps_mem/">REF</a>

PIP INSTALL:
$ sudo pip install ps_mem

USSAGE:
ps_mem [-h|--help] [-p PID,...] [-s|--split-args] [-t|--total] [-w N]
       [-d|--discriminate-by-pid] [-S|--swap]

Ex 1:
  $ sudo ps_mem
  →  Private  +   Shared  =  RAM used       Program
  → 
  →  34.6 MiB +   1.0 MiB =  35.7 MiB       gnome-terminal
  → 139.8 MiB +   2.3 MiB = 142.1 MiB       firefox
  → 291.8 MiB +   2.5 MiB = 294.3 MiB       gnome-shell
  → 272.2 MiB +  43.9 MiB = 316.1 MiB       chrome (12)
  → 913.9 MiB +   3.2 MiB = 917.1 MiB       thunderbird
  → ---------------------------------
  →                           1.9 GiB
  → =================================
  → 

Ex 2: Show only ps_mem for current $USER:
  ~ sudo ps_mem -p $(pgrep -d, -u $USER)
  → ...

Ex 3: Summarize total RAM usage per user:

  for i in $(ps -e -o user= | sort | uniq); do
    printf '%-20s%10s\n' $i $(sudo ps_mem --total -p $(pgrep -d, -u $i))
  done
</pre>

  <span xsmall>SysV shared memory</span>
<pre xxxsmall zoom>
- SysV shared memory segments are accounted as a cache, though they
  do not represent any data on the disks.

To check the size of shared memory segments:
#  ipcs -m  # command and checking the bytes column.
</pre>

</td>

<td colsep></td>
<td>
  <b>BACKUPS</b> 
  <hr  xxxsmall/>
  tar (tape-archive)
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/tar">man 1 tar</a>
- standard tool for archiving saving a (many) files and directories to a single
  tape or disk archive.
- Individual files can be restored from the .tar file when needed.

Examples:
<b>Create archive file:</b>
$ tar czf _home_myUser_myProject_01.tar.gz /home/myUser/myProject
      ↑↑↑                                  ^^^^^^^^^^^^^^^^^^^^^^
      │││                                  directory to archive
      │││
      ││└── name of output file
      │└─── use gzip for compression (.gz extension)
      └──── compress
 
<b>Restore backup from archive file:</b>
$ cd /home/myUser
$ tar xzf _home_myUser_myProject_01.tar.gz
      ↑↑↑                                 
      │││
      ││└── name of  input file
      │└─── use gzip for de-compression
      └──── de-compress
</pre>
  
  <span xsmall>Remote Incremental backups:</span>
  <ul xxxsmall zoom>
  <li><a bgorange href="https://github.com/earizon/easyup">EasyUp</a> KISS incremental remote backup around rsync+ssh</a></li>
  <li><a href="http://rsnapshot.org/">Rsnapshot</a> filesystem snapshot utility on top of rsync.<br/>
     rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh.
     The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required 
     and rsync to save bandwidth (backup only changes) 
  </li>
  <li><a href="https://linuxhint.com/inotofy-rsync-bash-live-backups/">Live backups with inotify + rsync + bash</a>. Backup on "real-time changes"</li>
  <li><span cite>"""<a href="http://www.bacula.org/">Bacula</a> is a set of
    Open Source, computer programs that permit to manage backup, recovery, and 
    verification of computer data across a network of computers of different 
    kinds,  offering many advanced storage management features that make it 
    easy to find and recover lost or damaged files.</span>"""
<pre xxxsmall>
<a href="http://www.bacula.org/9.0.x-manuals/en/main/index.html">Manual v.9</a>
Director Daemon supervises all the backup, restore, verify and archive operations.
Sysadmin uses Director to schedule backups and to recover files..

Console service allows the administrator or user to communicate with the Director
(three versions: text-based, QT-based, wxWidgets)

File Daemon It's installed on the machine to be backed up and is responsible for 
providing the file attributes and data when requested by the Director
as well as for the file system dependent part of restoring the file attributes and data 
during a recovery operation.

Storage daemons are software programs in charge of storage and recovery of the 
file attributes and data to the physical backup media or volumes. In other words, it is 
responsible for reading and writing your tapes (or other storage media, e.g. files)

Catalog Services are responsible for maintaining the file indexes and 
volume databases for all files backed up allowing sysadmin or user to
quickly locate and restore any desired file. The Catalog services sets
Bacula apart from simple backup programs like tar and bru, because the catalog
maintains a record of all Volumes used, all Jobs run, and all Files saved, permitting
efficient restoration and Volume management. Bacula currently supports three different 
databases, MySQL, and PostgreSQL one of which must be chosen when building Bacula.

Monitor Service Allows the administrator or user to watch current status of Directors,
File Daemons and Bacula Storage Daemons. Currently, only a GTK+ version is available.
</pre>
  </li>
  <li>Symple remote backups with ssh
<pre xxxsmall>
$ tar cjf - myDirToBackup \       # local
  | ssh myUser@myRemoteMachine \  # ssh pipe
  "cd myBackupPath && tar -xjf -" # remote
</pre>
  </li>
  <li><a href="https://github.com/Leo-G/backup-bash">"Real time" backup with rsync and bash</li>
  </ul>
</td>  
<td colsep></td>
<td colsep>Sec.Audit</td>
</td>
<td>
  <a href="https://www.nongnu.org/tiger/">Tiger</a><br/>
  <span xsmall>Quick Audit&amp;Intrusion Detection</span>
<pre xxxsmall zoom>
(Unix/Linux)
- open source shell-scripts collection for security audit and host intrusion detection.
- Very extensible.
- It scans system configuration files, file systems, and user configuration files
  for possible security problems and reports them.

<b>Install</b>
- Debian/Ubuntu/Mint/...
  $ sudo apt install tiger 
  (Output will be similar to)
  →┌────────────────────────────────────────────────────────────────────────────┤ Tripwire Configuration ├────────────────────────────────────────────────────────────────────────────┐
  →│ Tripwire uses a pair of keys to sign various files, thus ensuring their unaltered state.  By accepting here, you will be prompted for the passphrase for the first of those      │
  →│ keys, the site key, during the installation.  You are also agreeing to create a site key if one doesn't exist already.  Tripwire uses the site key to sign files that may be     │
  →│ common to multiple systems, e.g. the configuration & policy files.  See twfiles(5) for more information.                                                                         │
  →│                                                                                                                                                                                  │
  →│ Unfortunately, due to the Debian installation process, there is a period of time where this passphrase exists in a unencrypted format. Were an attacker to have access to your   │
  →│ machine during this period, he could possibly retrieve your passphrase and use it at some later point.                                                                           │
  →│                                                                                                                                                                                  │
  →│ If you would rather not have this exposure, decline here.  You will then need to create a site key, configuration file & policy file by hand.  See twadmin(8) for more           │
  →│ information.                                                                                                                                                                     │
  →│                                                                                                                                                                                  │
  →│ Do you wish to create/use your site key passphrase during installation?                                                                                                          │
  →│                                                                                                                                                                                  │
  →│                                                       <Yes>                                                          <No>                                                        │
  →└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
  (Pressing Yes)
  →┌────────────────────────┤ Tripwire Configuration ├────────────────────────┐
  →│                                                                          │
  →│ Tripwire keeps its configuration in a encrypted database that is         │
  →│ generated, by default, from /etc/tripwire/twcfg.txt                      │
  →│                                                                          │
  →│ Any changes to /etc/tripwire/twcfg.txt, either as a result of a change   │
  →│ in this package or due to administrator activity, require the            │
  →│ regeneration of the encrypted database before they will take effect.     │
  →│                                                                          │
  →│ Selecting this action will result in your being prompted for the site    │
  →│ key passphrase during the post-installation process of this package.     │
  →│                                                                          │
  →│ Rebuild Tripwire configuration file?                                     │
  →│                                                                          │
  →│                    <Yes>                       <No>                      │
  →│                                                                          │
  →└──────────────────────────────────────────────────────────────────────────┘
  (Press yes)
  →┌────────────────────────┤ Tripwire Configuration ├─────────────────────────┐
  →│                                                                           │
  →│ Tripwire keeps its policies on what attributes of which files should be   │
  →│ monitored in a encrypted database that is generated, by default, from     │
  →│ /etc/tripwire/twpol.txt                                                   │
  →│                                                                           │
  →│ Any changes to /etc/tripwire/twpol.txt, either as a result of a change    │
  →│ in this package or due to administrator activity, require the             │
  →│ regeneration of the encrypted database before they will take effect.      │
  →│                                                                           │
  →│ Selecting this action will result in your being prompted for the site     │
  →│ key passphrase during the post-installation process of this package.      │
  →│                                                                           │
  →│ Rebuild Tripwire policy file?                                             │
  →│                                                                           │
  →│                    <Yes>                       <No>                       │
  →└───────────────────────────────────────────────────────────────────────────┘
  (Press yes)
  ...
  (enter required passphrases)
  ...
<b>
  The Tripwire binaries are located in /usr/sbin and the database is located
  in /var/lib/tripwire. It is strongly advised that these locations be stored
  on write-protected media (e.g. mounted RO floppy). See 
  /usr/share/doc/tripwire/README.Debian for details.
</b>
 
- Other Distros
$ wget  -c  http://download.savannah.gnu.org/releases/tiger/tiger-3.2rc3.tar.gz
                                                            ^^^^^^^^^^^^^^^^^^^
                                                            latest version (2019-01)
  $ tar -xzf tiger-3.2rc3.tar.gz
  $ cd tiger-3.2/
  $ sudo ./tiger

<b>tigerrc (Configuration)</b>
<b>Running</b>
  $ sudo tiger
  → Tiger UN*X security checking system
  →    Developed by Texas A&M University, 1994
  →    Updated by the Advanced Research Corporation, 1999-2002
  →    Further updated by Javier Fernandez-Sanguino, 2001-2015
  →    Contributions by Francisco Manuel Garcia Claramonte, 2009-2010
  →    Covered by the GNU General Public License (GPL)
  → 
  → Configuring...
  → 
  → Will try to check using config for '2018' running Linux 4.17.17-x86_64-linode116...
  → --CONFIG-- [con005c] Using configuration files for Linux 4.17.17-x86_64-linode116. Using
  →            configuration files for generic Linux 4.
  → Tiger security scripts *** 3.2.3, 2008.09.10.09.30 ***
  → 14:57> Beginning security report for localhost.
  → 14:57> Starting file systems scans in background...
  → 14:57> Checking password files...
  → 14:57> Checking group files...
  → 14:57> Checking user accounts...
  → 14:59> Checking .rhosts files...
  → 14:59> Checking .netrc files...
  → 14:59> Checking ttytab, securetty, and login configuration files...
  → 14:59> Checking PATH settings...
  → 14:59> Checking anonymous ftp setup...
  → 14:59> Checking mail aliases...
  → 14:59> Checking cron entries...
  → 14:59> Checking 'services' configuration...
  → 14:59> Checking NFS export entries...
  → 14:59> Checking permissions and ownership of system files...
  → --CONFIG-- [con010c] Filesystem 'nsfs' used by 'nsfs' is not recognised as a valid filesystem
  → 14:59> Checking for indications of break-in...
  → --CONFIG-- [con010c] Filesystem 'nsfs' used by 'nsfs' is not recognised as a valid filesystem
  → 14:59> Performing rootkit checks...
  → 14:59> Performing system specific checks...
  → 15:06> Performing root directory checks...
  → 15:06> Checking for secure backup devices...
  → 15:06> Checking for the presence of log files...
  → 15:06> Checking for the setting of user's umask...
  → 15:06> Checking for listening processes...
  → 15:06> Checking SSHD's configuration...
  → 15:06> Checking the printers control file...
  → 15:06> Checking ftpusers configuration...
  → 15:06> Checking NTP configuration...
  → 15:06> Waiting for filesystems scans to complete...
  → 15:06> Filesystems scans completed...
  → 15:06> Performing check of embedded pathnames...
  → 15:07> Security report completed for localhost.
  → Security report is in `/var/log/tiger/security.report.localhost.190115-14:57'.

 
- security report will be generated in the ./log 
→ ...
→ Security report is in `log//security.report.tecmint.181229-11:12'.
$ sudo cat log/security.report.tecmint.181229-11\:12

To display more information on a specific security message:
 - run the tigexp (TIGer EXPlain) command and provide the msgid as an argument, where “msgid” is the text inside the [] associated with each message.

For example, to get more information about the following messages, where [acc001w] and [path009w] are the msgids:

--WARN-- [acc015w] Login ID nobody has a duplicate home directory (/nonexistent) with another user.  
--WARN-- [path009w] /etc/profile does not export an initial setting for PATH.


</pre>
</td>
</tr>  
</table>  
<br/>
<table>  
<tr>  
<td colsep>Text&nbsp;Mng</td>  
<td>  
   Text view tools
<pre xxxsmall zoom>
Displaying text:
$ head -n 20 /path/to/textFile # shows first 20 lines (-n 20). 10 lines by default if -n not provided.
$ tail -n 20 /path/to/textFile # shows last  20 lines (-n 20). 10 lines by default if -n not provided.
$ tail -f    /path/to/textFile # shows stream ("f"lush) of lines as they are appended to the file
$ less       /path/to/textFile # Views text. Add scroll control backwards and forwards. 
                               # embedded systems use "more", that just scroll forwards.
$ cat        /path/to/textFile # dump text content to standard output (STDOUT)
$ cat file1 file2 file3 ....   # concatenates files'content and dumps into STDOUT
$ tac file1 file2 file3 ....   # concatenates files'content and dumps into STDOUT in reverse order
</pre>
   Text info tools
<pre xxxsmall zoom>
$ wc /path/to/textFile  ← Display total count of words, lines and bytes
                          Options:
                            -w count only words
                            -l count only lines
                            -w count only bytes


$ diff file1 file2     ← Compares two text files and output a difference report indicating:
                         '&gt; line_in_file2_not_in_file1
                         '&lt; line_in_file1_not_in_file2
$ sdiff                ← Similar to diff but with report in colum mode (more human readable)
$ diff3                ← diff for three files
</pre>

   Text modification tools
<pre xxxsmall zoom>
By default we can use next tools like:
   $ tool inputFile   # Apply to given file
or
   $ command1 ... | tool1 | tool2 | tool3 # Use stdout from previous command (|) as input 

sorting content:
$ sort file1  ← Sorting alphabetically lines in file  (-r to reverse, -g for numerical sort)
j
$ sort file1 -t ':' -k 4 -k 1    ← Use ':' as separator, sort first by column 4, then column 1.

$ join file1 file2    ← Join two lines together assuming they share at least one common value
                        on the relevant line, skiping lines withouth common value.

Cut by column:
$ cut -d "," -f 1,3,7 file1.csv ← Use "," as column delimiter, show then columns 1,3,7
$ cut -c 1-50         file.txt  ← show characters 1 to 50 in each line
$ cut -5, 8, 20-      file.txt  ← show characters 1 to 5 and 8 and from 20 to the end

        This would display (“cut”) characters (columns) 1 to 5, 8 and from 20 to the end.

$ uniq file1     ←  Eliminates duplicate entries from a file
                    Commonly used with sort like:
                    $ cat file.txt | sort | uniq
                    Options: -c: display number of occurances of each duplicate
                             -u: list only unique entries
                             -d: list only duplicate entries

$ tr "u" "d" file1  ← translate all instances of characters in a text file
$  cat some_file | tr '[A-Z]' '[a-z]' > new_file  ← Convert all capital letters to lowercase

$ nl file1.txt  ← Display file1.txt to STDOUT prefixing with line numbers

$ sed "s/<b green>up</b>/<b orange>down</b>/<b blue>g</b>" file1.txt ← Replaces "<b green>up</b>" by "<b orange>down</b>". "<b blue>g</b>" flags indicates to replace all ocurrences. Otherwise only first is replaced.
sed stays for "Stream editor", and has a lot of powerful flags like searching for regular expresions ...
<span TODO>$ awk </span>
</pre>
Vim Cheat Sheet
<pre xxxsmall zoom><b>
Global                                            Insert(Append) mode</b>
| :help keyword - open help for keyword           |                                                     
| :saveas file - save file as                     | i - insert before the cursor                     
| :close - close current pane                     | I - insert at the beginning of the line          
| K - open man page for word under the cursor     | a - insert (append) after the cursor             
                                                  | A - insert (append) at the end of the line       
<b>Cursor movement (Prefix command with "number" to</b>  | o - append (open) a new line below current line  
                 <b>repeat it "number" times)</b>        | O - append (open) a new line above current line  
| h - move cursor left                            | ea - insert (append) at the end of the word      
| j - move cursor down                            | Esc - exit insert mode                           
| k - move cursor up                                                                                    
| l - move cursor right                                                                                 
| H - move to top of screen                   <b>Editing</b>
| M - move to middle of screen                | r - replace a single character
| L - move to bottom of screen                | J - join line below current one with one sp. in between
| w - jump forwards to the start of a word    | gJ - join line below current one without sp. in between
| W - jump forwards to the start of a word    | gwip - reflow paragraph
|     (words can contain punctuation)         | cc - change (replace) entire line
| e - jump forwards to the end of a word      | C - change (replace) to the end of the line
| E - jump forwards to the end of a word      | c$ - change (replace) to the end of the line
|     (words can contain punctuation)         | ciw - change (replace) entire word
| b - jump backwards to the start of a word   | cw - change (replace) to the end of the word
| B - jump backwards to the start of a word   | s - delete character and substitute text
|     (words can contain punctuation)         | S - delete line and substitute text (same as cc)
| % - move to matching character              | xp - transpose two letters (delete and paste)
|     '('←→')', '{'←→'}', '['←→']'            | u - undo
|     :h matchpairs in vim for more info      | Ctrl + r - redo
| 0 - jump to the start of the line           | . - repeat last command
| ^ - jump to the first non-blank line char.
| $ - jump to the end of the line
| g_ - jump to last non-blank line-char       <b>visual mode (makes life much simpler!!)</b>
| gg - go to first line of document           | v - start visual mode, mark lines, then do cmd.
| G -  go to the last line of document        | V - start linewise visual mode
| 5G - go to line 5                           | o - move to other end of marked area
| } - jump to next paragraph/function/block   | Ctrl + v - start visual block mode
| { - jump to prev paragraph/function/block   | O - move to other corner of block
| zz - center cursor on screen                | Esc - exit visual mode
| Ctrl + e - move screen down one line             
|     without moving cursor                   <b>Search/replace</b>
| Ctrl + y - move screen up one line          | /pattern - search for pattern
|     without moving cursor                   | ?pattern - search backward for pattern
| Ctrl + b - move back one full screen        | \vpattern - 'very magic' pattern: non-alphanumeric
| Ctrl + f - move forward one full screen     |             characters are interpreted as special
| Ctrl + d - move forward 1/2 a screen        |             regex symbols (no escaping needed)
| Ctrl + u - move back 1/2 a screen           | n - repeat search in same direction
                                              | N - repeat search in opposite direction
                                              | :%s/old/new/g - replace all old with new throughout file
                                              | :%s/old/new/gc - replace all old with new throughout file
                                              |                  with confirmations
                                              | :noh - remove highlighting of search matches

<b>
Visual commands                Registers                            Marks                                   Macros</b>
| > - shift text right         | :reg - show registers content      | :marks - list of marks                | qa - record macro a
| < - shift text left          | "xy - yank into register x         | ma - set current position for mark A  | q - stop recording macro
| y - yank (copy) marked text  | "xp - paste contents of register x | `a - jump to position of mark A       | @a - run macro a
| d - delete marked text       |                                    | y`a - yank text to position of mark A | @@ - rerun last run macro
| ~ - switch case              | Tip: Registers persists restart
                               |      (stored in ~/.viminfo)
                               | Tip: Register 0 contains always
                               |      the value of the last yank
<b>
Cut and paste                                            Exiting</b>
| yy - yank (copy) a line                                | :w - write (save) the file, but don't exit
| 2yy - yank (copy) 2 lines                              | :wq or :x or ZZ - write (save) and quit
| yw - yank (copy) the characters of the word from       | :q - quit safely (fails on unsaved changes)
|                  the cursor position to the start of   | :q!- force quit (ignore unsaved changes)
|                  the next word                         | :wqa - write (save) and quit on all tabs
| y$ - yank (copy) to end of line                        |
| p - put (paste) the clipboard after cursor
| P - put (paste) before cursor
| dd - delete (cut) a line
| 2dd - delete (cut) 2 lines
| dw - delete (cut) the characters of the word from the
|      cursor position to the start of the next word
| D - delete (cut) to the end of the line
| d$ - delete (cut) to the end of the line
| x - delete (cut) character

<b>
Working with multiple files                                             Tabs</b>
| :e file - edit a file in a new buffer                                 | :tabnew or :tabnew file - open a file in a new tab
| :bnext or :bn - go to the next buffer                                 | Ctrl + wT - move the current split window into its own tab
| :bprev or :bp - go to the previous buffer                             | gt or :tabnext or :tabn - move to the next tab
| :bd - delete a buffer (close a file)                                  | gT or :tabprev or :tabp - move to the previous tab
| :ls - list all open buffers                                           | #gt - move to tab number #
| :sp file - open a file in a new buffer and split window               | :tabmove # - move current tab to the #th position (indexed from 0)
| :vsp file - open a file in a new buffer and vertically split window   | :tabclose or :tabc - close the current tab and all its windows
| Ctrl + ws - split window                                              | :tabonly or :tabo - close all tabs except for the current one
| Ctrl + ww - switch windows                                            | :tabdo command - run the command on all tabs (e.g. :tabdo q - closes all opened tabs)
| Ctrl + wq - quit a window
| Ctrl + wv - split window vertically
| Ctrl + wh - move cursor to the left window (vertical split)
| Ctrl + wl - move cursor to the right window (vertical split)
| Ctrl + wj - move cursor to the window below (horizontal split)
| Ctrl + wk - move cursor to the window above (horizontal split)
</pre>
</td>
<td colsep></td>
<td colsep>Services</td>
<td>
  <a href="http://freedesktop.org/wiki/Software/systemd/">SystemD</a>("Services")
<pre xxxsmall zoom>
<a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html">man page</a>,
<a href="http://www.tecmint.com/create-new-service-units-in-systemd/">See also</a>
"service unit"                  "targets"
- createNew                       unit_collection
- run                             "wants"
- lifespan:daemon|run-once

Check unit_collections:          Check status of a service:
# systemctl --type=service       # systemctl status firewalld.service


# (sudo) systemctl daemon-reload
# (sudo) systemctl \
   enable|start|stop|restart|disable \
     firewalld.service

# sudo vim /etc/systemd/system/MyCustomScript.service\
  | [Unit]
  | Description = making network connection up
  | After = network.target
  | [Service]
  | ExecStart = /root/scripts/conup.sh
  | [Install]
  | WantedBy = multi-user.target

<b>
Systemd      |Systemd      |Systemd           | Systemd
Utilities    |Daemons      |Targets           | Core
</b>                                            
$ systemctl  |systemd      | bootmode         | manager
$ journalctl |journald     | basic            | systemd
$ notify     |networkd     | shutdown  
$ analyze    |logind       | reboot    
$ cgls       |user session |
$ cgtop                    | multiuser          
$ loginctl                 | dbus dlog, logind  
$ nspawn                   |                    
                           | graphical
                           | user-session
                           | display service

</pre>
FILE NAME EXTENSIONS FOR UNIT TYPES:
<pre xxxsmall zoom>
*<b orange>.target     </b>: define groups of units. They achieve little themselves and serve to call
 <b orange>            </b>  other units that are responsible for services, filesystems ...
 <b orange>            </b>  (equivalent to the classical SysV runlevels)
*<b orange>.service    </b>: handle services that SysV-init-based distributions will typically
 <b orange>            </b>  start or end using init scripts.
*<b orange>.(auto)mount</b>: mounting and unmounting filesystems
*<b orange>.path       </b>: allow systemd to monitor files and directories specified
 <b orange>            </b>  when an access happens in path, systemd will start the appropriate unit
*<b orange>.socket     </b>: create one or more sockets for socket activation.
 <b orange>            </b>  service unit associated will start the service when a connection request
 <b orange>            </b>  is received.
</pre>

CONFIG. FILE LAYOUT:
<pre xxxsmall zoom>
(NOTE: /etc takes precedence over /usr)
<b orange>Maintainer   </b>: /usr/lib/systemd/system              ( + $ systemctl daemon-reload)
<b orange>Administrator</b>: /etc/systemd/system/[name.type.d]/ ) ( + $ systemctl daemon-reload)
<b orange>runtime      </b>: /runtime/systemd/system
</pre>

Journalctl: <span xsmall><br/>
  Display/filter/search system logs</span>
<pre xxxsmall zoom>
# journalctl                      # ← all logs
# journalctl -b                   # ← Boot Messages
# journalctl -b -1                # ← Last Boot Messages
# journalctl --list-boots         # ← list system boots
# journalctl --since "3 hour ago" # ← Time range
                     "2 days ago" #
    --until "2015-06-26 23:20:00" #
# journalctl -u nginx.service     # ← by unit (can be specified multiple times)
# journalctl -f                   # ← Follow ("tail")
# journalctl -n 50                # ← most recent (50) entries
# journalctl -r                   # ← reverse chronological order
# journalctl -b -1  -p "crit"     # ← By priority:
                                  # ←   -b -1     : FROM emergency
                                  # ←   -p "crit" : TO: Critical
# journalctl _UID=108             # ← By _UID
---------------------------------------------------------------------
Output Formats ( -o parameter )

   json: json one long-line
   json-pretty:
   verbose:
   cat:  very short form, without any date/time or source server names
   short: (default), syslog style
   short-monotonic: similar to short, but the time stamp second value is shown with precision
</pre>
</td>
<td colsep></td>  
<td colsep>Soft&nbsp;install</td>  
<td>
  <a href="https://www.flatpak.org/">FlatPak</a>
 <hr xxxsmall />
 Basic Concepts
<pre xxxsmall zoom>
<b>Sandboxes</b>
- each application is built and run in an isolated 'sandbox' environment
  containing an application and its runtime. 
- By default, the application can only access the contents of its sandbox.
- Access to user files, network, graphics sockets, subsystems on the bus and devices
  have to be explicitly granted. 
- Access to other things, such as other processes, is deliberately NOT possible.

-  resources inside the sandbox that need to be exposed outside are known as "exports".
   (Ex: .desktop file and icon,...)

<b>Portals</b>
- Mechanism through which applications can interact with the host environment 
  from within a sandbox. They give the ability to interact with data, files
  and services without the need to add sandbox permissions.

- Examples of capabilities that can be accessed through portals include opening
  files through a file chooser dialog, or printing. 
- Interface toolkits can implement transparent support for portals, so access
  to resources outside of the sandbox will work securely and out of the box.

<b>Repositories</b>
- applications and runtimes are typically stored and published using repositories,
 which behave very similarly to Git repositories, containing a single object or
 multiple ones. Each object is versioned, allowing the up|down-grade. 
- Remote repository's content can be inspected and searched, and it can
  be used as the source of applications and runtimes.
- When an update is performed, new versions of installed applications and 
  runtimes are downloaded from the relevant remotes. (only the difference actually)
</pre>

 flatpak cli:
<pre xxxsmall zoom>
NOTE: graphical software management tools exists so command-line is optional

$ flatpak install 

$ flatpak uninstall

<b>Identifiers</b>
- unique three-part like
  com.company.App
              ^^^
      final segment is the object's name


<b>Identifier triple</b>

   com.company.App/i386/stable         com.company.App//stable       com.company.App/i386//
   ^^^^^^^^^^^^^^^ ^^^^ ^^^^^^                        ^^                                 ^^
    Application-ID Arch branch                   Use default                        Use default
    or name                                      architecture                       branch


<b>System versus user</b>
- Flatpak commands/repositories can be used/applied:
  - system-wide (default)
  - per-user    (--user option)

<b>Basic commands</b>
$ flatpak remotes # ← list remotes repositores configured on the system
(output list indicates whether remote has been added per-user or system-wide)


$ <b orange>URL_FLATPAKREPO</b>="https://dl.flathub.org/repo/flathub<b>.flatpakrepo</b>
                                                          ^^^^^^^^^^^ 
                                                       a .flatpakrepo file
                                                       contains:
                                                       - remote details
                                                       - remote GPG key
$ flatpak remote-add \          ← Add a remote repository
     --if-not-exists \
     flathub \                  ← arbitrary local-name assigned to remote 
     <b orange>${URL_FLATPAKREPO}</b>

$ flatpak remote-delete flathub ← Remove remote-repo from list of known remotes

$ flatpak search gimp           ← return any applications matching search terms.
(each row-result includes application ID + remote where it was found)


$ FLATPAKREF="https://flathub.org/repo/appstream/org.gimp.GIMP.flatpakref"
$ flatpak install ${FLATPAKREF}         ← install application from FLATPAKREF
$ flatpak install flathub org.gimp.GIMP ← install application from remote and ID
                  ^^^^^^^ ^^^^^^^^^^^^^ 
                  remote  application ID
  (the application runtime will also be instaled if not yet present)

<b>$ flatpak run org.gimp.GIMP     ← Run the application</b></b>

$ flatpak update                ← update all your installed applications
                                  and runtimes to the latest version

$ flatpak list                  ← List installed applications and runtimes

$ flatpak list --app            ← List installed applications only

$ flatpak uninstall ${APP_ID}   ← Uninstall Application

<b>Full Journey</b>
# Add remote "repository"
$ flatpak remote-add --user --from gnome https://sdk.gnome.org/gnome.flatpakrepo
# Install monodevelop from remote repository
$ flatpak install --user --from https://download.mono-project.com/repo/monodevelop.flatpakref
# Run monodevelop
$ flatpak run com.xamarin.MonoDevelop

</pre>
</td>
<td>
<a href="https://dnf.readthedocs.io/en/latest/">DNF</a>(RedHat/Fedora/Centos)
<pre xxxsmall zoom>
<a href="https://github.com/rpm-software-management">rpm soft. management @ GitHub</a>
<b>MOST COMMONLY USED:</b>
$ dnf search  "*myPackage*"     # ← Show matching pattern in package name|description
$ dnf list    "*myPackage*"     # ← Show matching pattern in package name
                                    Filter like:
                                                                         
$ sudo dnf install myNewPackage # ← Install package and dependencies
                                    (-y flag to avoid confirmation prompt)

$ sudo dnf history              # ← Check dnf install history
$ sudo dnf history undo 13      # ← Undo/rollback install

$ sudo dnf upgrade              # ← Upgrade all upgradable packages
                                    (patch security bugs)

<b>Package Report:</b>
$ dnf list <b>installed</b>     # ← report all installed packages
$ dnf list <b>available</b>     # ← report all available packages
                                    in any accessible repository
$ dnf list <b>obsoletes</b>     # ← report obsoleted by packages 
                                    in any accessible repository
$ dnf list <b>recent   </b>     # ← report packages recently added
                                    into accessible repositories
$ dnf list <b>upgrades </b>     # ← report available packages upgrading

<b>Avoid dnf/yum update certain packages:</b>
(This can be needed in critical systems where no downtime is allowed for some service)

- Add next line to /etc/dnf/dnf.conf (new Fedora/RedHat distros) or 
                   /etc/yum.conf     ( old Fedora/RedHat distros)
|exclude=kernel* another_package_name_or_name_pattern


<b>List all available versions of a package </b>
YUM: sorting by version number:
$ yum list docker-ce --showduplicates | sort -r

<b>Report (remote) package repositories</b>
$ dnf repolist   
(example output)
→ ...
→ Using metadata from Mon Sep 10 16:21:18 2018
→ repo id                  repo name                         
→ base                     CentOS-7 - Base                  
→ centos-openshift-origin  CentOS OpenShift Origin         
→ centos-sclo-rh           CentOS-7 - SCLo rh             
→ centos-sclo-sclo         CentOS-7 - SCLo sclo          
→ code                     Visual Studio Code           
→ docker-ce-stable         Docker CE Stable - x86_64   
→ *epel                    Extra Packages for Enterprise Linux 7 - x86_64   12,672
→ extras                   CentOS-7 - Extras          
→ go-repo                  go-repo - CentOS          
→ nodesource               Node.js Packages for Enterprise Linux 7 - x86_64    144
→ openlogic                CentOS-7 - openlogic packages for x86_64            113
→ pgdg94                   PostgreSQL 9.4 7 - x86_64
→ updates                  CentOS-7 - Updates      

<b>Full command list:</b>
<!-- { -->
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#clean-command-label">clean</a>
    Performs cleanup of temporary files kept for repositories. This includes any 
    such data left behind from disabled or removed repositories as well as 
    for different distribution release 
    versions.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#distro-sync-command-label">distro-sync</a>
    As necessary upgrades, downgrades or keeps selected installed packages to 
    match the latest version available from any enabled repository. If no 
    package is given, all installed packages are considered.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#downgrade-command-label">downgrade</a>
    Downgrades the specified packages to the highest installable package of all 
    known lower versions if possible. When version is given and is lower than 
    version of installed package then it downgrades to target version.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#group-command-label">group</a>
    Groups are virtual collections of packages. DNF keeps track of groups 
    that the user selected (“marked”) installed and can manipulate the 
    comprising packages with simple commands.  (See only manual for more info)
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#help-command-label">help</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#history-command-label">history</a>
   The history command allows the user to view what has happened in past 
   transactions and act according to this information (assuming the 
   history_record configuration option is set).
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#info-command-label">info</a>
     list description and summary information about installed and available packages.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#install-command-label">install</a>
    DNF makes sure that the given packages and their dependencies are 
    installed on the system. Each <spec> can be either a <package-spec>, or a 
    @<group-spec>. See Install Examples. If a given package or provide cannot 
    be (and is not already) installed, the exit code will be non-zero.

    When <package-spec> that specify exact version of the package is given, 
    DNF will install the desired version, no matter which version of the 
    package is already installed. The former version of the package will be 
    removed in the case of non-installonly package.

    There are also a few specific install commands install-n, install-na and 
    install-nevra that allow the specification of an exact argument in NEVRA 
    format.

    dnf install tito
        Install package tito (tito is package name).
    dnf install ~/Downloads/tito-0.6.2-1.fc22.noarch.rpm
        Install local rpm file tito-0.6.2-1.fc22.noarch.rpm from ~/Downloads/ directory.
    dnf install tito-0.5.6-1.fc22
        Install package with specific version. If the package is already 
        installed it will automatically try to downgrade or upgrade to specific version.
    dnf --best install tito
        Install the latest available version of package. If the package is 
        already installed it will automatically try to upgrade to the latest 
        version. If the latest version of package cannot be installed, the installation fail.
    dnf install vim
        DNF will automatically recognize that vim is not a package name, but 
        provide, and install a package that provides vim with all required 
        dependencies. Note: Package name match has precedence over package provides match.
    dnf install https://.../packages/tito/0.6.0/1.fc22/noarch/tito-0.6.0-1.fc22.noarch.rpm
        Install package directly from URL.
    dnf install '@Web Server'
        Install environmental group ‘Web Server’
    dnf install /usr/bin/rpmsign
        Install a package that provides /usr/bin/rpmsign file.
    dnf -y install tito --setopt=install_weak_deps=False
        Install package tito (tito is package name) without weak deps. Weak 
        deps are not required for core functionality of the package, but they 
        enhance the original package (like extended documentation, plugins, 
        additional functions, …). 
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#list-command-label">list</a>
    Dumps lists of packages depending on the packages’ relation to the system
    . A package is installed if it is present in the RPMDB, and it is 
    available if it is not installed but it is present in a repository that 
    DNF knows about. The list command can also limit the displayed packages 
    according to other criteria, e.g. to only those that update an installed 
    package. The exclude option in configuration file (.conf) might influence 
    the result, but if the command line option --disableexcludes is used, it 
    ensure that all installed packages will be listed
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#makecache-command-label">makecache</a>
    dnf [options] makecache
        Downloads and caches in binary format metadata for all known repos. 
        Tries to avoid downloading whenever possible (e.g. when the local 
        metadata hasn’t expired yet or when the metadata timestamp hasn’t changed).
    dnf [options] makecache --timer
        Like plain makecache but instructs DNF to be more resource-aware, 
        meaning will not do anything if running on battery power and will 
        terminate immediately if it’s too soon after the last successful 
        makecache run (see dnf.conf(5), metadata_timer_sync). 
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#mark-command-label">mark</a>
    dnf mark install <package-specs>...
        Marks the specified packages as installed by user. This can be useful 
        if any package was installed as a dependency and is desired to stay on 
        the system when Auto Remove Command or Remove Command along with 
        clean_requirements_on_remove configuration option set to True is executed.
    dnf mark remove <package-specs>...
        Unmarks the specified packages as installed by user....
    dnf mark group <package-specs>...
        Marks the specified packages as installed by group...
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#module-command-label">module</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#provides-command-label">provides</a>
    Finds the packages providing the given <provide-spec>. This is useful 
    when one knows a filename and wants to find what package (installed or not
    ) provides this file.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#reinstall-command-label">reinstall</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#remove-command-label">remove</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#repoinfo-command-label">repoinfo</a>
<a bgorange href="https://dnf.readthedocs.io/en/latest/command_ref.html#repolist-command-label">repolist</a>

<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#repoquery-command-label">repoquery</a>
    dnf [options] repoquery [<select-options>] [<query-options>] [<pkg-spec>]
        Searches the available DNF repositories for selected packages and 
        displays the requested information about them. It is an equivalent of rpm 
        -q for remote repositories.
    dnf [options] repoquery --querytags
        Provides list of recognized tags by repoquery option --queryformat
        There are also a few specific repoquery commands repoquery-n, 
        repoquery-na and repoquery-nevra that allow the specification of an exact 
        argument in NEVRA format (does not affect arguments of options like –
        whatprovides <arg>, …).
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#repository-packages-command-label">repository-packages</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#search-command-label">search</a>
    Search package metadata for the keywords. Keywords are matched as case-
    insensitive substrings, globbing is supported. By default lists packages 
    that match all requested keys (AND operation). Keys are searched in 
    package names and summaries. If option “–all” is used, lists packages 
    that match at least one of keys (OR operation). And in addition keys are 
    searched in package descriptions and URLs. The result is sorted from the 
    most relevant results to the least.
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#shell-command-label">shell</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#swap-command-label">swap</a>
    Remove spec and install spec in one transaction. Each "spec" can be 
    either a <package-spec>, which specifies a package directly, or a 
    @"group-spec", which specifies an (environment) group which contains it. 
    Automatic conflict solving is provided in DNF by –allowerasing option 
    that provides functionality of swap command automatically
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#updateinfo-command-label">updateinfo</a>
    Display information about update advisories.
    Depending on output type, DNF displays just counts of advisory types (
    omitted or --summary), list of advisories (--list) or detailed 
    information (--info). When --info with -v option is used, the information 
    is even more detailed
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-command-label">upgrade</a>
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-minimal-command-label">upgrade-minimal</a>
    Upgrade-minimal Command
    
    $ dnf [options] upgrade-minimal
        Updates each package to the latest version that provides bugfix, enhancement
        or fix for security issue (security)
    $ dnf [options] upgrade-minimal <package-installed-specs>...
        Updates each specified package to the latest available version that provides
        bugfix, enhancement or fix for security issue (security). Updates 
        dependencies as necessary. 
<a href="https://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-to-command-label">upgrade-to</a>
<!-- } -->

- ADDITIONAL INFORMATION:
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#options-label">Options</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#specifying-packages-label">Specifying Packages</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#specifying-packages-versions-label">Specifying Exact Versions of Packages</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#specifying-provides-label">Specifying Provides</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#specifying-groups-label">Specifying Groups</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#specifying-transactions-label">Specifying Transactions</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#metadata-synchronization-label">Metadata Synchronization</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#configuration-files-replacement-policy-label">Configuration Files Replacement Policy</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#files-label">Files</a>
    <a href="https://dnf.readthedocs.io/en/latest/command_ref.html#see-also-label">See Also</a>

  <a href="https://www.softwarecollections.org/en/">Software Collections</a>
Ex:
$ python --version
Python 2.7.5

$ scl enable rh-python35 bash
$ python --version
Python 3.5.1

  # <a href="https://wiki.centos.org/SpecialInterestGroup/SCLo">https://wiki.centos.org/SpecialInterestGroup/SCLo</a>
  # <a href="http://fedoraproject.org/wiki/EPEL">http://fedoraproject.org/wiki/EPEL</a>
  """ Extra Packages for Enterprise Linux (or EPEL) is a Fedora Special Interest
    Group that creates, maintains, and manages a high quality set of additional
    packages for Enterprise Linux, including, but not limited to, Red Hat 
    Enterprise Linux (RHEL), CentOS ... usually based on their Fedora counterparts
    and will never conflict with or replace packages in the base Enterprise
    Linux distributions....  """


<b orange># Install from given repository:</b>
$ sudo yum --disablerepo=\* --enablerepo=my-cool-repo install myPackage

Ex: Install Development Tools
...
<b>$ dnf groupinfo "Development Tools"</b>
→ Group: Development Tools
→  Description: A basic development environment.
→  Mandatory Packages:
→    autoconf
→    automake
→    binutils
→    ...
→  Default Packages:
→    byacc
→    cscope
→    ...
→  Optional Packages:
→    ElectricFence
→    ant
→    babel
     ...
<b>$ sudo dnf groupinstall "Development Tools"</b>

</pre>

  <a href="https://help.ubuntu.com/community/AptGet/Howto#Maintenance_commands">APT</a>(Debian/Ubuntu)
<pre xxxsmall zoom>

  <a TODO href="https://help.ubuntu.com/community/SourcesList">Package source list: /etc/apt/sources.list file</a>


$ sudo apt-get  install ubuntu-desktop  "package2" ... (-s to simulate)
$ sudo aptitude install ubuntu-desktop  ← Ncurses variant


$ sudo auto-apt run "./configure" ← runs "command_string", installing uninstalled packages when possible.
  ^ keeps databases up-to-date by calling:
    $ auto-apt update
    $ auto-apt updatedb
    $ auto-apt update-local

$ apt-get update ← Run periodically and after modifications to /etc/apt/*

$ apt-get upgrade ← upgrade all installed packages.

$ apt-get dist-upgrade ← same as upgrade, except add the "smart upgrade" checkbox.
                         It tells APT to use "smart" conflict resolution system,
                         and <b>it will attempt to upgrade the most important packages 
                         at the expense of less important ones if necessary.</b>
                         ¡¡¡does not upgrade from a previous version of Ubuntu!!!

<b>Diagnostics:</b>
$ apt-get check    ← update package lists and checks for broken dependencies

<b>Cleaning/Removal</b>
$ sudo apt-get autoclean  ← removes .deb files for packages that are no longer
                            installed on your system. (Can save space in /var/cache/apt/archives)
$ apt-get clean           ← same as autoclean, except it removes all packages from the package cache.
                            Not recomended with slow-connections.
                            ($ du -sh /var/cache/apt/archives)

$ sudo apt-get remove "package_name" ← keeps  configuration files 
$ sudo apt-get purge  "package_name" ← Remove configuration files

$ apt-get autoremove     ← removes packages no longer needed

<b>Troubleshooting</b>
$ sudo apt-get -f install  ← Fix Broken Packages (system complains about "unmet dependencies")

$ dpkg-reconfigure "package_name"


$ echo "'package_name' hold" | \  ← Put package_name on hold
  sudo dpkg --set-selections        may have the unintended side effect of preventing upgrades
                                    to packages that depend on updated versions of the pinned package.
                                    apt-get dist-upgrade will override this, but will warn you first.

<b>Search commands</b>
$ apt-cache search "search_term" ← lists packages matching in name or description

$ dpkg -l *"search_term"*  ← find packages whose names contain "search_term".
                             It also shows whether a package is installed on your system

$ dlocate "package_name"         ← "reverse lookup". It Determines which installed package owns "package_name".
                                    It shows files from installed packages that match "package_name",
                                    with the name of the package they came from. 
                                    Its equivalent to the slower (but installed by default):
                                    $ dpkg -S "filename_search_pattern"
$ sudo apt-file update && \       ← Similar to dlocate  but searches over all available packages. 
                                    """what package provides this file?"""

  sudo apt-file search \"filepath_pattern"
<b>Package Info</b>
$ apt-cache show "package_name"  ← shows the description of "package_name", version, size, dependencies and conflicts.
$ dpkg -L "package_name"         ← list files in package
$ dpkg -c foo.deb                ← lists files in the manually downloaded package "./foo.deb".

$ apt-cache pkgnames             ← provides a list of every package in the system



<b>Setting http-proxy</b>
- alt 1: Temporary proxy session:
  # export http_proxy=http://username:password@yourproxyaddress:proxyport

- alt 2: APT configuration file method 
  Add next line to /etc/apt/apt.conf 
  | Acquire::http::Proxy "http://yourproxyaddress:proxyport";


<b>Developer commands:</b>
$ apt-get build-dep <package_name> 
</pre>
</pre>


  <a href="https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management"><code>apk</code></a> (Alpine/"Docker")
<pre xxxsmall zoom>
Because Alpine Linux is designed to run from RAM, package management involves two phases:

- Installing / Upgrading / Deleting packages on a running system.
- Restoring a system to a previously configured state 
  (e.g. after reboot), including all previously installed packages 
  and locally modified configuration files. (RAM-Based Installs Only)

- apk is the tool used to install, upgrade, or delete software on a running sytem.
- lbu is the tool used to capture the data necessary to 
  restore a system to a previously configured state.


apk: 
  add      Add new packages to the running system
  del      Delete packages from the running system
  fix      Attempt to repair or upgrade an installed package
  update   Update the index of available packages
  info     Prints information about installed or available packages
  search   Search for packages or descriptions with wildcard patterns
  upgrade  Upgrade the currently installed packages
  cache    Maintenance operations for locally cached package repository
  version  Compare version differences between installed and available packages
  index    create a repository index from a list of packages
  fetch    download (but not install) packages
  audit    List changes to the file system from pristine package install state
  verify   Verify a package signature
  dot      Create a graphviz graph description for a given package
  policy   Display the repository that updates a given 
           package, plus repositories that also offer the package
  stats    Display statistics, including number of 
           packages installed and available, number of 
           directories and files, etc.
  manifest Display checksums for files contained in a given package


- Software packages for Alpine Linux are digitally signed 
  tar.gz archives with ".apk" extension (often called "a-packs")
  stored in one or more repositories (directory with a collection of *.apk files
  and a APKINDEX.tar.gz index )

- The list of repositories to check is stored in /etc/apk/repositories
  (one repo per line)
  Ex:
  /media/sda1/apks
  http://nl.alpinelinux.org/alpine/v3.7/community
  <b blue>@edge</b> http://nl.alpinelinux.org/alpine/edge/main
  <b blue>@edgecommunity</b> http://nl.alpinelinux.org/alpine/edge/community
  <b blue>@testing</b> http://nl.alpinelinux.org/alpine/edge/testing
  ^ "tagged" repo
    will be used like
    # apk add stableapp newapp@<b blue>edge</b> bleedingapp@<b blue>testing</b>
    by default only untagged repositories are used

Update the Package list
  # apk update (Fill catch locally the latest APKINDEX.tar.gz from remote repos)

Add Packages (transitive dependencies is automatic):
  # apk add openssh openntp vim

Add a packager from dev. repository (dangerous):
  # apk add cherokee --update-cache \
    --repository http://dl-3.alpinelinux.org/alpine/edge/testing/
    --allow-untrusted

Add local Package
  # apk add --allow-untrusted /path/to/file.apk


Remove a Package

  # apk del openssh

Upgrade a Running System

  # apk update
  # apk upgrade

To upgrade only a few packages, use the add command with the -u or --upgrade option:

apk update
apk add --upgrade busybox 
Note: Remember that when you reboot your machine, the remote repository will not be available until after networking is started. This means packages newer than your local boot media will likely not be installed after a reboot. To make an "upgrade" persist over a reboot, use a local cache.
Search for Packages


Search:
 # apk search -v        ← list all packages along with descriptions
 # apk search -v 'acf*' ← list all packages part of the ACF system
 # apk search -v --description 'NTP' ← list all packages that list NTP as 
                                       part of their description, 

Information on Packages
  # apk info -a zlib ← -w: show just webpage info
                       -a: show          all info
</pre>

</td>
</tr>
</table>
<br/>
Storage
<table>
<td colsep>Basic&nbsp;FS.Mng</td>
<td>
   <span xsmall>Moving around FS</span>
<pre xxxsmall zoom>
<b>Display current working directory</b>
$ pwd  # pwd: "P"rint "W"orking "D"irectory
<b>Change working directory</b>
$ cd /home/myUser/Dowload
$ pushd . # Store current dir. in stack
$ cd      # With no args move to $HOME directory
$ cd ~    # ~ is alias for $HOME
$ cd ..   # Change to parent directory
$ popd    # Move to last dir. in stack (and remove from stack)

<b>(ls "file or directory") List "file" or "files in directory"</b>
With no file or directory list info in current working directory
ls -l :  ("long"), show permissions, file size, modification date, ownership
ls -a :  ("all" ), shows also hidden files (files/dirs starting with ".") 
ls -d :  Show only directory entry, do NOT display directory contents 
ls -F :  ("format") append helper graphical symbol like '*' for executable files
ls -S :  sort by size output in descending order
ls -R :  ("recursive") list recursively children directories
</pre>

   <span xsmall>handling files/dirs</span>
<pre xxxsmall zoom>
<b>Create directory</b>
mkdir -p /home/myUser/work/project01 # -p: will create any non-existing directory up to project01
                                     #     Withouth -p mkdir will fail if /home/myUser/work does not exists

<b>Moving files</b>
$ mv /my/path01/myFile1  /my/path02/   # move myFile1 from path01 to path02 directory
<b>Rename file</b>
$ mv myOriginalName  myFinalName   # use the mv (move) command to rename
<b>copying files</b>
$ cp    /tmp/fileToCopy       /home/myUser/ # copy to destination directory
$ cp -R /tmp/directoryToCopy  /home/myUser/ # copy recursively (-R) directory to destination directory


<b>Remove files/directories</b>
$ rm -f file       # force (-f) file deletion.  The -f option is useful for automated scripts

                   # Be very careful with recursive deletions. Specially as root user

<b>Securely remove files by overwriting first</b>
$ shred -n 2 -z -v /tmp/myImportantSecret  # -n 2: Overwrite twice with random data
                                           # finally write over with zeroes (-z)
                                           # -v: Show progress

<a href="https://linux.die.net/man/1/shred">shred</a> prevent data from being recovered by software (and most probably hardware)
</pre>

   <span xsmall>Hard/Soft Links</span>
<pre xxxsmall zoom>
In unix an "inode" is the low-level structure that stores the physical location in disk of
a given file. This "inode" is not visible to the user. 
The user visible entities are the file system paths, that point to the real inodes.

When a new file is created we have an structure similar to:

   /my/file/path  (points to)  → inode   (points to) →  physical_block_on_disk
   ^visible in              ^invisible to               ^managed by hard-disk
    user shells,             users, managed              internal circuitry
    GUI explorers,...        by the OS kernel            (or networks NAS)

* We can create <b>symbolic links</b> to a file_path, that are "sortcuts" to access
  a file_path from another file_path like (ln -s):
  
     $ ln -s /my/file/path   /my/newLocation/file/path/symLink
     
      This will leave and structure similar to:
     
        /my/file/path   →  inode   →  physical_block_on_disk
         ↑
         │
        /my/newLocation/file/path/symLink
     
     If the original /my/file/path is deleted or moved the links is broken.
  
  
* A hard-link can also be created pointing direcly to the inode, like (ln):
     $ ln /my/file/path   /my/newLocation/file/path2

      This will leave and structure similar to:
     
        /my/file/path   
                                    →  inode   →  physical_block_on_disk
        /my/newLocation/file/path2

The underlying inode will increase the number of references. The file data can be
accesses independently by the original /my/file/path or the new /my/newLocation/file/path2.
The inode (file) wil exists until all hardlinks or references are deleted.
</pre>
</td> 
<td> 
   <span xsmall>Searching files/data</span>
<pre xxxsmall zoom>
<b><a href="https://linux.die.net/man/1/find">find</a> files whose name ends in "html"</b>
Ex 1: "complex" find 
Command             |   Human explanation
(split into lines   |
 for readability)   |
------------------- +--------------------
$ find              |   let's display find results
   /var/lib         | ←     starting in this base directory and subdirectories
   -type f          | ← AND of type file (ignore directories, links, ...)
   -iname "*html"   | ← AND whose name matches *html (iname:ignore case, name: case sensitive)
   -mmin  -30       | ← AND whose modification time is 30 or less (-30) minutes (-mmin)
   -msize +20k      | ← AND whose size (msize) is 20kilobytes or more (+20)

Ex 2: find files and <b orange>for each found file execute</b> a <b blue>given command (grep ...)</b>
$ find 
   /var/lib
   -type f
   -iname "*html"
   <b orange>-exec</b> <b blue>grep "myStyleSheet.css"</b> <b orange>{} \;</b>
</pre>

  <span xsmall>Check disk free/used space:</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/0/df">man 1 df</a> 
$ df -kh  # Check free space

<a href="https://linux.die.net/man/1/du">man 1 du</a>
$ du -sch dir1 dir2  # check "d"isk "u"ssage of dir1 dir2
</pre>
  
  <span xsmall>Graphical tools:</span>
<pre xxxsmall zoom>
"Graphical Console" (ncurses)
mc     : (Midnight Commander) Linux version of Norton Comander
rancher: Light and Nice Console File Manager with VI Key Bindings
</pre>

</td>
<td>
  <span xsmall>Monitor files open:</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/8/lsof">man 8 lsof</a>
# list files open by process "pID"
$ sudo lsof -p <b orange>511</b> #
(output can be similar ...)
COMMAND   <b orange>PID</b>  USER   FD      TYPE     DEVICE SIZE/OFF    NODE NAME
avahi-dae <b orange>511</b> avahi  cwd       DIR        8,1       67 1274283 /etc/avahi
avahi-dae <b orange>511</b> avahi  rtd       DIR        8,1       67 1274283 /etc/avahi
avahi-dae <b orange>511</b> avahi  txt       REG        8,1   136264 2568376 /usr/sbin/avahi-daemon
avahi-dae <b orange>511</b> avahi  DEL       REG        8,1          1713236 /usr/lib64/libnss_sss.so.2;5ae2fcc0
avahi-dae <b orange>511</b> avahi  DEL       REG        8,1          1390813 /usr/lib64/...
avahi-dae <b orange>511</b> avahi    0r      CHR        1,3      0t0    1028 /dev/null
avahi-dae <b orange>511</b> avahi    1u     unix 0xff222c00      0t0   20500 socket
avahi-dae <b orange>511</b> avahi    3u     unix 0xffb84400      0t0   18699 /var/run/avahi-daemon/socket
avahi-dae <b orange>511</b> avahi    7w     FIFO        0,8      0t0   20324 pipe
avahi-dae <b orange>511</b> avahi   11r  a_inode        0,9        0    7017 inotify
avahi-dae <b orange>511</b> avahi   12u     IPv4      21553      0t0     UDP *:mdns
avahi-dae <b orange>511</b> avahi   13u     IPv4      21554      0t0     UDP *:44720
avahi-dae <b orange>511</b> avahi   14u  netlink                 0t0   21555 ROUTE
...

# list processes using any file in etc
$ sudo lsof <b orange>/etc/*</b>
(output can be similar ...)
COMMAND     PID      USER   FD   TYPE DEVICE SIZE/OFF      NODE NAME
avahi-dae   511     avahi  cwd    DIR    8,1       67 101274283 <b orange>/etc/</b>avahi
avahi-dae   511     avahi  rtd    DIR    8,1       67 101274283 <b orange>/etc/</b>avahi
java      41043 azureuser  296r   REG    8,1      393       154 <b orange>/etc/</b>os-release
java      41043 azureuser  297r   REG    8,1      393       154 <b orange>/etc/</b>os-release
</pre>

  <span xsmall>Monitor file/dir. access</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/inotifywait">man 1 inotifywait</a>: Wait for changes, then execute someCommand
while  true ; do
    inotifywait -q -e modify fileToMonitor1 fileToMonitor2 ... ;  someCommandToExecute ; done
done

<a TODO href="https://linux.die.net/man/1/inotifywatch">man 1 inotifywatch</a>: gather filesystem access statistics
</pre>

   <span xsmall>file last access/exec</span>
<pre xxxsmall zoom>
(basic audit)
$ stat myFile.txt   
    File: myFile.txt
    Size: 5557            
  Blocks: 16
IO Block: 4096   regular file
  Device: 800h/2048d      
   Inode: 1554743
   Links: 1
  Access: (0644/-rw-r--r--)
     Uid: ( 1000/ earizon)
     Gid: ( 1000/ earizon)
  <b>Access: 2018-09-12 14:31:06.882431359 +0000</b>
  <b>Modify: 2018-08-29 16:15:31.000000000 +0000</b>
  <b>Change: 2018-09-12 14:31:06.882431359 +0000</b>
 Birth: -

For an executable access will show when it was last executed
</pre>

</td>
<td colsep></td>
<td colsep>Block&nbsp;Storage</td>
<td>
  <span xsmall>List block devices</span>
<pre xxxsmall zoom>
[root@localhost earizon]# lsblk
NAME            MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda               8:0    0 223.6G  0 disk
├─sda1            8:1    0     1G  0 part /boot
└─sda2            8:2    0 222.6G  0 part
  ├─fedora-root 253:0    0    50G  0 lvm  /
  ├─fedora-swap 253:1    0   7.8G  0 lvm  [SWAP]
  └─fedora-home 253:2    0 164.8G  0 lvm  /home
sdb               8:16   0 931.5G  0 disk
└─sdb1            8:17   0 931.5G  0 part /mount/disk01
sdd               8:48   0 465.7G  0 disk
└─sdd1            8:49   0 465.7G  0 part
mmcblk0         179:0    0  29.7G  0 disk
└─mmcblk0p1     179:1    0  29.7G  0 part /run/media/myUser/C852-6915
</pre>


  <span xsmall>annotated <code>/etc/fstab</code></span>
<pre xxxsmall zoom>
  $ cat /etc/fstab | nl -
→ 1 /dev/mapper/fedora-root                        /               ext4   defaults          1 1
→ 2 UUID=735acb4c-29bc-4ce7-81d9-83b778f6fc81      /boot           ext4   defaults          1 2
→ 3 LABEL=backups                                  /mnt/backups    xfs    defaults          1 2
→ 4 /dev/mapper/fedora-home                        /home           ext4   defaults          1 2
→ 5 /dev/mapper/fedora-swap                        swap            swap   defaults          0 0
→ 6 PARTUUID=8C208C30-4E8F-4096-ACF9-858959BABBAA  /mnt/ddbb       xfs    defaults          1 2
→ 6 "some network attached device"                 /var/.../       xfs    defaults,nofail*3 1 2
    └───────────────────┬───────────────────┘      └─────┬────┘   └──┬──┘ └───┬───┘         │ │
                        ↓                                ↓           ↓        ↓             │ │
       partition device (dev/...),                 mount point in   FS    CSV mount options │ │
       partition Universal Unique ID (UUID) or     FS tree hierchy  type  for the FS type.  │ │
       partition LABEL  or PARTUUID (GPT)                                 Different FSs can │ │
       identifies the partition.                                          have different    │ │
       UUID *2 are prefered to /dev/sd...                                 mount opts. plus  │ │
       like /dev/sdb3 since the device name                               common ones to    │ │
       can change for USB or plugable devices                             all FS *1         │ │
                                                                                            │ │
           this flag determines the                                                         │ │
           FS check order during boot:                   used by dump(8) to determine ←─────┘ │
           (0 disables the check)                        which ext2/3 FS need backup          │
           - root (/)  should be 1                       (default to 0)                       │
           - Other FSs should be 2                                                            │
                         ↑                                                                    │ 
                         └────────────────────────────────────────────────────────────────────┘ 
   
*1 defaults mount options common to all File System types: 
   rw     : Read/write vs 'ro' (read only)
   suid   : Allow set-user-ID | set-group-ID bits (nosuid: Ignore them)
   dev    : Interpret character or block special devices
   exec   : Permit execution of binaries
   auto   :
   nouser : Do NOT allow ordinary user to mount the filesystem.
   async  : Do not force synchronous I/O to file system.
            (WARN: sync may cause life-cycle shortening in flash drives)
   
    
    
*2 Next command list the UUIDs of partitions:
     $ blkid
   → /dev/sda1: LABEL="storage" UUID="60e97193-e9b2-495f-8db1-651f3a87d455" TYPE="ext4" 
   → /dev/sda2: LABEL="oldhome" UUID="e6494a9b-5fb6-4c35-ad4c-86e223040a70" TYPE="ext4" 
   → /dev/sdb1:                 UUID="db691ba8-bb5e-403f-afa3-2d758e06587a" TYPE="xfs" PARTUUID="788369ae-01"
                                ^^^^ 
                                tags the filesystem actually (vs the partition itself)

*3 <a TODO href="https://unix.stackexchange.com/questions/53456/what-is-the-difference-between-nobootwait-and-nofail-in-fstab">REF</a>
- nofail:  allows the boot sequence to continue even if the drive fails to mount.
           On cloud systems it ussually allows for ssh access in case of failure
</pre>

<a href="https://en.wikipedia.org/wiki/Device_mapper">Device mapper</a>

<pre xxxsmall zoom>
device mapper: kernel framework mapping virtual block devices to 
               one (or more) physical block device (with the posibility
               to process&amp;filter in/out data)

<b>DEVICE-MAPPER ARCHITECTURE:</b>
<b>
 MAPPED DEVICE               │           MAPPING TABLE              │ TARGET DEVICE</b>
 (LOGICAL DRIVE)             │                                      │ PLUGIN (INSTANCE/s)
                             │                                      │
 logical device provided by  │ entry1:                              │ - filters
 device-mapper driver.       │ mapped-device1    ←→ target-device1  │ - access physical devices
 It provides an interface to │ └─ start address   └┬─ start address │ 
 operate on.                 │                     └─ sector-length │ 
                             │ entry2:                              │ Example plugins:
 Ex:                         │ mapped-device2    ←→ target-device2  │ - mirror for RAID
 - LVM2 logical volumes      │ └─ start address   └┬─ start address │ - linear   for LVM2 
 - dm-multipath pseudo-disks │                     └─ sector-length │ - stripped for LVM2
 - "docker images"           │ entry3:                ^^^^^^^^^^^^^ │ - snapshot for LVM2
                             │ ....                   1sector = 512 │ - dm-multipath
                             │                                 bytes│
                             │  NOTE: 1 sector = 512 bytes          │

<b>DATA FLOW:</b>
                                         
App → (Data) → MAPPED DEVICE →          DEVICE MAPPER               →  TARGET-DEVICE     → Physical 
                                        Route to target                PLUGIN instance     Block Device
                                        based on:       
                                        - MAPPED-DEVICE 
                                        - MAPPING-TABLE                

- Data can be also modified in transition, which is performed, for example,
  in the case of device mapper providing disk encryption or simulation of
  unreliable hardware behavior.


<b>Features</b>
- The device mapper "touch" various layers of the Linux kernel's storage stack.

- Functions provided by the device mapper include linear, striped and error mappings,
  as well as crypt and multipath targets.

Exs.:
  - Two disks may be concatenated into one logical volume with a pair
    of linear mappings, one for each disk.

  - crypt target encrypts the data passing through the specified device,
    by using the Linux kernel's Crypto API.

<b>available mapping targets</b>
 - cache    : allows creation of hybrid volumes, by using solid-state drives 
              (SSDs) as caches for hard disk drives (HDDs)
 - crypt    : provides data encryption, by using kernel Crypto API
 - delay    : delays reads and/or writes to different devices (testing)
 - era      : behaves in a way similar to the linear target, while it keeps 
              track of blocks that were written to within a user-defined
              period of time
 - error    : simulates I/O errors for all mapped blocks      (testing)
 - flakey   : simulates periodic unreliable behaviour         (testing)
 - linear   : maps a continuous range of blocks onto another block device
 - mirror   : maps a mirrored logical device, while providing data redundancy
 - multipath: supports the mapping of multipathed devices, through usage of 
              their path groups
 - raid     : offers an interface to Linux kernel's software RAID driver (md)
 - snapshot : (and snapshot-origin) used for creation of LVM snapshots,
              as part of the underlying copy-on-write scheme
 - striped  : stripes the data across physical devices, with the number of
              stripes and the striping chunk size as parameters
 - thin     : allows creation of devices larger than the underlying 
              physical device, physical space is allocated only when
              written to
 - zero     : equivalent of /dev/zero, all reads return blocks of zeros,
              and writes are discarded

<b>kernel features and projects are built on top</b>
Note: user-space apps talk to the device mapper via <b>libdevmapper.so</b>
  which in turn issues ioctls to the /dev/mapper/control device node.

  - cryptsetup    : utility to setup disk encryption based on dm-crypt
  - dm-crypt/LUKS : mapping target providing volume encryption
  - dm-cache      : mapping target providing creation of hybrid volumes
  - dm-integrity  : mapping target providing data integrity, either
                    using checksumming or cryptographic verification,
                    also used with LUKS
  - dm-log-writes : mapping target that uses two devices, passing through
                    the first device and logging the write operations performed
                    to it on the second device
  - dm-verity     : validates the data blocks contained in a file system
                    against a list of cryptographic hash values, developed as 
                    part of the Chromium OS project
  - dmraid(8)     : provides access to "fake" RAID configurations via the 
                    device mapper
  - DM Multipath  : provides I/O failover and load-balancing of block devices
                    within the Linux kernel

                    - allows to configure multiple I/O paths between server nodes 
                      and storage arrays(separate cables|switches|controllers) 
                      into a single mapped/logical device.
                    
                    - Multipathing aggregates the I/O paths, creating a new device
                      that consists of the aggregated paths.


  - Docker        : uses device mapper to create copy-on-write storage for
                    software containers

  - DRBD          : Distributed Replicated Block Device

  - kpartx(8)     : utility called from hotplug upon device maps creation and deletion

  - LVM2          : logical volume manager for the Linux kernel

  - Linux version of TrueCrypt

  <a href="https://linux.die.net/man/8/dmsetup">man 8 dmsetup</a>

dmsetup — low level logical volume management

SYNOPSIS
  dmsetup clear device_name
  dmsetup create device_name [-u|--uuid uuid] [--addnodeoncreate|--addnodeonresume] [-n|--notable|--table {table|table_file}] [--readahead
           {[+]sectors|auto|none}]
  dmsetup deps [-o options] [device_name]
  dmsetup help [-c|-C|--columns]
  dmsetup info [device_name]
  dmsetup info -c|-C|--columns [--count count] [--interval seconds] [--nameprefixes] [--noheadings] 
               [-o fields] [-O|--sort sort_fields] [--sepa‐rator separator] [device_name]
  dmsetup load device_name [--table {table|table_file}]
  dmsetup ls [--target target_type] [--exec command] [--tree] [-o options]
  dmsetup mangle [device_name]
  dmsetup message device_name sector message
  dmsetup mknodes [device_name]
  dmsetup reload device_name [--table {table|table_file}]
  dmsetup remove [-f|--force] [--retry] [--deferred] device_name
  dmsetup remove_all [-f|--force] [--deferred]
  dmsetup rename device_name new_name
  dmsetup rename device_name --setuuid uuid
  dmsetup resume device_name [--addnodeoncreate|--addnodeonresume] [--noflush] [--nolockfs] [--readahead {[+]sectors|auto|none}]
  dmsetup setgeometry device_name cyl head sect start
  dmsetup splitname device_name [subsystem]
  dmsetup stats command [options]
  dmsetup status [--target target_type] [--noflush] [device_name]
  dmsetup suspend [--nolockfs] [--noflush] device_name
  dmsetup table [--target target_type] [--showkeys] [device_name]
  dmsetup targets
  dmsetup udevcomplete cookie
  dmsetup udevcomplete_all [age_in_minutes]
  dmsetup udevcookie
  dmsetup udevcreatecookie
  dmsetup udevflags cookie
  dmsetup udevreleasecookie [cookie]
  dmsetup version
  dmsetup wait [--noflush] device_name [event_nr]
  dmsetup wipe_table device_name [-f|--force] [--noflush] [--nolockfs]

  devmap_name major minor
  devmap_name major:minor
</pre>
  MBR vs GPT
<pre xxxsmall zoom>
MASTER BOOT RECORD (MBR, OLD 80'S MS-DOS)          | GPT/GUID:
- Designed when HD were  tens of megabytes.        | - Suported by Linux GRUB 2 and GParted
- First 512 bytes of disk                          | - Globally Unique Identifiers Partition Table
  - 446 Bytes bootloader                           | - Part of UEFI specs
  -  64 Partition table                            | - Linux can use it with UEFI or legacy BIOS
  -   2 boot signature                             | - no more primary/logical partitions.
- limited to 4 primary partitions                  | - 64-bit disk pointers allows 264 total sectors:
  - A single primary partition can hold an         |   - 512-byte blocks allows for 8 zebibytes.
    extended partition with unlimited logical      | - fault-tolerance: partition table in first, last 
    partitions.                                    |   sector of disk
- original addressing: cylinders, heads, sectors.  | - cyclic redundancy check (CRC) checksum to verify 
  - 2TB max size ( 512bytes block)                 |   its own integrity, and of the partition table
  -16TB max size (4099bytes block) with LBA hack   | - Unique IDs for disks and partitions.
                                                   | NOTE:  GPT-GUIDs identifies disk tables
                                                   |            UUIDs identifies filesystems  (blkid)
                                                   |
                                                   | # <b>gdisk /dev/sdc</b>
                                                   | → GPT fdisk (gdisk) version 0.8.1
                                                   | → Partition table scan:
                                                   | →   MBR: protective    
                                                   | →   BSD: not present   
                                                   | →   APM: not present   
                                                   | →   GPT: <b>present</b>
                                                   | → Found valid GPT with protective MBR; using GPT.
                                                   | → Command (? for help): (press <b>"p"</b> key)
                                                   |   → Disk /dev/sdc: 3907029168 sectors, 1.8 TiB
                                                   |   → Logical sector size: 512 bytes   ← 4096 physical in new diskss
                                                   |   → Disk identifier (GUID): <b>058D39EE-5D06-409F-AA0C-298A3E6CC302</b>
                                                   |   → Partition table holds up to 128 entries
                                                   |   → First usable sector is 34, last usable sector is 3907029134
                                                   |   → Partitions will be aligned on 2048-sector boundaries
                                                   |   → Total free space is 819142765 sectors (390.6 GiB)
                                                   |   → NUMBER  START (SECTOR)    END (SECTOR)  SIZE       CODE  NAME
                                                   |   →    1            2048         1953791   953.0 MiB   0700  
                                                   |   →    2         1953792        80078847    37.3 GiB   0700  
                                                   |   → ...
</pre>
</td>
<td colsep></td>
<td colsep>LVM</td>
<td>
 <span xsmall>(Logic.Vol.Mgr)</span>:
 <hr xxxsmall />
 <span xsmall>LVM Diagram</span>:
<pre xxxsmall zoom bgorange>
 physical drive 1                                     logical-volume 1
 physical drive 2    N <-> 1    Volume-Group 1 <-> M  logical-volume 2
 physical drive 3                                     logical-volume 3
 ...                                                  ...
                     ^^^^^^^                 ^^^^^^^ 
                     The Vol.Group           The Vol.Group
                     acts as a logical       allows to dynamically
                     pool of physical        create logical volumes
                     devices                 isolated from the physical
                                             resources
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
                     The Volume-Group acts as a relation
                     N-to-M between physical resources
                     and logical partitions

Quick Sumary:
    CREATE       → ADD Physical drives → Add logical-volumes
    VOLUME-GROUP   to VOLUME-GROUP       to VOLUME-GROUP.
                                         ^^^^^^^^^^^^^^^^^^
                                         logical-volumes can map to:
                                         - company deparments
                                         - test/pre/pro enviroment
                                         - ...
</pre>

 <span xsmall>"Full-Journey" SETUP</span>:
<pre xxxsmall zoom>
WARN: You need LVM tools installed. Mount alone is not able to mount LVM volumes

<a href="https://opensource.com/article/18/11/manage-storage-lvm">REF</a>


<b>PRE-SETUP:</b>
Format a <b brown>physical drive /dev/sdx</b> to be included on the pool
# dd if=/dev/zero of=<b orange>/dev/sdx</b> count=8196
# parted /dev/sdx print | grep Disk
Disk /dev/sdx: 100GB
# parted /dev/sdx mklabel gpt
# parted /dev/sdx mkpart primary 1s 100%

Note: Volume-group is synonym of "physical-storage pool"

<b>STEP 1: Create an LVM pool (and add a first physical disk to it)</b>
NOTE: Usually, you don't have to set up LVM at all since most distros 
     defaults to creating a virtual "pool" of storage and adding your
     machine's hard drive(s) to that pool.

# vgcreate volgroup01 /dev/sdx1  # ← create new storage pool and
                                      aggregate disk-partition 


<b>STEP 2: Create logical-volumes</b>
# lvcreate volgroup01 49G --name vol0  # ← create logical-volume /dev/volgroup01/vol0
# lvcreate volgroup01 49G --name vol1  # ← create logical-volume /dev/volgroup01/vol1


<b>STEP 4: Switch volume-group online</b>
# vgchange --activate y volgroup01

<b>STEP 5: make the file systems</b>
# mkfs.ext4 -L finance    /dev/volgroup01/vol0
# mkfs.ext4 -L production /dev/volgroup01/vol1
            ^^^^^^^^^^^^^ 
            label the drive
            In this case a logical-volume is used by department

<b>STEP 6: Mount the volumes</b>
# mount /dev/volgroup01/vol0 /mnt/vol0
# mount /dev/volgroup01/vol1 /mnt/vol1

<b>STEP 7: Adding space to the volume-group</b>
# part /dev/sdy mkpart primary 1s 100%  # ← create partition on new physical-disk
# vgextend volgroup01 /dev/sdy1         # ← aggregate to volgroup01 
# lvextend -L +49G /dev/volgroup01/vol0 # ← Extend the already-existing logical-volume
</pre>

  <span xsmall>Show LVM layout</span>
<pre xxxsmall zoom>
<b>vgdisplay</b> shows info about volume groups: 
# vgdisplay
  --- Volume group ---
  VG Name               volgroup01
  System ID            
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  4
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                3
  Open LV               3
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               <237.47 GiB
  PE Size               4.00 MiB
  Total PE              60792
  Alloc PE / Size       60792 / <237.47 GiB
  Free  PE / Size       0 / 0  
  VG UUID               j5RlhN-Co4Q-7d99-eM3K-G77R-eDJO-nMR9Yg

<b>lvdisplay</b> shows info about logical volumes: 

# lvdisplay
  --- Logical volume ---
  LV Path                /dev/volgroup01/finance
  LV Name                finance
  VG Name                volgroup01
  LV UUID                qPgRhr-s0rS-YJHK-0Cl3-5MME-87OJ-vjjYRT
  LV Write Access        read/write
  LV Creation host, time localhost, 2018-12-16 07:31:01 +1300
  LV Status              available
  # open                 1
  LV Size                149.68 GiB
  Current LE             46511
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:3

[...]
</pre>
</td>
<td>
<span xsmall>Show PVs,VGs,LVs</span>
<pre xxxsmall zoom>
<b># pvs # ← Physical Volumes</b>
  PV         VG     Fmt  Attr PSize    PFree
  <b orange>/dev/sda2</b>  fedora lvm2 a--  <222.57g    0



<b># vgs # ← Volume Groups </b>
  VG     #PV #LV #SN Attr   VSize    VFree
  <b orange>fedora</b>   1   3   0 wz--n- <222.57g    0
<b># lvs # ← Logical Volumes</b> 
  LV   VG     Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  <b orange>home</b> fedora -wi-ao---- <164.82g
  <b orange>root</b> fedora -wi-ao----   50.00g
  <b orange>swap</b> fedora -wi-ao----    7.75g
</pre>

  <span xsmall>Mount in rescue-mode</span>
<pre xxxsmall zoom>
PRE-SETUP:
- the LVM toolchain must ready for use in the rescue-mode environment.
   (/usr/sbin directory mounted or similar)

STEPS:
# vgchange --activate y
(output will be similar to)
→ 2 logical volume(s) in volume group "volgroup01" now active
# mkdir /mnt/finance
# mount /dev/volgroup01/finance /mnt/finance
</pre>


  <span xsmall>LVM + LUKS encryption</span>
<pre xxxsmall zoom>
- LUKS stands for Linux-Unified-Key-Setup encryption toolchain.
- LVM  integrates nicely with disk encryption

LUKS encrypts full-partitions (vs files  in GnuPG, ...)

NOTICE/WARN: LUKS will prompts for a password during boot.
             (server-autoboot will fail)


<b>STEP 1: format the partition with the "cryptsetup" command</b>
# cryptsetup luksFormat /dev/sdx1
→ LUKS will warn that it's going to erase your drive: (Accept to continue)
→ A prompt will ask for a passphrase: (Enter it to continue)

The partition is encrypted at this point but no filesystem is in yet:
- In order to partition it you must un-lock it.

# cryptsetup luksOpen /dev/sdx1 mySafeDrive # ← Unlock before formating it.
                                ^^^^^^^^^^^ 
                                human-friendly name
                                will create a symlink
                                /dev/mapper/mySafeDrive
                                to auto-generated designator

→ LUKS will ask for the passphrase to un-lock the drive: (Enter it to continue)

- Check the volume is "OK":
# ls -ld /dev/mapper/mySafeDrive
→ lrwxrwxrwx. 1 root root 7 Oct 24 03:58 /dev/mapper/mySafeDrive -> ../dm-4

<b>STEP 2: format with standard-filesystem (ext4,...)</b>
# mkfs.ext4 -o Linux -L mySafeExt4Drive /dev/mapper/mySafeDrive

<b>STEP 3: Mount the unit</b>
# mount /dev/mapper/mySafeExt4Drive /mnt/hd
</pre>

  <span xsmall>Increase LV Size</span>
<pre xxxsmall zoom>
<b>STEP 1: Mark physical disk partition as LVM:</b>
# fdisk -cu /dev/sdd   # ← cfdisk offers a visual ncurses alt. to fdisk
→ new partition ("n")
  → primary partition ("p")
    → Enter partition number (1-4)
      → Change type ("t") to Linux LVM  ("8e")
        → Check status ("p")
          → Write changes ("c")


<b>STEP 2: create new PV (Physical Volume)</b>
# pvcreate /dev/sdd1
  → Verify the pv:
    # pvs

<b>STEP 3: Extending Volume-Group</b>
# vgextend vg_tecmint /dev/sdd1
  → Verify it:
  # vgs


<b>STEP 4: Increar Logical Volume Size</b>
4.1: Check available free space in volume-group:
# vgdisplay | grep -i "Free"
 → Free  PE / Size       4607 / 18GB  
                         ^^^^^^^^^^^  
                         max size a logical volume
                         can be extended to.

4.2: Extend the volume:
# lvextend -l +4607 /dev/vg_tecmint/LogVol01
              ^
              Use '+' to add the more space.

4.3: Check changes:
# lvdisplay

<b>STEP 5: re-size the file-system</b>
# resize2fs /dev/vg_tecmint/LogVol01
</pre>
</td>

<td colsep></td>
<td colsep>File&nbsp;Systems</td>
<td>
  EXT4
<pre xxxsmall zoom>
Features:
- metadata and journal checksums.
- timestamps intervals down to nanoseconds.
- EXT4 extents: described by its starting and ending place on the hard drive.
  EXT4-Extents make possible to describe very long, physically contiguous files in 
  a single inode pointer entry significantly reducing the number of pointers in large files.
- New anti-fragmentation algorithms.
</pre>

Checks error|fragmentation:
<pre xxxsmall zoom>
(ussually it must be really low in EXT"N" filesystems):
WARN: Be sure to use the -n flag, preventing fsck to take any action on the file-system

# fsck -fn /dev/sda
→ ...
→ ...
/dev/sda: 613676/3040000 files (<b>0.3% non-contiguous</b>), 6838740/12451840 blocks
</pre>

  Journal
<pre xxxsmall zoom>
- for performance reasons, we do not want to write or sync every change to ext4.
- If the system crashes meanwhile, the changes that are not written to ext4 will
  be lost if Journal is not enabled.
- Every write/sync operation is written to Journal first (not to ext4 first)
  and it is finalized later (written to ext4 later). If the system crashes,
  during recovery, probably on the next boot, Journal is replied back to ext4
  so changes are applied and not lost.

Journal can be used in three different modes (mount option):

  - journal:   All data (both metadata and actual data) is written to Journal first, so the safest.
  - ordered:   This is the default mode. All data is sent to ext4, metadata is sent to Journal also.
               No protection for data but metadata is protected for crash.
  - writeback: Data can be written to ext4 before or after being written to Journal. 
               On a crash, new data may get lost.

The information / blocks is written to Journal following next sequence:

 1.- A Descriptor Block is written, containing the information about the
     final locations of this operation.
 2.- A Data Block is written.(real data or meta data)
 3.- A Commit Block is written. After this, the data can be sent to ext4.
     (Alternatively a Revocation Block will cancel)
     If commit-block is not found, when a replay happens (crash-recovery, ...),
     data will not be written to ext4.
</pre>

 Tunning performance
<pre xxxsmall zoom>
<a href="https://www.kernel.org/doc/Documentation/filesystems/ext4.txt">REF: Kernel.org doc</a>
   Contains full list of mount opts, /proc&amp;/sys entries

Mount options:
journal_async_commit    Commit block can be written to disk without waiting
            for descriptor blocks. If enabled older kernels cannot
            mount the device. This will enable 'journal_checksum'
            internally.


commit=nrsec    (*) Ext4 can be told to sync all its data and metadata
            every 'nrsec' seconds. The default value is 5 seconds.
            This means that if you lose your power, you will lose
            as much as the latest 5 seconds of work (your
            filesystem will not be damaged though, thanks to the
            journaling).  This default value (or any low value)
            will hurt performance, but it's good for data-safety.
            Setting it to 0 will have the same effect as leaving
            it at the default (5 seconds).
            Setting it to very large values will improve
            performance.

inode_readahead_blks=n  This tuning parameter controls the maximum
            number of inode table blocks that ext4's inode
            table readahead algorithm will pre-read into
            the buffer cache.  The default value is 32 blocks.

stripe=n    Number of filesystem blocks that mballoc will try
            to use for allocation size and alignment. For RAID5/6
            systems this should be the number of data
            disks *  RAID chunk size in file system blocks.

min_batch_time=usec This parameter sets the commit time (as
            described above) to be at least min_batch_time.
            It defaults to zero microseconds.  Increasing
            this parameter may improve the throughput of
            multi-threaded, synchronous workloads on very
            fast disks, at the cost of increasing latency.
</pre>
</td>
<td>
  <span TODO>XFS</span>
<pre xxxsmall zoom>
https://www.systutorials.com/docs/linux/man/8-xfs_admin/

SEE ALSO
mkfs.xfs(8), mount(8), xfs_db(8), xfs_growfs(8), xfs_repair(8), xfs(5). 
</pre>


</td>

<td>
  <a TODO href="https://opensource.com/article/18/4/stratis-lessons-learned">Stratis (by RedHat)</a>
  <a xxsmall href="https://stratis-storage.github.io/StratisSoftwareDesign.pdf">REF Design(PDF)</a>
  <br/>
</td>
<td colsep></td>
<td colsep>Encrypt.</td>
<td>
  Storage encryption 
  <ul xxxsmall>
  <li>can be performed at the file system level or the block level.</li>
  <li>Linux file system encryption options include eCryptfs and EncFS, while 
    FreeBSD uses PEFS.</li>
  <li>Block level or full disk encryption options include dm-crypt + LUKS on 
    Linux and GEOM modules geli and gbde on FreeBSD.</li>
  </ul>
  <hr xxxsmall />
  <a href="https://www.veracrypt.fr/en/Home.html">VeraCrypt</a>
<pre xxxsmall zoom>
  free open source disk encryption software for Windows/OSX/Linux.
  <a href="https://www.idrix.fr">Developed by IDRIX</a>, based on
  TrueCrypt 7.1a. main features:
  - Creates virtual encrypted disk within a file and mounts
    it as a real disk.
  - Encrypts entire partition or storage device
  - Encrypts a partition or drive where Windows is installed
    (pre-boot authentication).
  - Encryption is automatic, real-time(on-the-fly) and transparent.
  - Parallelization and pipelining allow data to be read
    and written as fast as if the drive was not encrypted.
  - Encryption can be hardware-accelerated on modern processors.
  - Provides plausible deniability, in case an adversary forces 
    you to reveal the password: Hidden volume (steganography)
    and hidden operating system.
</pre>
</td>

</tr>
</table>
<br/><br/>
<table>
<tr>
<td colsep>kernel&nbsp;monit</td>
<td>
  Monitoring Diagram
<pre xxxsmall zoom bgorange>
  ↑        ┌───────────────────────────────────────────────────────────────────┐
  │        │                    APPLICATIONS                                   |
  │        ├───────────────────────────────────────────────────────────────────┤
  │        │[ltrace][ldd]      System Libraries [gethostlatency]         [perf]│
  │        ├───────────────────────────────────────────────────────────────────┤
  │        │[strace][sydgid]     System Call Interface [*3]              [perf]|     CPU
[perf]   ↑ ├─────────────────┬───────┬──────────────┬───────┬──────────────────┤Interconnect  ┌──────────┐
[dtrace] │ │ VFS             │       │SOCKETS  [ss] │       │SCHEDULER   [perf]├──────────────┤CPU1[perf]├───┐
[stap]  L K├─────────────────┤       │──────────────┤       │[perf][latencytop] ←───[top]     └──────────┘   │
[lttnp] I E│ FILE SYSTEMS    │       │TCP/UPD  [*2] │       │[mpstat]          │  ╱[ps]      Memory│         │
[ktap]  N R├─────────────────┤       │──────────────┤       ├──────────────────┤ ╱ [pidstat]    BUS│  [perf] │
  │     U N│ VOLUME MANAGERS │       │IP            │       │VIRTUAL MEMORY    │╱                  │         │
  │     X E├─────────────────┤       │[ip]          │       │[vmstat]          ←                 ┌───┐       │
  │       L│ BLOCK DEVICE    │       │[route]       │       │[slabtop]         ├────────────────→│RAM│       │
  │      │ │ Interface       │       │[iptables]    │       │[free]            │                 └───┘       │
  │      │ │ [*1] [pidstat]  │       │              │       │[memleak]         │                 [numastat]  │
  │      │ │                 │       │              │       │[comkill]         │                 [lstopop]   │
  │      │ │                 │       │              │       │[slabratetop]     │                             │
  │      │ │                 │       │──────────────│       ├──────────────────┤                             │
  │      │ │                 │       │Ethernet [ss] │       │CLOCKSOURCE       │                             │
  │      │ │                 │       │[tcpdump]     │       │[/sys/...]        │                             │
  │      │ ├─────────────────┴───────┴──────────────┴───────┴──────────────────┤                             │
  │      │ │                       Device Drivers                              │                             │
  ↓      ↓ └───────────────────────────────────────────────────────────────────┘             I/O [perf]      │
                           Expander-Interconnect                           ┌──────────┐     BUS  [tiptop]    │
                   ─┬────────────────────────────────────────┬─────────────┤I/O Bridge├──────────────────────┘
                    │                                        │             └──────────┘
                    │                                        │            
              ┌─────┴───────────┐                    ┌───────┴───────────┐[nicstat]     
              │I/O Controller *1│                    │ Network Controller│[ss]
              └─────────────────┘                    └───────────────────┘[ip]
             ┬──────┴───────┬                         ┬──────┴────┬      
             │              │                         │           │
            Disk[*1]       Swap [swapon]             Port        Port 
                                                     [ping] [traceroute]
                                                     [ethtool] [snmpget]
                                                     [lldptool] 
           
*1: [iostat] [iotop] [blktrace]
*2: [tcptop] [tcplife] [tcpconnect] [tcpaccept] [tcpconnlat] [tcpretrans]
*3: [opensnoop] [statsnoop] [syncsnoop]

OTHERS: [sar] [dstat] [/proc]

 ┌───┐[sar -m FAN]       ┌────────────┐[ipmitool]
 │FAN│                   │POWER SUPPLY│[dmidecode]
 └───┘                   └────────────┘


</pre>

<a TODO href="http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html">Tracer comparative</a>
</td>
<td>
  <span xsmall>ltrace: Library Call Tracer</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/ltrace">man 1 ltrace</a>
Summary:<b>
ltrace                           | ltrace -c  # ← Count time and calls for each library call
                                                   and report a summary on program exit.</b>
  [-e filter|-L]                 |   [-e filter|-L] 
  [-l|--library=library_pattern] |   [-l|--library=library_pattern] 
  [-x filter]                    |   [-x filter] 
  [-S]                           |   [-S] 
  [-b|--no-signals]              |   
  [-i] [-w|--where=nr]           |   
  [-r|-t|-tt|-ttt]               |   
  [-T]                           |   
  [-F pathlist]                  |
  [-A maxelts]                   |
  [-s strsize]                   |
  [-C|--demangle]                |
  [-a|--align column]            |
  [-n|--indent nr]               |
  [-o|--output filename]         |   [-o|--output filename] 
  [-D|--debug mask]              |
  [-u username]                  |
  [-f]                           |   [-f] 
  [-p pid]                       |   [-p pid] 
  [[--] command [arg ...]]       |   [[--] command [arg ...]]



runs the specified command until it exits, 
intercepting/recording:
   + dynamic library calls  by process
     - Display functions and funct.parameters.
     - external prototype libraries is needed 
       for human-readable output.
       (ltrace.conf(5), section PROTOTYPE LIBRARY DISCOVERY ) 

   + signals which received by process

   + system calls           by process



</pre>

  <span xsmall>strace: System call tracer</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/strace">man 1 strace</a>

SUMMARY
strace                    | strace -c  ← -c: Count time, calls, and errors 
                          |                  for each system call and report summary on exit.
                          |                  -f aggregate over all forked processes
  [ -dDffhiqrtttTvVxx ]   |   [ -D ] 
  [ -acolumn ]            |   
  [ -eexpr ] ...          |   [ -eexpr ] ... 
                          |   [ -Ooverhead ] 
  [ -ofile ]              |   
  [ -ppid ] ...           |   
  [ -sstrsize ]           |   
  [ -uusername ]          |
  [ -Evar=val ] ...       |
  [ -Evar ] ...           |   [ -Ssortby ] 
                          |   [ -Ssortby ] 
  [ command [ arg ... ] ] |   [ command [ arg ... ] ]


strace runs specified command until it exits intercepting:
  +  system calls called by a process
     - system-call-name + arguments + return-value is printed to STDERR (or -o file)
       Ex output:
       open("/dev/null", O_RDONLY) = 3
       open("/foo/bar", O_RDONLY) = -1 ENOENT (No such file or directory)
       
  +  signals    received by a process 
       Ex output:
       $ strace sleep 111
       → ...
       → sigsuspend([] <unfinished ...>
       → --- SIGINT (Interrupt) ---     ← Signal received
       → +++ killed by SIGINT +++

If a system call is being executed and meanwhile another one is being called 
from a different thread/process then strace will try to preserve the order
of those events and mark the ongoing call as being unfinished. 
When the call returns it will be marked as resumed. Ex. output:
  → [pid 28772] select(4, [3], NULL, NULL, NULL &lt;<b>unfinished ...&gt;</b>
  → [pid 28779] clock_gettime(CLOCK_REALTIME, {1130322148, 939977000}) = 0
  → [pid 28772] <b>&lt;... select resumed&gt;</b> )      = 1 (in [3])

Interruption of a (restartable) system call by a signal delivery is
processed differently as kernel terminates the system call and also 
arranges its immediate reexecution after the signal handler completes.

read(0, 0x7ffff72cf5cf, 1)              = ? <b>ERESTARTSYS (To be restarted)</b>
--- SIGALRM (Alarm clock) @ 0 (0) ---
rt_sigreturn(0xe)                       = 0
read(0, ""..., 1)                       = 0

</pre>
  
  <span xsmall>explain:decode error returned from strace</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/explain">man 1 explain</a>
</pre>

  <span xsmall>mpstat<br/>CPU stats <br/>(interr., hypervisor...)</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/mpstat">mpstat</a>
Sumary
mpstat 
  [ -A ]                        ==  -I ALL -u -P ALL 
  [ -I { SUM | CPU | ALL } ]    ==  Report interrupts statistics
  [ -u ]                            Reports cpu utilization (default)
  [ -P { cpu [,...] | ON | ALL } ]  Indicates the processor number
  [ -V ] 
  [ secs_interval [ count ] ]
    secs_interval = 0 => Report from times system startup (boot)

mpstat writes to standard output activities for each available processor, 
Global average activities among all processors are also reported. 


- CPU output columns: 
%usr   :  executing at the user level (application).
%nice  :  executing at the user level with nice priority.
%sys   :  executing at the system level (kernel).
          It does NOT include time spent servicing hardware 
          and software interrupts.
%iowait:  idle during which the system had an outstanding disk I/O request.
%irq   :  time spent by the CPU or CPUs to service hardware interrupts.
%soft  :  time spent by the CPU or CPUs to service software interrupts.<b>
%steal :  time spent in involuntary wait by the virtual CPU or CPUs
           while the hypervisor was servicing another virtual processor.</b>
%guest : time spent by the CPU or CPUs to run a virtual processor.
%idle  : time that the CPU or CPUs were idle and the system did not have
         an outstanding disk I/O request.
</pre>


  <span xsmall>pidstat: Linux task stats</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/pidstat">man 1 pidstat</a>
Summary

pidstat 
  [ -C comm ]       ← Display only tasks whose command name includes the string comm
  [ -d ]            ← Report I/O statistics 
  [ -h ] 
  [ -I ] 
  [ -l ] 
  [ -p { pid [,...] | SELF | ALL } ] 
  [ -r ]            ← Report page-faults and memory ussage
  [ -t ]            ← Also display stats for associated threads  
  [ -T { TASK | CHILD | ALL } ] 
  [ -u ] 
  [ -V ] 
  [ -w ] 
  [ secs_interval [ count ] ]

- monitor individual tasks.
- Dumps to STDOUT activities for every task selected    (-p) 
   or for every        task managed by the Linux kernel (-p ALL)
   or for every active task managed by the Linux kernel ("no -p")
</pre>
</td>
<td>
  <span xsmall>iostat<br/>
  stats on CPU, device I/O, FSs</span>
<pre xxxsmall zoom TODO>
<a href="https://linux.die.net/man/1/iostat">man 1 iostat<a>

</pre>
  <span xsmall>blktrace<br/>
  traces on block I/O traffic</span>
<pre xxxsmall zoom TODO>
<a href="https://linux.die.net/man/8/blktrace">man 8 blktrace</a>
</pre>
</td>
<td colsep> </td>
<td>
  <span bgorange>perf</span>
<pre xxxsmall zoom>
Performance counters for Linux are a new kernel-based subsystem
that provide a framework for all things performance analysis.

 It covers hardware level (CPU/PMU, Performance Monitoring Unit) 
features and software features (software counters, tracepoints) as well. 
</pre>

  <span xsmall bgorange>perf stat<br/>
  gather perf-counter stats</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-stat">man 1 perf-stat</a>
SUMMARY

perf stat 
     [--event=EVENT]  ← PMU event in the form:
                        - symbolic event name (perf list to list)
                        - raw PMU event (eventsel+umask) with format 
                          rNNN where NNN is an hexadecimal event descriptor 
     [--no-inherit]   ← child tasks do not inherit counters 
     [--all-cpus]
     [--pid=<pid>]    ← comma separated list of existing processes
     [--tid=<tid>]    ← comma separated list of existing thread id 
     [--scale]        ← scale/normalize counter values 
     [--repeat=<n>]   ← repeat command, print average + stddev (max: 100) 
     [--big-num]      ← print large numbers with thousands-local-separator
     [--cpu=]         ← comma separated list of cpus (All if not provided)
     [--no-aggr]      ← Do not aggregate counts across all monitored CPUs
                        in system-wide mode (-a). Only valid in system-wide mode. 
     [--null]         ← don't start any counters 
     [--verbose]      ← show counter open errors, etc,...
     [--field-separator SEP]
     [--cgroup name]  ← monitor only the container (cgroup) called "name".
                        - Only available in per-cpu mode. The cgroup filesystem
                        must be mounted. All threads belonging to container "name"
                        are monitored when they run on the monitored CPUs. 
                        - Multiple cgroups can be provided. Each cgroup is applied 
                        to the corresponding event, i.e., first cgroup to first event, 
                        - It is possible to provide an empty cgroup 
                          (monitor all the time) using, e.g., -G foo,,bar.
                        - Cgroups must have corresponding events, i.e., they always
                          refer to events defined earlier on the command line. 
     [--output file]
     [--append]
     [--log-fd]      ← append to given fd instead of stderr.
     (-)
     <command> [<options>]
     ^^^^^^^^^ 
     Any command you can specify in a shell. 

<b>example:</b></b>
$ perf stat - make -j
    Performance counter stats for 'make -j':

    8117.370256  task clock ticks     #      11.281 CPU utilization factor
            678  context switches     #       0.000 M/sec
            133  CPU migrations       #       0.000 M/sec
         235724  pagefaults           #       0.029 M/sec (page faults)
    24821162526  CPU cycles           #    3057.784 M/sec
    18687303457  instructions         #    2302.138 M/sec
      172158895  cache references     #      21.209 M/sec
       27075259  cache misses         #       3.335 M/sec

    Wall-clock time elapsed:   719.554352 msecs
</pre>

  <span xsmall>perf top<br/>
  real-time system profiling</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-top">man 1 perf-top</a>
</pre>
</td>
<td>
  <span xsmall>perf record<br/>
  record command's profile into perf.data</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-record">man 1 perf-record</a>
</pre>

  <span xsmall>perf report<br/>
  display recorded perf.data</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-report">man 1 perf-report</a>
</pre>

  <span xsmall>perf list<br/>
  List (sym.) event types</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-list">man 1 perf-list</a>
</pre>
</td>
<td>
  <span xsmall>perf bench<br/>
  General framework for bench.suites</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-bench">man 1 perf-bench</a>
</pre>

  <span xsmall bgorange>perf lock<br/>
  Analyze lock events</span>
<pre TODO xxxsmall zoom>
<a href="https://linux.die.net/man/1/perf-lock">man 1 perf-lock</a>
</pre>
</td>
<td colsep> </td>
<td>
  <span TODO>dtrace</span>
<pre xxxsmall zoom>
</pre>

  <span TODO>stap</span>
<pre xxxsmall zoom>
</pre>
  <span xsmall bgorange>(x)latencytop</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/8/xlatencytop">man 8 xlatencytop</a>

- aimed at:
  - identifying and visualizing where 
    (kernel and userspace) latencies are happening
  - What kind of operation/action is causing the latency


LatencyTOP focuses on the cases where the applications want to run
and execute useful code, but there's some resource that's not
currently available (and the kernel then blocks the process).

- This is done both on a system level and on a per process level,
  so that you can see what's happening to the system, and which 
  process is suffering and/or causing the delays.

Ussage:
$ sudo latencytop
- press "s" followed by a letter to display active processes
  starting with that lettter.
- press "s" followed by 0 to remove the filter
</pre>

  <span TODO>latrace</span>
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/latrace">man 1 latrace</a>

LD_AUDIT 2.4+ libc frontend
Synopsis

latrace [-ltfsbcCpADaoyIiBdvTFELVh] command [arg ... ]
Description

latrace is able to run a command and display its dynamic library calls using 
a LD_AUDIT libc feature (available from libc version 2.4 onward - see the 
section called "DISCUSSION" ). It is also capable to measure and display 
various statistics of dynamic calls.

If the config file is provided, latrace will display symbol's arguments with 
detailed output for structures. The config file syntax is similar to the C 
language, with several exceptions (see the section called "CONFIG").

The latrace by default fully operates inside of the traced program. However 
another pipe mode is available, to move the main work to the latrace binary (
see the section called "PIPE mode"). 

</pre>

</td>
</tr>
</table>
<br/>
<table>
<tr>
<td colsep>Tunning</td>

<td>
  <a href="https://tuned-project.org/" bgorange>tuned</a>
<pre xxxsmall zoom>
OS Tunning is done in practice through:
   - long-profiling
   - continuous-monitoring

Tunning becomes harder if system load changes frequently.

Ex.: A system with a peak of load certain hours a day
     can be tuned for performance     those known hours
     and    tuned for power-efficency the rest of day

<a href="https://linux.die.net/man/8/tuned">man 8 tuned</a>
Dynamic Adaptive system tuning daemon

- cron-friendly system service that lets to select a tuning profile
  (pre-build or custom).
- Tuning include:
  - sysctl settings (/proc/sys/)
  - settings for disk-elevators
  - power management options
  - transparent hugepages
  - custom-scripts

<b>Install</b>:
$ sudo dnf -y install tuned  # RedHat/Fedora/CentOS package install

=============================================
 Package                      Arch    Version
=============================================
Installing:
 tuned                        noarch  ...    
Installing dependencies:
 kernel-tools-libs            x86_64  ...    
 python3-perf                 x86_64  ...    
 hdparm                       x86_64  ...    
 python3-configobj            noarch  ...    
 python3-linux-procfs         noarch  ...    
 python3-schedutils           x86_64  ...    
 virt-what                    x86_64  ...    
Installing weak dependencies:
 kernel-tools                 x86_64  ...    

$ sudo systemctl enable tuned # ← enable tuned service at boot
→ ...
$ sudo systemctl start  tuned # ← Start  tuned service now
$ sudo systemctl status tuned # ← Check  tuned service status
$ sudo systemctl status tuned
→ * tuned.service - Dynamic System Tuning Daemon
→    Loaded: loaded (/usr/lib/systemd/system/tuned.service; disabled; vendor preset: disabled)
→    Active: <b>active (running)</b> since Sun 2019-01-20 16:29:05 EST; 15s ago
→      Docs: man:tuned(8)
→            man:tuned.conf(5)
→            man:tuned-adm(8)
→  Main PID: 10552 (tuned)
→     Tasks: 4 (limit: 4915)
→    Memory: 15.7M
→    CGroup: /system.slice/tuned.service
→            └─10552 /usr/bin/python3 -Es /usr/sbin/tuned -l -P

<b>Ussage:</b>
$ <b>tuned-adm list</b>   #  ← List existing tunning profiles
→ Available profiles:
→ - balanced                    - General non-specialized
→ - desktop                     - Optimize for the desktop
→ - latency-performance         - deterministic performance             (increased power consumption)
→ - network-latency             - deterministic performance low-latency (increased power consumption)
→ - network-throughput          - Optimize for streaming network throughput
                                  generally only necessary on older CPUs or
                                  40G+ networks
→ - powersave                   - Optimize for low power consumption
→ - throughput-performance      - provides excellent performance across a
                                  variety of common server workloads
→ - virtual-guest               - Optimize for running inside a virtual guest
→ - virtual-host                - Optimize for running KVM guests
→ Current active profile: balanced

$ <b>sudo tuned-adm active</b>  #  ← query status
Current active profile: balanced

$ <b>sudo tuned-adm profile  powersave</b> # ←  select profile
</pre>
</td>
<td>
  <span>powertop</span>
<pre xxxsmall zoom>
Allows to:
  - diagnose device/CPU power consumption issues
  - Tune/control device/CPU power management.

$ sudo powertop # ← Interactive mode if no other option is provided
$ sudo powertop --auto-tune  # ← Callibrate non-interactively
       ^^^^^^^^^^^^^^^^^^^^ 
       To enable at system boot add next systemd Unit:
       <b>STEP 1: Create/Edit powertop.service like:</b>
       $ sudoedit /etc/systemd/system/powertop.service
       (Add next lines)
     + [Unit]
     + Description=Powertop auto-tune
     + 
     + [Service]
     + ExecStart=/usr/bin/powertop --auto-tune
     + RemainAfterExit=true
     + 
     + [Install]
     + WantedBy=multi-user.target  

       <b>STEP 2: Enable the new service like:</b>
       $ sudo systemctl daemon-reload
       $ sudo systemctl enable powertop
       $ sudo systemctl start powertop

       <b>STEP 3: Check it has run properly</b>
       $ sudo journalctl -u powertop
     → ...
     → systemd[1]: Started Powertop auto-tune.
     → powertop[4778]: modprobe cpufreq_stats failedLoaded 0 prior measurements
     → powertop[4778]: RAPL device for cpu 0
     → powertop[4778]: RAPL Using PowerCap Sysfs : Domain Mask d
     → powertop[4778]: RAPL device for cpu 0
     → powertop[4778]: RAPL Using PowerCap Sysfs : Domain Mask d
     → powertop[4778]: Devfreq not enabled
     → powertop[4778]: glob returned GLOB_ABORTED
     → powertop[4778]: <b>Leaving PowerTOP</b>

OTHER PERTINENT OPTIONS:
--calibrate    :  Runs  in  calibration  mode: When running on battery,
                 powertop can track power consumption as well as system
                 activity.
                  When there are enough measurements, powertop can start
                 to report  power  estimates.
-csv=file      : Generate CSV report. 
-html=file     : Generate an HTML report.
-extech=$USBDEV: Use Extech Power Analyzer for analysis
                 USBDEV will be a USB adaptor similar to /dev/ttyUSB0 
-iteration=$Num : Number of times to run each test.
-time[=seconds] : Generate report for specified number of seconds.
-workload=file  : Execute workload file as a part of calibration 
....
</pre>
</td>
<td>
  ZSwap<br/>
  <span xsmall>(low-memory systems)</span>
<pre xxxsmall zoom>
  Increase system performance in systems with memory-preasure
<a href="https://www.maketecheasier.com/use-zswap-improve-old-linux-performance/">REF</a> 

setup
<b>Ubuntu Setup:</b>
  STEP 1: Edit /etc/default/grub and add "zswap.enabled=1" option to "GRUB_CMDLINE_LINUX_DEFAULT".
    For example, a line like
    | GRUB_CMDLINE_LINUX_DEFAULT="quiet splash" 
    becomes 
    | GRUB_CMDLINE_LINUX_DEFAULT="quiet splash zswap.enabled=1".
  
  STEP 2: Update Grub configuration:
  $ sudo update-grub
  
  STEP 3: Reboot and the zswap module will be enabled automatically.
  
  STEP 4: After you reboot, check if the module is active:
  $ cat /sys/module/zswap/parameters/enabled

<b>Fedora&amp;OpenSUSE Setup:</b>
STEP 1: Edit /etc/default/grub and add "zswap.enabled=1" option to GRUB_CMDLINE_LINUX

STEP 2: Update Grub configuration:
$ sudo grub2-mkconfig -o $(sudo find /boot/ -name grub.cfg)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
                          Depending on whether your computer
                          boots from a BIOS or UEFI system 
                          the path will change

STEP 3: Reboot and the zswap module will be enabled automatically.

STEP 4: After you reboot, check if the module is active:
$ cat /sys/module/zswap/parameters/enabled
(must display "Y,")

<b>Tunning</b>
-  Check adding the (grub) option "zswap.max_pool_percent=20" to see if performance increase.
   It’s recommended NOT to go above 50% since more than that can have detrimental effects 
   on systems with low amounts of RAM.
</pre>
</td>
<td>
Tunning Filesystem:
<pre xxxsmall zoom>
(/etc/fstab) mount options:
noatime:
        Do not update inode access times on this filesystem (e.g. for faster access on the news  spool
        to  speed  up  news servers).  This works for all inode types (directories too), so it implies
        nodiratime.

nodiratime
       Do  not  update directory inode access times on this filesystem.  (This option is implied when
       noatime is set.)

lazytime
       Only update times (atime, mtime, ctime) on the in-memory version of the file inode.

       This mount option significantly reduces writes to the inode table for workloads  that  perform
       frequent random writes to preallocated files.

       The on-disk timestamps are updated only when:

       - the inode needs to be updated for some change unrelated to file timestamps

       - the application employs fsync(2), syncfs(2), or sync(2)

       - an undeleted inode is evicted from memory

       - more than 24 hours have passed since the i-node was written to disk.


</pre>
<br/>
  Optimizing SSD
<pre xxxsmall zoom>
  <a href="https://searchdatacenter.techtarget.com/tip/Optimizing-Linux-for-SSD-usage">REF</a>
<b>Setting disk partitions</b>
SSD disks uses  4 KB blocks for reading
               512KB blocks for deleting!!!

To makes sure partitions are aligned to SSD-friendly settings:
$ sudo fdisk -H 32 -C 32 –c ....
             ^^^^^ ^^^^^        
             head  cylinder 
             size  size 

<b>Setting up Ext4 for SSD:</b>
 - Optimize ext4 erase blocks by ensuring that files smaller
   than 512 KB are spread across different erase blocks:
   - specify stripe-width and stride to be used. (default: 4KB)
     - alt.1: FS creation:
       $ sudo mkfs.ext4 -E stride=128,stripe-width=128 /dev/sda1
     - alt.2: existing FS:
       $ tune2fs -E stride=128,stripe-width=128 /dev/sda1

<b>Setting i/o scheduler for SSD</b>
- Default value is Complete Fair Queueing.
  SSD benefits from the deadline scheduler:
  - Include a line like next one in /etc/rc.local:

    echo deadline > /sys/block/sda/queue/scheduler

<b>Trimming the data blocks from SSD</b>
- Trimming makes sure that when a file is removed, the data blocks
  actually do get wiped.
- Without trimming, SSD performance degrades as data blocks get
  filled up.
- Add "discard" option to /etc/fstab to enable trimming. Ex:
/dev/sda1   /     ext4     <b>discard</b>,errors=remount-ro,noatime  0 1
                                                            ^^^^^^^
                                                          file access times does 
                                                          not get updated every time
                                                          file is read, minimizing 
                                                          writes to FS.
</pre>
</td>
</table>

</body>
<!--
{{{
Turning on Linux ACLs:
   https://wiki.archlinux.org/index.php/Access_Control_Lists
____________________________________________________

Other OOSS Storage solutions
<pre xxxsmall zoom>
Ceph   :distributed storage solution with unified object
        and block storage capabilities.

FreeNAS:"World's #1 storage OS"
        - It can be installed on nearly any hardware to turn 
          it into a network attached storage (NAS) device.
        - Paid, supported enterprise solutions available under TrueNAS
       
NAS4Free: " simplest and fastest way to create a centralized 
          and easily-accessible server for all kinds of data."
          Key features:
          - ZFS file system
          - software RAID (levels 0, 1 or 5)
          - disk encryption.
          - OS: FreeBSD
       
Openfiler: unified storage solution:
          NAS + SAN storage.
          Features:
          - high availability/failover.
          - block replication 
          - Web-based management.
</pre>
_______________________

https://wiki.centos.org/AdditionalResources/Repositories/SCL
__________
https://en.wikipedia.org/wiki/Avahi_(software) ZeroConf Linux impl.
__________
https://www.2daygeek.com/zstandard-a-super-faster-data-compression-tool-for-linux/
Zstandard super-fast compression tool
__________
TODO: journalctrl
the journal is "synchronous". Eacth time someone tries to write it checks if
ther is space or something needs to be deleted. (vs remove each 24 day,...)
 $ journalctrl [tab] ...
____________________

____________________
https://linux.die.net/sag/
________________________
http://swift.siphos.be/linux_sea/
________________________
Add pstree view (and security related info)
________________________
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Networking_Guide/
https://docs.fedoraproject.org/en-US/Fedora/24/html/Networking_Guide/index.html
https://wiki.debian.org/NetworkManager
________________________
https://lwn.net/Articles/531114/
________________________
/proc/sys/vm/
file-system-control-panel to kernel
________________________
Troubleshooting
<td>
boot
</td>
  Authentication issues (PAM)
<td>
</td>
<td>
Performance <br/>

memory
<pre xxxsmall zoom>
 "everything goes through memory"

top / htop  / atop
- if there is lot o buffer and cache even if there is not
  much availa. mem "there is no problem"
cache is a mechanism to speed up performance
     ... but it can be reused


less /proc/meminfo;
....
MemTotal: 
:                   
Pool of usable memory  after kernel load:
  Active   :       
  Inactive : Memory allocated by kernel and never used
Active (anon)ymos:      
Inactive (anon)ymous:   
Active (file)ymos:     
Inactive (file)ymous:    
cat /proc/meminfo; vmstat; iostat; bonnie++; dd ; nc (netcat)
</pre>
disk
<pre xxxsmall zoom>
Look for:
- wrong I/O scheduler
- wrong filesystem
- wrong journaling


sar: System activity reporting
 (Maybe first for local hard-disk) 
</pre>

network
<pre xxxsmall zoom>
</pre>

cpu
<pre xxxsmall zoom>
</pre>
</td>
<td>
hardware issues
</td>
https://asciinema.org/
Record and share your terminal sessions, the right way.
Forget screen recording apps and blurry video. Enjoy a lightweight, purely text-based approach to terminal recording. 
_______________________
<!-- TODO: https://opensource.com/article/18/11/partition-format-drive-linux
__________________
https://www.dfrws.org/sites/default/files/session-files/paper-an_analysis_of_ext4_for_digital_forensics.pdf
_________________
https://www.kernel.org/doc/html/v4.12/crypto/index.html
__________________
https://www.oreilly.com/library/view/red-hat-certified/9780134723990/earning objectives 

Lesson 6: Managing Users and Groups          Lesson 7: Managing Permissions
6.1 Understanding the Need for Users         7.1 Understanding Ownership 
6.2 Creating and Managing Users              7.2 Changing File Ownership 
6.3 Understanding User Properties            7.3 Understanding Basic Permissions 
6.4 Understanding User Configuration Files   7.4 Managing Basic Permissions 
6.5 Creating and Managing Groups             7.5 Understanding umask 
6.6 Understanding Group Membership           7.6 Understanding Special Permissions 
6.7 Managing Password Properties             7.7 Managing Special Permissions 
                                             7.8 Understanding ACLs 
                                             7.9 Managing ACLs 

Lesson 8: Configuring Networking                                Lesson 9: Managing Processes
8.1 Understanding NIC Naming                                    9.1 Understanding Jobs and Processes 
8.2 Managing runtime network Configuration with the ip Command  9.2 Managing Shell Jobs 
8.3 Storing Network Configuration Persistently                  9.3 Getting Process Information with ps 
8.4 Managing Persistent Network Configuration with nmcli        9.4 Understanding Memory Usage 
8.5 Managing Persistent Network Configuration with nmtui        9.5 Understanding Performance Load 
8.6 Verifying Network Configuration Files                       9.6 Monitoring System Activity with top 
8.7 Understanding Routing and DNS                               9.7 Sending Signals to Processes 
8.8 Configuring Routing and DNS                                 9.8 Understanding Priorities and Niceness 
8.9 Understanding Network Analysis Tools                        9.9 Changing Process Nice Values 
8.10 Using Network Analysis Tools 
______________________________
Lesson 10: Managing Software                  Lesson 11: Working with Virtual Machines
10.1 Understanding Meta Package Handlers      11.1 Introducing KVM Virtualization 
10.2 Setting up Yum Repositories              11.2 Managing Libvirt and KVM 
10.3 Using Repositories                       11.3 Installing a Virtual Machine 
10.4 Managing Packages with yum               11.4 Using virsh 
10.5 Using Yum Groups                         11.5 Using virt-manager 
10.6 Understanding yum and RPM Queries        11.6 Understanding KVM Networking 
10.7 Using RPM Queries                        11.7 Managing KVM Networking 
                                              11.8 Importing OVF Virtual Machine Files 
______________________________

Lesson 12: Scheduling Tasks                Lesson 13: Configuring Logging
12.1 Using cron vs. at                     13.1 Understanding rsyslogd and journald Logging 
12.2 Understanding Cron Execution Times    13.2 Configuring rsyslog Logging 
12.3 Scheduling with cron                  13.3 Working with journald 
12.4 Understanding anacron                 13.4 Configuring logrotate 
12.5 Using at 

Lesson 14: Managing Partitions
14.1 Understanding Disk Layout 
14.2 Understanding GPT and MBR Partitions 
14.4 Creating GPT Partitions with gdisk 
14.5 Understanding File System Differences 
14.6 Making the File System 
14.7 Mounting the File System Manually 
14.8 Mounting Partitions via /etc/fstab 
14.9 Creating a Swap Partition 
______________
https://linux.die.net/man/1/dstat
Dstat is a versatile replacement joining the info from vmstat, iostat, ifstat an mpstat. Dstat overcomes some of the limitations and adds some extra features.

Dstat allows you to view all of your system resources instantly, you can eg. compare disk usage in combination with interrupts from your IDE controller, or compare the network bandwidth numbers directly with the disk throughput (in the same interval). 
_____________________
https://pcp.io/
- Analyze systems' performance metrics in real-time or using historical data.
- Compare performance metrics between different hosts and different intervals. Observe trends and identify abnormal patterns.
__________________
<a href="https://docs.fedoraproject.org/en-US/fedora/f29/system-administrators-guide/">Fedora Sys.Admin.Guide</a>
__________________
TODO: Change file permissions. (chmod, chown owner:group, chgrp)
     
        you can also use numbers (instead of letters) to change file permissions. Where:
        r (read) = 4 w (write) = 2 x (execute) = 1 
______________________
chattr: Change file system attributes (works on ext2fs and possibly others...). 

    Example:
    chattr +i /sbin/lilo.conf[1] 

    - 'immutable':  prevent any changes (accidental or otherwise) to the  file.

    A (no Access time): last access time will not be updated. 
                        - It can be useful, for example, on files or directories which
                          are very often accessed for reading, especially since this parameter 
                          is the only one which changes on an inode when it's opened.

        a (append only): (For a directory, this means that you can only add files to it, but 
                          not rename or delete any existing file)

        s (secure deletion): when the file or directory is deleted, the blocks it was
                          occupying on disk are written back with zeroes (similar to shred).
                          Note that this does work on the ext2, and ext3 filesystems but is
                          unlikely to work on others 

$ lsattr (list attributes): list if whether a file has any special attributes set by chattr
                            -R recursive

See also:
   https://unix.stackexchange.com/questions/32256/whats-the-meaning-of-output-of-lsattr
______________________
<a TODO href="http://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/etc.html">[/etc config directory]</a>
___________________________
KVM: {{{
- https://www.systutorials.com/136652/handling-sparse-files-on-linux/
- https://www.systutorials.com/245839/how-to-enlarge-root-partition-and-filesystem-size-of-cloud-linux-vm-at-runtime-without-rebooting-linux/
- https://www.systutorials.com/241831/how-to-resize-a-virtual-disk-of-kvm/
}}}
___________________
https://www.systutorials.com/124416/shrinking-a-ext4-file-system-on-lvm-in-linux/
_____________________
__________________________
https://www.systutorials.com/1760/linux-setting-date-time-and-timezone/
_______________________

_________________________
https://www.linuxlinks.com/best-linux-multi-core-compression-tools/
_________________________
Cobbler (short of "Advanced PXE" network installs)
Cobbler (short of "Advanced PXE" network installs)
The most common way to do network installations is network booting via PXE, which requires setup of a TFTP server and DHCP configuration. 
However, PXE is not viable in some situations due to external constraints–for instance, what if your department does not have control of your DHCP server? 
What if you are at home and don’t have a server of your own? Solutions for installing machines without PXE are useful in those cases.
 For virtualization technology like Xen and KVM, other fully automatic installation solutions are required.

If you’re a systems administrator, gluing all of this (PXE, reinstalls, and virtualization) together manually is something you might prefer not to do. 
You’d really like a tool to do this setup and configuration for you.

Cobbler is a universal boot server that sets up everything you need for software installation–PXE, reinstalls, and virtualization. You can set up a Cobbler boot
server for your favorite distros in just a few minutes. And as your provisioning needs grow, you can take advantage of more advanced features to
further automate and simplify your systems administration requirements.
_______________________________
Windows running on KVM (Linked-in comments)
KVM vs. VirtualBox as a desktop virtualizer 
Tilman Schmidt IT Generalist Top Contributor
I've been using VirtualBox for years to run a Windows VM on my OpenSuse Linux desktop. On my new notebook, which runs CentOS 6, I decided for various reasons (not the least of them the strong disapproval of the kernel development community) to give KVM a try. Two gripes I currently have:
a) I can't seem to get my existing VirtualBox VM to run with KVM. I can convert the virtual disk image just fine, but when I start it in KVM I invariably get a bluescreen with the famous message that Windows has stopped the machine in order to protect my data.
b) The Virtual Machine Manager insists that I provide the root password in order to start a VM. With VirtualBox I just had to add my user to the vboxusers group.
Comments 
Sam Varshavchik
IT Consultant
Top Contributor
Well, trying to run a hypervisor with a VM image created on another hypervisor is always a hit-and-miss proposition.


I had no issues creating a new KVM, then booting and installing both Windows XP and 7.


Keep in mind that this is Windows we're talking about. If you migrate to a different VM, the guest OS is now going to see completely different virtual hardware, when it boots. Trying taking an ordinary, physical server with MS Windows installed on its hard drive, yank out its motherboard, put in a completely different motherboard, with a different class of CPU, plug in the hard drives, and try to boot. I don't think that the chances of being able to boot to the desktop, without a bluescreen, would be very good, in this situation; yet, what you have would be the exact analogue of this scenario.
Eric Ross
Network Administrator
A few years ago, I moved from VirtualBox to KVM. I had similar issues.


These may work:
- Disable any optimizations in VirtualBox for the VM, set the devices as generic as possible, and convert again.
- In KVM when the VM starts booting, press F8 to boot into Safe Mode. If it comes up, uninstall any video and chipset drivers. You'll want to install virtio drivers afterwards.


I found it easier to install from scratch.


You can start VM's at boot or from the commandline without a password. On my work server, my Virtual Machine Manager prompts me for a password to get in (I believe it has to do with XFCE starting at bootup). I manually start XFCE on my home server so I don't get prompted for a password in VMM.
Angel Docampo
Implementador soluciones Open Source en Datalab Tecnología
I can convert windows virtual machines from vmware to kvm with those steps, I'm pretty sure it will work as well from virtualbox to kvm.


As said before, windows hates to change hardware. The workaround is to tell windows is using the simplest hardware before converting, on the source virtual environment.
So, uninstall any virtualbox guest tools/additions, reboot, tell to virtualbox the hard disk is an IDE, the network adapter is an realtek 8139too or Intel E1000, and make sure video is a VGA. Boot again and download this file https://www.virtualbox.org/raw-attachment/wiki/Migrate_Windows/MergeIDE.zip , unzip it, and double click on the .reg file.
Make sure Atapi.sys, Intelide.sys, Pciide.sys, and Pciidex.sys are in the %SystemRoot%System32Drivers folder. If any are missing they can be extracted from %SystemRoot%Driver CacheI386Driver.cab which can be opened in Windows file Exlorer like a directory and then the missing files can be copied out.
Then convert the image to qcow2, set it as virtual hard disk as you did, and it should work
Then, install spice guest tools from fedora (ISO), http://alt.fedoraproject.org/pub/alt/virtio-win/latest/images/ or from spice-space.org (EXE) http://www.spice-space.org/download/windows/spice-guest-tools/


With the boot IDE disk, add a second disc, type VirtIO, and boot windows guest again. It will detect the new disk, and will install the drivers.
Halt the machine, remove second disk, change type from IDE to VirtIO of the primary disk, and boot the guest again.


It should boot without problem.


Furthermore, you can add a VirtIO network adapter as well. And video driver will be QXL, the fastest out there (It can play videos pretty well).


Hope it helps.
Alejandro G. likes this
Gustin Johnson
Sr. Linux and Windows System Administrator seeking a new opportunity, with a focus on DevOps
Don't forget to add your user to libvirtd and kvm groups. This will allow you to start/stop and otherwise manage VMs as your regular user.


You may want to track down the RedHat virtio driver disk for windows. This makes a huge difference particularly on IO.


For additional performance you will also want to specify the CPU architecture in the VM properties. I usually just click the button that clones the host OS CPU info.


Converting a VM is still kind of a pain. I usually find it less effort and headache in the long run to just rebuild the Windows VMs. I have not had any problems with Linux VMs. I have both hypervisors installed on my laptop, so I can access old VMs when I need to. You just have to remove the kvm module before loading the vbox ones.


I am also not a fan of the ancient kernels in RHEL/Cent, so I do most of my work on more recent Ubuntu installs. I have a couple of KVM hosts at home, so I prefer Ubuntu server there. I am beginning to be a huge fan of btrfs on VM hosts. There are some nice features there that are useful when working with VMs.
Muhammad Yousuf Khan
Asst: Manager IT infrastructure
i do migrate OS from Hardware, and i did migrate several VMs from VMware server x.x to KVM with the utility called Clonezilla. with 100% success result (so far).
i didnt install anything from scratch as reinstalling domain controller or installing an additional domain controller can be a problem and also cost a lot.


after migration when you boot at first your windows may not work for some time like 15 to 30 minutes. actually this will be the time when windows detecting and installing new hardware. and then it will give you a prompt to restart and thats all.


in vmware i was using vmware tool which i had uninstall before using Clonezilla. if there is anything like vmware tool and Virt tools in virtual boxl you must uninstall it before initiating the process otherwise it will give you blue screen.
Tilman Schmidt
IT Generalist
Top Contributor
Thanks for all the comments.


Regarding portability of VMs from VirtualBox to KVM: I guess I've been a bit naive there, thinking virtual machine settings could be made sufficiently similar that the Windows guest wouldn't notice the difference. Good point about uninstalling the VirtualBox specific drivers first @Eric @Angel @Muhammad, should have thought of that. But I'll probably end up ditching the old VirtualBox VM and create a new one for KVM, which (@Sam) does indeed work perfectly fine.


Regarding starting VMs without root privilege, @Alejandro @Eric it was indeed virt-manager asking for the root password on startup. But the shell commands "virsh list --all", "virsh start myvm", and "virt-viewer myvm" also work only if run as root. If run as a regular user, "virsh list --all" comes up empty, "virsh start myvm" complains "Domain not found: no domain with matching name 'myvm'", and "virt-viewer myvm" (after starting myvm with "sudo virsh start myvm") just does nothing. All of these work fine when run as root via sudo. @Gustin Adding the user to the kvm group did not change anything. There is no group libvirtd on my system.


Another (small) inconvenience when starting the VM from the command line is that it requires two commands, one (virsh start myvm) to start the VM and one (virt-viewer myvm) to get a window showing its screen. VirtualBox and virt-manager are both able display the VM console screen automatically when I start a VM. I guess I'll end up creating a shell alias to something like 'sudo "virt-viewer $1 & virsh start $1"'. (Quoting might get interesting on that one.)
Gustin Johnson
Sr. Linux and Windows System Administrator seeking a new opportunity, with a focus on DevOps
Regarding portability:
I have moved a couple of VMs from VirtualBox to kvm. The one big problem is that disk IO sucks since the kvm instance is using IDE emulation. The Windows VM refuses to let me switch to virtio while the Linux instances were no problem at all even after installing the relevant drivers.


In contrast the Windows VMs that I built on KVM have much better IO with the virtio drivers. You do have to attach the Red Hat driver ISO during the install to install the drivers so that Windows will actually install to a virtio block device. It is kind of clunky (don't forget to re-mount the Windows ISO and click the refresh button in the Windows installer) but if you snapshot a base install (trivial and fast with btrfs or cloning with virt-manager) you only need to do this once per Windows version. You could also build a custom Windows install to roll the drivers in. Microsoft has a lot of documentation and tools to help with this, though they never mention this in relation to kvm.


I have had about the same success rate moving to KVM as I have between the other hypervisors, and I have used all of the hypervisors in the x86/x86_64 world.


Regarding the root requirement:
What distribution do you have? I do not need root or sudo to run virsh on my 3 personally owned kvm hosts. All three are running various flavours of Ubuntu where I have the libvirt-bin package installed on my systems. The /etc/libvirt/libvirtd.conf file specifies the group(s) with read and write permissions (by default the libvirtd group on Ubuntu). This works locally and remotely with both virsh and virt-manager.


Regarding displays:
They suck on kvm IMHO. I usually just rdp with remmina to my Windows VMs to get copy and paste working. For Linux VMs, well I almost never need a GUI on a VM. I do have one Linux VM at home with a GUI and I use xrdp to proxy a vncserver session. There are probably better ways to do this.


There is nothing that I have found that behaves the same as VirtualBox (or VMWare workstation/player). If you do find something do let me know.


Hth,
_______________________
https://www.tecmint.com/setup-drbd-storage-replication-on-centos-7/
The DRBD (stands for Distributed Replicated Block Device) is a distributed, flexible and versatile replicated storage solution for Linux. It mirrors the content of block devices such as hard disks, partitions, logical volumes etc. between servers. It involves a copy of data on two storage devices, such that if one fails, the data on the other can be used.
_______________________
https://cockpit-project.org/
The easy-to-use, integrated, glanceable, and open web-based interface for your servers

https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8-beta/html/managing_systems_using_the_cockpit_web_interface/getting-started-with-cockpit_system-management-using-cockpit

The Cockpit Web interface enables you a wide range of administration tasks, including:
 - Managing services
 - Managing user accounts
 - Managing and monitoring system services
 - Configuring network interfaces and firewall
 - Reviewing system logs
 - Managing virtual machines
 - Creating diagnostic reports
 - Setting kernel dump configuration
 - Configuring SELinux
 - Updating software
 - Managing system subscriptions 
__________________
cron tasks:
sudo crontab -e:
0 8  * * 1-5 /usr/bin/tuned-adm profile throughput-performance
0 18 * * 1-5 /usr/bin/tuned-adm profile server-powersave
__________________
https://www.usenix.org/conference/fast15/technical-sessions/presentation/lee

F2FS: A New File System for Flash Storage 
(Much better than EXT4)
Experimental results highlight the desirable performance of F2FS; on a state-of-the-art mobile system, it outperforms EXT4 under synthetic workloads by up to 3.1 (iozone) and 2 (SQLite). It reduces elapsed time of several realistic workloads by up to 40%. On a server system, F2FS is shown to perform better than EXT4 by up to 2.5 (SATA SSD) and 1.8 (PCIe SSD).
______________________
https://kerneltalks.com/linux/whats-new-in-rhel-8/
______________________________
Mount Google Drive

https://www.techrepublic.com/article/how-to-mount-your-google-drive-on-linux-with-google-drive-ocamlfuse/
Fedora install:
  https://ask.fedoraproject.org/en/question/68813/any-good-client-for-google-drive/

______________________
https://www.tecmint.com/glances-an-advanced-real-time-system-monitoring-tool-for-linux/
____________________________
https://www.linuxsysadmins.com/30-yum-command-for-package-management-in-linux/
_____________________________
https://www.reddit.com/r/linuxadmin/comments/an1szj/fullsystem_dynamic_tracing_on_linux_using_ebpf/?utm_source=reddit-android
________________________
the-practical-linux-hardening-guide: This guide details the planning and the tools involved in creating a secure Linux production systems.
https://www.reddit.com/r/linuxadmin/comments/an0bbp/perform_whoislookup_on_ips_found_in_varlogsecure/?utm_source=reddit-android
________________________
- High Performance Java Persistence:
  https://www.reddit.com/r/linux/comments/ajkfs0/github_trimstraythepracticallinuxhardeningguide/?utm_source=reddit-android
___________________________
- https://www.tecmint.com/ranger-console-file-manager-with-vi-key-bindings/#
___________________________
https://www.linuxlinks.com/essential-system-tools-f3-detect-fix-counterfeit-flash-storage/
Essential System Tools: f3 – detect and fix counterfeit flash storage
___________________________
https://linuxtechlab.com/useful-yum-tips-tricks/
___________________________
Editors:
- vim
- nano
}}}
-->
</html>

