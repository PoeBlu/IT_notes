<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>changeme title</title>
<!--
 Q:Note what the attribute { and } do:
 A:Those attributes are ignored by the browser but are helpful to fold/unfold text in some
   editors (Vim, Emacs,...)
-->
<!--
ROW TEMPLATE
<tr {>
  <td col1 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col2 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col3 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
</tr }>
-->

<head>
<script>
var zoomDivDOM
function onZoomDivDoubleClick() { zoomDivDOM.innerHTML = ''; }
var zoomDivFW = true; // FW Full Width
var zoomDivFH = true; // FW Full Height 
var zoomDivTop = true; 
var zoomDivLft = true; 
function onTDDoubleClick()      { zoomDivDOM.innerHTML = 
     "('Esc' to close) Toggle "+
     "<span style='color:blue;' onClick=\"zoomDivFW  = !zoomDivFW ; zoomDivDOM.style.maxWidth  = zoomDivFW  ? '98%' : '30%'\">[Width]</span> " 
   + "<span style='color:blue;' onClick=\"zoomDivFH  = !zoomDivFH ; zoomDivDOM.style.maxHeight = zoomDivFH  ? '98%' : '30%'\">[Height]</span> " 
   + " Toggle " 
   + "<span style='color:blue;' onClick=\"zoomDivLft = !zoomDivLft; zoomDivDOM.style.left      = zoomDivLft ? '1%'  : '69%'\">[Horz]</span> " 
   + "<span style='color:blue;' onClick=\"zoomDivTop = !zoomDivTop; zoomDivDOM.style.top       = zoomDivTop ? '1%'  : '69%'\">[Vert]</span> " 
   + " <br/> " 
   + this.innerHTML; 
}

function removeToLeftMarginInPre() {
  // TODO:(0) Not working
  // nodeList = document.querySelectorAll('pre')
  // for (idx in nodeList) { 
  //   var node = nodeList[idx]
  //   var html = node.innerHTML
  //   var pattern = html.match(/^\s*[|]/)
  //   var regEx = new RegExp(pattern, "")
  //   console.log(html)
  //   node.innerHTML = html.replace(regEx,''))
  //    
  // }
}


function onPageLoaded() {
  zoomDivDOM = document.getElementById('zoomDiv')
  zoomDivDOM.addEventListener('dblclick',onZoomDivDoubleClick, false)
  document.addEventListener('keyup',function(e) { if (e.code !== "Escape") return; onZoomDivDoubleClick(); })
  // Change default a.target to blank. Ussually this is bad practice 
  // but this is the exception to the rule
  var nodeList = document.querySelectorAll('a')
  for (idx in nodeList) { 
      if (!nodeList[idx].href) { continue; }
      if (nodeList[idx].href && !nodeList[idx].href.startsWith("http")) continue;
      nodeList[idx].target='_blank'; 
  }
  nodeList = document.querySelectorAll('td')
  for (idx in nodeList) { 
     if (!!! nodeList[idx].addEventListener) continue;
     nodeList[idx].addEventListener('dblclick',onTDDoubleClick, false)
  }
  setTimeout(onZoomDivDoubleClick, 3000);
  removeToLeftMarginInPre();
}
</script>
<style>
*[mono]         { font-family: monospace; white-space: pre; }
pre { background-color:#EEEEEE; outline:1px dotted grey; margin: 0; }
*[cite]         { font-style: italic; }
*[TODO]         { color:red; font-weight: bold; }
*[TODO]:before  { content: "TODO:"; }
*[xxxsmall]{ font-size:0.1rem; }
img[xxxsmall]{ max-width:10rem; }
* xxsmall] { font-size:0.3rem; }
*[xsmall]  { font-size:0.7rem; }
*[small]   { font-size:0.9rem; }
*[xbig  ]  { font-size:1.5em; text-decoration: underline; }
ul { margin-left: 1.0em; padding-left: 0rem; }
#zoomDiv [xxxsmall] , #zoomDiv * [xxxsmall], #zoomDiv * * [xxxsmall], #zoomDiv * * * [xxxsmall]{ font-size:1em; } 
#zoomDiv img[xxxsmall] , #zoomDiv * img[xxxsmall], #zoomDiv * * img[xxxsmall], #zoomDiv * * * img[xxxsmall]{ max-width:100%; } 

/* REF: https://stackoverflow.com/questions/4910077/select-all-child-elements-recursively-in-css */
#zoomDiv * [small], #zoomDiv * [xsmall], #zoomDiv * [xxsmall] { font-size:1em; }
#zoomDiv * td { font-size:1em; }

body      { font-family:sans-serif; font-size:16px; padding: 0; margin: 0; }
#zoomDiv  { 
   position:fixed; top:1%; left:1%; width:auto; height:auto;
   max-height: 98%; max-width: 98%; overflow: auto;
   background-color:#FFFFFF; color:#000; border-radius: 0.5rem; border: 4px solid black; font-size: 2rem;
   box-shadow: 5px 5px 30px black;
   padding: 0.5rem;
}

a            { text-decoration:none; font-family:monospace; padding:0.1em;}
a[href^="#"]:before /* mark internal anchor */ {  content: ">"; }
a[href^="#"]:after  /* mark internal anchor */ {  content: "<"; }
a:visited { color:blue; }
td { 
   font-size: 0.8rem;
   vertical-align: top;
   outline: 1px solid grey; 
}
td[col1] ,th[col1] {background-color:#FFFFFF; min-width:34%; max-width:34%; font-size: 1rem;}
td[col2] ,th[col2] {background-color:#FAFAFA; min-width:33%; max-width:33%; }
td[col3] ,th[col3] {background-color:#FFFFFF; min-width:33%; max-width:33%; }
tr[header_delimit] > *{background-color:#000000; color:#FFFFFF; font-size:2em; color: white; }
tr[header_delimit] > td > a{color:inherit; text-decoration: underline; }
div[subtable1] { max-width: 95%; overflow: auto; padding:0; margin: 0;}

</style>
</head>
<body onLoad='onPageLoaded()'>
<div id='zoomDiv'>Hint: double-click on cell to zoom!!</div>

<table style='width:100%'{>
<tbody>
<tr {>
  <th colspan=3 header_delimit {   >topic1</th>
</tr }>
<tr {>
  <td col1 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col2 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col3 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
</tr }>
<tr {>
  <th colspan=3 header_delimit } { >topic2</th>
</tr }>
<tr {>
  <td col1 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col2 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col3 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
</tr }>
<tr {>
  <th colspan=3 header_delimit }   >topic3</th>
</tr }>
<tr {>
  <td col1 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col2 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
  <td col3 >
     <ul>
       <li> </li>
       <li> </li>
       <li> </li>
     </ul>
  </td>  
</tr }>
</body>
<!--
REF: http://www.alanflavell.org.uk/unicode/unidata25.html
─  ┐  ┠   ┰    ╀   ═   ╠   ╰     ┌─────┬─────┐
                                 │     │     │
━  ┑  ┡   ┱    ╁   ║   ╡   ╱     │     │     │
                                 ├─────┼─────┤
│  ┒  ┢   ┲    ╂   ╒   ╢   ╲     │     │     │
                                 │     │     │
┃  ┓  ┣   ┳    ╃   ╓   ╣   ╳     └─────┴─────┘
                                 ← ↑
┄  └  ┤   ┴    ╄   ╔   ╤   ╴     → ↓

┅  ┕  ┥   ┵    ╅   ╕   ╥   ╵     ┌─────────┐
                                 │         │
┆  ┖  ┦   ┶    ╆   ╖   ╦   ╶     │         │
                                 │         │
┇  ┗  ┧   ┷    ╇   ╗   ╧   ╷     │         │
                                 └─────────┘
┈  ┘  ┨   ┸    ╈   ╘   ╨   ╸ 

┉  ┙  ┩   ┹    ╉   ╙   ╩   ╹ 

┊  ┚  ┪   ┺    ╊   ╚   ╪   ╺ 

┋  ┛  ┫   ┻    ╋   ╛   ╫   ╻ 

┌  ├  ┬   ┼    ╌   ╜   ╬   ╼ 

┍  ┝  ┭   ┽    ╍   ╝   ╭   ╽ 

┎  ┞  ┮   ┾    ╎   ╞   ╮   ╾ 

┏  ┟  ┯   ┿    ╏   ╟   ╯   ╿ 

-->

<!--
TODO
NON-CLASSIFIED: {{{
    ___________
"http://www.eweek.com/enterprise-apps/linux-3.13-improves-networking-memory-performance.html
    ___________"
"The Linux 3.13 kernel follows the Linux 3.12 kernel
 that was released in November of 2013. Among the new capabilities and features are a packet filtering technology, improved solid-state disk 
(SSD) storage capabilities and integrated support for near-field communications (NFC) payments.
One of the biggest changes in the Linux 3.13 release is the inclusion of the new nftables packet filtering technology, which is intended to be a
 successor to the widely deployed iptables technology. Iptables are typically used for security, access and firewall configuration on Linux servers and systems.
The basic idea with nftables is that it is a more robust and easier to use than iptables while offering similar functionality that is 
backward-compatible with existing iptables rules.
""We are supportive of nftables and what it means for the Linux community moving forward,"" Denise Dumas, senior director of Platform Engineering 
at Red Hat, told eWEEK. ""iptables has always been difficult for customers to use successfully, and we have high hopes that nftables 
will provide a much more user-friendly experience.""

In addition, Linux 3.13 gains automatic non-uniform memory access (NUMA) balancing, which Dumas said should be very helpful for enterprise users.
        
There is now also a new storage block layer for SSDs that is part of the Linux 3.13 kernel. ""With drivers being written for new high IOPS (Input/Output Per Second)  devices, the classic request_fn based driver doesn't work well enough,""  Linux developer Jens Axobe wrote in his code commit message.  ""It has problems with scaling to bigger machines, and runs into scaling  issues even on smaller machines when you have IOPS in the hundreds of  thousands per device."" The new block layer approach, called ""blk-mq,"" introduces block  multi-queue support, which is intended to meet the high IOPS  requirements of SSDs.
        
""The design is centered around per-cpu queues for queueing IO,  which then funnel down into x number of hardware submission queues,"" Axboe wrote.
Networking also gets a boost in Linux 3.13 with a pair of innovations,  including the High-Availability Seamless Redundancy (HSR) standard that  is now supported in Linux, enabling a new approach for failover.
""It [HSR] requires a special network topology where all nodes are connected in a ring (each node having two physical network interfaces),""
 Linux developer Arvid Brodin wrote in his code commit message. ""It is suited for applications that demand high availability and very short reaction time.""
In addition to HSR, Linux 3.13 benefits from the TCP Fast Open specification, which is intended to accelerate the ability of a system 
to open up multiple Transmission Control Protocol (TCP) connections. The technology first landed in the Linux 3.7 kernel  at the end of 2012 and is now enabled by default in the Linux 3.13 release.
""Applications have started to use Fast Open (e.g., Chrome browser has such an optional flag) and the feature has gone through several 
generations of kernels since 3.7 with many real network tests,"" Linux kernel developer Yuchung Cheng wrote in his code commit message. ""It's time to enable this flag by default for applications to test more conveniently and extensively.""
Sean Michael Kerner is a senior editor at eWEEK and InternetNews.com. Follow him on Twitter @TechJournalist. - See more at: http://www.eweek.com/enterprise-apps/linux-3.13-improves-networking-memory-performance.html#sthash.WVlKASt4.dpuf
    ___________"
"To start an screen session at system start-up add a line similar to next one to /etc/rc.local:
screen -dmS cgminer bash -lc 'sleep 10; export HOME=/root; cgminer;
    ___________"
"http://lartc.org/ (LInux Advanced Routing and Traffic Control)
    ___________"
"Hidding processes to other Users: Src: http://www.cyberciti.biz/faq/linux-hide-processes-from-other-users/

The  hidepid option in the procfs defines how much info about processes we want to be available for non-owners. 
 - hidepid=0 : The old behavior - anybody may read all world-readable /proc/PID/* files (default).
 - hidepid=1 - It means users may not access any /proc/ / directories, but their own.  
  Sensitive files like cmdline, sched*, status are now protected against other users.
- hidepid=2 -  It means hidepid=1 plus all /proc/PID/ will be invisible to other users.  It compicates intruder's task of 
  gathering info about running processes, whether some daemon runs with elevated privileges, whether another user
 runs some sensitive program, whether other users run any program at all, etc.Linux kernel protection: 

Ex:
   # mount -o remount,rw,hidepid=2 /proc
Alternatively edit  /etc/fstab:
   proc    /proc    proc    defaults,hidepid=2     0     0
    ___________"
}}}
____________________________________________
INCREMENTAL BACKUPS: {{{
    ___________

     Bacula  http://www.bacula.org/es/
    ___________
He creado un script /opt/IncrementalBackup/incrementalBackup.sh que genera "instantaneas" de
un fichero/directorio así como copias incrementales.

El truco de las copias incrementales consiste es añadir el parámetro - -link-dest a rsync: 

   Esta opción le indica que a la hora de hacer el backup tome como referencia otro backup
   (el del día anterior en nuestro caso) y copie sólo las diferencias. En caso de que un
   fichero no hay cambiado se limita a crear un enlace duro al fichero ya existente.  Si a
   continuación se borra la copia del día anterior elfichero permanece intacto accesible desde
   la ruta de. Con este truco conseguimos crear instantáneas de N días pero el backup ocupará
   el tamaño de una sola copia más los cambios entre día y día en vez de 
   (tamaño de una copia x N dias).

El script lee la configuración de /etc/incrementalBackup.conf (y /etc/incrementalBackup.ignore) 
si lo ejecutamos como root o de ~/incrementalBackup.conf (~/incrementalBackup.ignore) si lo ejecutamos
como un usuario normal. incrementalBackup.conf tiene un formato similar a:

  1 daysKept=6
  2 weeksKept=4
  3 monthsKept=12
  4 PortatilEnrique=root@192.168.2.27:/BACKUPS/
  5 CASAEnrique=root@217.127.113.184:/BACKUPS/
  6 USB=/mnt/usb/dtvBACKUPS/

Crea una copia de un fichero o directorio en el repositorio que le indiquemos codificada de la 
siguiente forma:

Si queremos hacer un backup de /var/spool/mail/cyrus crea una copia
como backup@@var@@spool@mail@@cyrus dentro del repositorio.

¿Qué es el repositorio?

Básicamente es un directorio definido en /etc/incrementalBackup.conf utilizando la nomenclatura de ssh.
P.ej, el repositorio USB se indica como:

USB=root@192.168.2.100:/mnt/usb/dtvBACKUPS

De momento en el servidor de correo (192.168.2.1) he dejado programado las copias de cyrus añadiendo
a /etc/crontab las líneas:

0 23 *  * *    root  /opt/IncrementalBackup/incrementalBackup.sh /var/spool/cyrus USB daily
0 22 *  * 5    root  /opt/IncrementalBackup/incrementalBackup.sh /var/spool/cyrus USB weekly 
0 21 28 * *    root  /opt/IncrementalBackup/incrementalBackup.sh /var/spool/cyrus USB monthly 

Que genera las copias (fijaros en los tamaños. 20080813 es la copia inicial, y el resto están basados
en la misma):
6.5G    backup@@var@@spool@@cyrus.20080812
22M     backup@@var@@spool@@cyrus.20080813
3.3M    backup@@var@@spool@@cyrus.y2008m07
1.5M    backup@@var@@spool@@cyrus.y2008w31

(las copias semanales -y2008w3-1 y mensuales -y200807- las he creado a mano para que este viernes y el
día 28 ya exista una imagen creada a partir de la cual a poder hacer copias incrementales).

Enrique
    ___________
    ___________
    ___________
}}}
____________________________________________
http://www.linuxjournal.com/content/dnsmasq-pint-sized-super-d%C3%A6mon
DNSMasq: the way it works is simplicity at its finest. First, let's look at its features:
Extremely small memory and CPU footprint: I knew this was the case, because it's the program that runs on Linux-based consumer routers where
memory and CPU are at a premium.

DNS server: DNSMasq approaches DNS in a different way from the traditional BIND dæmon. It doesn't offer the complexity of domain
transfers, master/slave relationships and so on. It does offer extremely simple and highly configurable options that are, in my opinion, far
more useful in a small- to medium-size network. It even does reverse DNS (PTR records) automatically! (More on those details later.)

DHCP server: where the DNS portion of DNSMasq lacks in certain advanced features, the DHCP services offered actually are extremely robust. 
Most routers running firmware like DD-WRT don't offer a Web interface to the advanced features DNSMasq provides, but it rivals and even
surpasses some of the standalone DHCP servers.

TFTP server: working in perfect tandem with the advanced features of DHCP, DNSMasq even offers a built-in TFTP server for things like booting
thin clients or sending configuration files.

A single configuration file: it's possible to use multiple configuration files, and I even recommend it for clarity's sake. In the end, however,
DNSMasq requires you to edit only a single configuration file to manage all of its powerful services. That configuration file also is very well
commented, which makes using it much nicer.
____________________________________________
SE-Linux:{{{
Problems with Apache and DNS: (http://stackoverflow.com/questions/23851452/cant-resolve-domain-names-in-php-under-apache/24019910#24019910)

setsebool -P nis_enabled 1
setsebool -P httpd_can_network_connect 1
}}}
____________________________________________
yum grouplist | grep Dev
...
Development Tools
...
yum groupinfo "Development Tools"
...
sudo yum groupinstall "Development Tools"
____________________________________________
KVM/Qemu:

____________________________________________
APT {{{
Installing from testing/unstable:
/etc/apt/sources.list

deb http://ftp.us.debian.org/debian squeeze main
deb http://ftp.us.debian.org/debian testing main contrib non-free # <- add this line
deb http://ftp.us.debian.org/debian unstable main contrib non-free # <- add this line

$ sudo apt-get update
$ sudo apt-get install gcc/testing
  ______________
Show package info:
$ apt-cache show gcc
  ______________

apt-get aptitude
dselect
dpkg (state)
apt-cache
  ______________
apt repo.management:
http://mirrorer.alioth.debian.org/  & man reprepro
https://wiki.debian.org/SettingUpSignedAptRepositoryWithReprepro

"reprepro

LAYOUT:
| apt/public_repository/:
|  +-- incoming
|  +-- dists/oneiric/
|      +-- /universe
|      +-- /universe/source/
|      +-- /universe/binary-i386/
|      +-- /main/
|          +-- source
|          +-- binary-i386
|      +-- /multiverse/
|          +-- source
|          +-- binary-i386
|      +-- /restricted/
|          +-- source
|          +-- binary-i386
|  +-- db/ 
|  +-- conf/
|      +--> distributions
|           | Origin: Viotech
|           | Label: Viotech Communications
|           | Suite: stable
|           | Codename: oneiric
|           | Version: 11.10
|           | Architectures: i386 source
|           | Components: main restricted universe multiverse
|           | Description: HomeB repository
|           | ... 
|  +-- pool/
|      +-- main/
|          +-- [a-z]/*

FILTERING OPTIONS:
    -C, --component ...: Ex.-C 'main|contrib': Limit to list of components only.
    -A, --architecture ...: Ex: -A 'sparc|i386' . Limit to this architecture.
    -T, --type dsc|deb|udeb: Limit to packagetypes only.
    -S, --section section: Overrides the section of inclusions. (Also override possible override files)
    -P, --priority priority: Overrides the priority of inclusions. (Also override possible override files)

EXPORT:
    --export=(never|changed|lookedat|force):whether install, update, pull, delete should export index files of the distros they work with.
    --export=normal (default till 3.0.0) | lookedat (alternative new name since 3.0.1) Every distribution the action handled will be exported, unless error.
    --export=changed (default since 3.0.1) every distribution actually changed will be exported, unless error. 
    --export=force: Export all distributions looked at, even if there was some error. 
    --export=never: No index files are exported. export will be called later.

COMMANDS
    export [ codenames ] Recreate all index files for the specified distributions.  Also useful to create initial empty but fully equipped dists/codename directory.

    createsymlinks [ codenames ] Creates suite symbolic links in the dists/-directory pointing to the corresponding codename.
              --delete =>delete already existing symlinks

    list codename [ packagename ]
           Ex: ~/apt/public_repository $ reprepro -b . list oneiric
    listmatched codename glob: similar to list but use shell-like glob.  (i.e. *, ? and [chars] are allowed).
    listfilter codename condition: does not list a single package, but all packages matching the given condition. condition can use  !(not)  |(or) ,(and) and parentheses
           Ex: ~/apt/public_repository $ reprepro -b . listfilter test2 'Section (== admin)'
       ls package-name: List the versions of the the specified package in all distributions.

       remove codename package-names: Delete all packages for given distribution that have package name listed as argument
       removematched codename glob
       removefilter codename condition
       removesrc codename source-name [version]

       update [ codenames ] Sync the specified distributions (all if none given) as specified in the config with their upstreams. See the description of conf/updates below.

       checkupdate [ codenames ] Same like update, but will show what it will change instead of actually changing it. 
       dumpupdate [ codenames ] Same like checkupdate, but less suiteable for humans and more suitable for computers.

       predelete [ codenames ]
       cleanlists
       pull [ codenames ]
       checkpull [ codenames ]
       dumppull [ codenames ]

       includedeb|includeudeb|includedsc
    
       processincoming rulesetname [.changes-file]

       check [ codenames ]: Check if all packages in the specified distributions have all files needed properly registered.
       checkpool [ fast ]:Check if all files believed to be in the pool are actually still there and have the known md5sum. When fast is specified md5sum is not checked.

conf/distributions (Required)
     . Codename: oneiric | wheezy | ... (required). used also as dir_name within dists/
     . Architectures: i386 sources amd64 ... (Required)
     . Suite:  stable|testing|unstable. (<- Debian) 
     . Components: main restricted univers multiverse ...(required)
     . FakeComponentPrefix (See man)
     . AlsoAcceptFor (See man)
     . Version: This optional field is simply copied into the Release files. (11.10, 12.04,...)
     . Origin This optional field is simply copied into the Release files. (Viotech)
     . Label  This optional field is simply copied into the Release files. (Viotech Communications)
     . NotAutomatic (anything but yes does not  make  much  sense  right now.)
     . ButAutomaticUpgrades
     . Description Ex: HomeB repository
     . UDebComponents: Components with a debian-installer subhierarchy containing .udebs.  (E.g. simply ""main"")
     . Update: When present, it describes which update rules are used for this distribution. (See man) 
     . Pull: See man 
     . SignWith: S.M.
     . DebOverride:: S.M.
     . ... 

DIRECTORY OPTIONS:

    -b, --basedir basedir: Sets  base-dir for all other default directories (default:${REPREPRO_BASE_DIR} || cwd)
    --outdir outdir: dir where pool/ subdirectory resides.  '+b/' => relative to basedir. (default:basedir)
    --confdir confdir: (default to basedir/conf)
    --logdir logdir:
    --dbdir dbdir:
    --listdir listdir: downloads indices when importing from other repositories. (temp. data only)
    --morguedir morguedir: Files deleted from the pool.
    --methoddir methoddir: Look here instead of /usr/lib/apt/methods for methods to call when importing from other repositories.




Adding packages:
Removing packages:
List packages:

"
  ______________
}}}
____________________________________________
SystemD: {{{

http://freedesktop.org/wiki/Software/systemd/

"http://www.tecmint.com/create-new-service-units-in-systemd/

How to Create and Run New Service Units in Systemd Using Shell Script
by Ioannis Koustoudis | Published: February 17, 2016 | Last Updated: September 7, 2016
(Ioannis Koustoudis is a LFCS­ Linux sysadmin from Kavala, Greece. He works for the ministry of education and supports almost 200 school units in their infrastructure. If he is not in front of a computer screen, he plays music (he is a multi­-instrumentalist) or take care of his two lovely kids.


Few days ago, I came across a Centos 7 32-bit distro and I felt the desire to test it on an old 32-bit machine. After booting I realized that it had a bug and it was loosing the network connection, which I had to turn it “up” manually every time after boot. So, the question was how could I set a script doing this job, running every time I boot my machine?

Well, this is very simple and I ‘ll show you the systemd-way using service units. But first a small introduction to service units.

In this article, I ‘m going to explain what a “service unit” in systemd is, how easy is to create and run one. I will try to simplify what “targets” are, why we call them “collections of units” and what are their “wants”. Finally we are taking advantage of a service unit to run our own script after the boot procedure.

It’s obvious that your computer is useful due to the services it offers and in order to have this functionality, many services have to be called as the computer boots and reaches different levels. Other services are called to be executed when the computer reaches for example the rescue level (runlevel 0) and others when it reaches the multi-user level (runlevel 3). You can imagine these levels as targets.

In a simple way target is a collection of service units. If you want to have a look at service units running in your graphical.target level, type:

# systemctl --type=service


As you can see some services are active and “running” all the time, while others run one-time and terminate (exited). If you want to check the status of a service, type:

# systemctl status firewalld.service


As you can see I checked the status of firewalld.service (tip: you can use the auto-complete for the name of the service). It informs me that firewalld service is running all the time and it is enabled.

Don’t Miss: How to Configure FirewallD Service in CentOS 7

Enabled and disabled means the service will be permanently loaded or not, during the next boot respectively. On the other hand to start and stop a service has the limitation of the present session and it’s not permanent.

For example, if you type:

# systemctl stop firewalld.service
# systemctl status firewalld.service

You can see that the firewalld.service is inactive (dead) but it is still enabled, which means that during next boot it will be loaded. So if we want a service to be loaded during boot time in the future we must enabled it. What a great conclusion! Lets create one, it’s easy.

If you go to the folder:

# cd /etc/systemd/system
# ls -l

You can see some link files of unit services and some directories of the “wants” of a target. For example: what the multi-user target wants to be loaded when the boot procedure reaches its level, is listed in the directory with name /etc/systemd/system/multi-user.target.wants/.

# ls multi-user.target.wants/

As you can see it doesn’t contain only services but also other targets which are also collections of services.

Let’s make a service unit with the name connection.service.

# vim connection.service

and type the following (hit “i” for insert mode), save it and exit (with “esc” and “:wq!” ) :

[Unit]
Description = making network connection up
After = network.target
[Service]
ExecStart = /root/scripts/conup.sh
[Install]
WantedBy = multi-user.target

To explain the above: we have created a unit of service type (you can also create units of target type), we have set it to be loaded after the network.target (you can understand that the booting procedure reaches the targets with a defined order) and we want every-time the service starts to execute a bash script with the name conup.sh which we are going to create.

The fun starts with the last part [install]. It tells that it will be wanted by “multi-user.target”. So if we enable our service a symbolic link to that service will be created inside the multi-user.target.wants folder! Got it? And if we disable it that link will be deleted. So simple.

Just enable it and check:

# systemctl enable connection.service

it informs us that the symbolic link in the multi-user.target.wants folder has been created. Check it:

# ls multi-user.target.wants/

As you can see “connection.service” is ready for next booting, but we must create the script file first.

# cd /root
# mkdir scripts
# cd scripts
# vim conup.sh

Add the following line inside vim and save it:

#!/bin/bash
nmcli connection up enp0s3

Of course if you want your script to execute something else, you could type whatever you want instead of the second line.

For example,

#!/bin/bash
touch /tmp/testbootfile

that would create a file inside /tmp folder (just to check that your service is working).

We must also make the script executable:

# chmod +x conup.sh

Now we are ready. If you don’t want to wait until next boot (it’s already enabled) we can start the service for the current session typing:

# systemctl start connection.service

Voila! My connection is up and running!

If you ‘ve chosen to write the command “touch /tmp/testbootfile” inside the script, just to check its functionality, you will see this file created inside /tmp folder.

I really hope to help you figure out what services, wants, targets and running scripts during booting is all about.
"
     ________
Systemd Utilities:
   systemctl 
   journalctl
   notify
   analyze
   cgls
   cgtop
   loginctl
   nspawn 

Systemd Daemons
   systemd
   journald
   networkd
   logind
   user session

Systemd Targets
    bootmode  multiuser          graphical
    basic     dbus dlog, logind    user-session
    shutdown                         display service
    reboot    

Systemd Core
    manager
    systemd
    
    unit:
        service timer mount target
        snapshot path socket swap   
    
    login:
       multiseat  inhibit session    pam
    
    namespace log cgroup dbus

Systemd Libraries
    dbus-1 libpam libcap libcryptsetup tcpwrapper libaudit libnotify

Linux Kernel:
    cgroups autofs kdbus
}}}
________
High Availability {{{
Sofware.admin.HA  Setting up a high availability nfs with drdb and heartbeat  http://www.howtoforge.com/high_availability_nfs_drbd_heartbeat
    Virtual Router Redundancy Protocol  http://fr.wikipedia.org/wiki/Virtual_Router_Redundancy_Protocol
    DRDB: Networked RAID 1  http://www.drbd.org/
    "The GlusterFS project, a petabyte-scale, networked elastic filesystem.

Gluster Geo-replication GlusterFS Geo-replication provides a continuous, asynchronous, and incremental replication service from one site to another over Local Area Networks (LANs), Wide Area Networks (WANs) and across the Internet. "   http://blog.gluster.com/2011/06/new-release-glusterfs-3-2-1/
}}}  

____________________________________________
Simulador de redes IP   http://nirlog.com/2007/07/09/simulating-cisco-and-linux-networks/
A wireless mesh network based on the SNAP® (Synapse Network Application Protocol) software stack is instant-on, self-forming, and self-healing  http://www.synapse-wireless.com/
______________________________________
Software.MySQL  Setting Up Master-Master Replication On 4 Nodes With MySQL5-DebianEtch  http://www.howtoforge.com/setting-up-master-master-replication-on-four-nodes-with-mysql-5-on-debian-etch
    Use DRBD to Provide Rock-Solid MySQL Redundancy http://www.enterprisenetworkingplanet.com/nethub/article.php/3810596
    Use DRBD to Provide Rock-Solid MySQL Redundancy "http://www.enterprisenetworkingplanet.com/nethub/article.php/3810596/Use-DRBD-to-Provide-Rock-Solid-MySQL-Redundancy.htm
"
    Intro to Mysql Tunning (Doc. official de Sun)   http://www.sun.com/offers/details/Intro_to_SQL_Part1.html?intcmp=2313
        http://www.sun.com/offers/details/Intro_to_SQL_Part2.html?intcmp=2314
        http://www.sun.com/offers/details/Intro_to_SQL_Part3.html?intcmp=2315
    tunning: Insert Delayed en Mysql    http://dev.mysql.com/doc/refman/5.0/en/insert-delayed.html
    Setting up a MySQL cluster 7.0 in Redhat based linux    http://linuxadminzone.com/setting-up-a-mysql-cluster-7-0-in-redhat-based-linux/
    The Wonders of Maatkit for MySQL: utilidades cli avanzadas para MySQL   http://www.databasejournal.com/features/mysql/article.php/3882031/The-Wonders-of-Maatkit-for-MySQL.htm
    Mysql functional partitioning   http://www.databasejournal.com/features/mysql/article.php/3884701/MySQL-Functional-Partitioning.htm
    Cómo detectar si estamos en mitad de una transacción en Mysql   http://www.tigretigre.com/content/mysqueries-revealed-transaction-motion-condition-detection-solution
    The openark kit provides common utilities to administer, diagnose and audit MySQL databases.    http://code.google.com/p/openarkkit/
Software.PostgreSQL Slony Replicator for Postgresql http://gborg.postgresql.org/project/slony1/projdisplay.php
    Software relacionado con Postgresql.  Muy interesante.  http://techdocs.postgresql.org/oresources.php
    Moodss es una aplicación de monitorización gráfica con plugins para Postgresql, ... http://moodss.sourceforge.net/
    Comparing MySQL to PostgreSQL replication   http://www.theserverside.com/feature/Comparing-MySQL-and-Postgres-90-Replication
    Bucardo is an asynchronous PostgreSQL replication system, allowing for both multi-master and multi-slave operations http://bucardo.org/wiki/Bucardo
    split_postgres_dump is a small Perl script that breaks a --schema-only dump file into pre and post sections.    http://bucardo.org/wiki/Split_postgres_dump
    Connection Pooling,Replication,Load Balance,    http://pgpool.projects.postgresql.org/
    Parallel Query  
    MySQL vs. PostgreSQL, Part 1: Table Organization    http://rhaas.blogspot.com/2010/11/mysql-vs-postgresql-part-1-table.html
    How to install and configure DBI-Link to join Oracle tables from PostgreSQL on Debian GNU/Linux http://www.techforce.com.br/news/linux_blog/dbi_link_to_oracle_for_postgresql_on_debian
    "Postgresql 9.1 new features: synchronous replication,transaction-controlled synchronous replication,unlogged tables(in-memory tables),SE-Postgres,Extensions
"   http://www.databasejournal.com/features/postgresql/article.php/3932351/PostgreSQL-91-Gets-Synchronous.htm
-->

</html>
