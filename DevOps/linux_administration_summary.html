<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>Linux Administration Summary(ignore)</title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>

<body onLoad='onPageLoaded()'>
<b id='initialMessage' orange>Hint double-click/long-press on elements to zoom!!</b>
<div id='zoomDiv'></div>
<div style="position:fixed; right:0.3%; bottom:0; width:auto;">
<b style="font-size:1.5rem" orange><a onclick="onZoomOut()">[-A]</a></b>
<b style="font-size:1.5rem"       >                                 </b>
<b style="font-size:2.0rem" orange><a onclick="onZoomIn ()">[A+]</a></b>
</div>
<!-- {{{ START }}} -->

<table style='width:100%'>
<tbody>
<tr>
<td>
  External Links
  <ul xxxsmall zoom>
  <li><a href="https://linux.die.net/man/8/">Admin Man Pages (about 1% of them are of current use)</a> </li>
  <li><a href="https://linux.die.net/Linux-CLI/">Command-line Tools  Summary</a> </li>

  <li><a href="https://en.wikipedia.org/wiki/Linux_Standard_Base">Linux Standard Base</a> </li>
  <li><a href="http://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/etc.html">/etc config directory</a>(see also <a href="www.tldp.org/LDP/Linux-Filesystem-Hierarchy">Full FS Hierarchy</a>)</li>
  </ul>
</td>

<td>
  <b>Adding new user</b>
<pre xxxsmall zoom>
$ useradd [options] LOGIN : creates new user with default+specified values

$ useradd -D  #  display default values
(ex.output)
  GROUP=100
  HOME=/home
  INACTIVE=-1
  EXPIRE=
  SHELL=/bin/bash
  SKEL=/etc/skel
  CREATE_MAIL_SPOOL=yes
useradd -D [options] # update default values

----- next opts have defaults if not indicated ----------
  --base-dir BASE_DIR  :  (default to /home) Ignored if --home-dir set

  --expiredate EXPIRE_DATE

  --inactive INACTIVE  :  day # after pass.expiration before disabling

  --gid GROUP: existing group name or ID for initial group (when --no-user-group used)

  --shell SHELL

--------------------------------------------------------
  --groups group1,group2,... supplementary groups

  --skel SKEL_DIR :  skel. dir. to be copied in the user's home directory

  --key KEY=VALUE : Overrides /etc/login.defs defaults (UID_MIN, UID_MAX, UMASK, PASS_MAX_DAYS and others).

           Example: -K PASS_MAX_DAYS=-1 can be used when creating system account to turn off password ageing,
              even though system account has no password at all.
  --no-log-init   : Do not add user to lastlog and faillog databases

  --create-home   : Create the user's home directory if it does not exist.
                  By default no home directories are created

  --no-create-home: Do not create the user's home directory if enabled in defaults

  --no-user-group : Do not create a group. Initial group indicated by --gid 

  --non-unique    : Allow duplicate (non-unique) existing UID in --uid

  --password PASS : (disabled by default)

  --system        : Create system account (no aging, uid chosen in SYS_UID_MIN-SYS_UID_MAX range

  --root CHROOTDIR: Apply changes in chrooted directory 


  --uid UID       : numerical value for user's ID.

  --user-group    : Create group with the same name as user, and use as initial group

  --selinux-user SEUSER : SELinux user for the user's login

</pre>
</td>
<td>
  <b>BackUps</b> 
  <ul xxsmall zoom>
  <li><a href="http://rsnapshot.org/">Rsnapshot</a> filesystem snapshot utility on top of rsync.<br/>
     rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh.
     The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required 
     and rsync to save bandwidth (backup only changes) 
  </li>
  <li><span cite>"""<a xbig href="http://www.bacula.org/">Bacula</a> is a set of
    Open Source, computer programs that permit to manage backup, recovery, and 
    verification of computer data across a network of computers of different 
    kinds,  offering many advanced storage management features that make it 
    easy to find and recover lost or damaged files.</span>"""
    <ul xxxsmall zoom>
    <li><a href="http://www.bacula.org/9.0.x-manuals/en/main/index.html">Manual v.9</a></li>
    <li>Director Daemon supervises all the backup, restore, verify and archive operations.
        Sysadmin uses Director to schedule backups and to recover files..</li>
    <li>Console service allows the administrator or user to communicate with the Director
        (three versions: text-based, QT-based, wxWidgets)</li>
    <li>File Daemon It's installed on the machine to be backed up and is responsible for 
      providing the file attributes and data when requested by the Director
      as well as for the file system dependent part of restoring the file attributes and data 
      during a recovery operation.</li>
    <li>Storage daemons are software programs in charge of storage and recovery of the 
      file attributes and data to the physical backup media or volumes. In other words, it is 
      responsible for reading and writing your tapes (or other storage media, e.g. files).</li>

    <li>Catalog Services are responsible for maintaining the file indexes and 
      volume databases for all files backed up. The Catalog services permit the sysadmin
      or user to quickly locate and restore any desired file. The Catalog services sets
      Bacula apart from simple backup programs like tar and bru, because the catalog
      maintains a record of all Volumes used, all Jobs run, and all Files saved, permitting
      efficient restoration and Volume management. Bacula currently supports three different 
      databases, MySQL, and PostgreSQL one of which must be chosen when building Bacula. </li>
    <li>Monitor Service Allows the administrator or user to watch current status of Directors,
      File Daemons and Bacula Storage Daemons. Currently, only a GTK+ version is available.</li>
    </ul>
  </li>
  <li><span xbig>Symple remote backups with ssh</span> :
<pre>
$ tar cjf - myDirToBackup \       # local
  | ssh myUser@myRemoteMachine \  # ssh pipe
  "cd myBackupPath && tar -xjf -" # remote
</pre>
  </li>
  <li><span xbig>Using <code>rsync --link-dest=</code> for incremental backups:</span><br/>
  <code>--link-dest</code> allows rsync to compare the file copy to an existing directory
    structure and copy only the changed files (an incremental backup) relative 
    to the stated directory and to use hard links for other files.</span>
<pre>
$ rsync -avh --delete \
   --link-dest=/pathToReferenceBackup \
   /pathToDirectoryToBackup_CURRENT_SOURCE  \
   /pathToNewBackup

Backup in /pathToNewBackup will use hardlinks for existing
files in (already existing) /pathToReferenceBackup, creating
just "diff" of the first backup.
</pre>
  </li>
  <li><a href="https://linuxhint.com/inotofy-rsync-bash-live-backups/">Live backups with inotify + rsync + bash</a></li>
  </ul>
</td>  
<td>
  <b>SystemD</b> 
  (<a href="http://freedesktop.org/wiki/Software/systemd/">REF@freedesktop</a>,
   <a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html">man</a>,
  <a href="http://www.tecmint.com/create-new-service-units-in-systemd/">See also</a>)<br/>
<pre xxxsmall zoom>
"service unit"                  "targets"
- createNew                       unit_collection
- run                             "wants"
- lifespan:daemon|run-once

Check unit_collections:          Check status of a service:
# systemctl --type=service       # systemctl status firewalld.service


# (sudo) systemctl daemon-reload
# (sudo) systemctl \
   enable|start|stop|restart|disable \
     firewalld.service

# sudo vim /etc/systemd/system/MyCustomScript.service\
  | [Unit]
  | Description = making network connection up
  | After = network.target
  | [Service]
  | ExecStart = /root/scripts/conup.sh
  | [Install]
  | WantedBy = multi-user.target

<b>
Systemd      |Systemd      |Systemd           | Systemd
Utilities    |Daemons      |Targets           | Core
</b>                                            
$ systemctl  |systemd      | bootmode         | manager
$ journalctl |journald     | basic            | systemd
$ notify     |networkd     | shutdown  
$ analyze    |logind       | reboot    
$ cgls       |user session |
$ cgtop                    | multiuser          
$ loginctl                 | dbus dlog, logind  
$ nspawn                   |                    
                           | graphical
                           | user-session
                           | display service

</pre>
FILE NAME EXTENSIONS FOR UNIT TYPES:
<pre xxxsmall zoom>
*<b orange>.target     </b>: define groups of units. They achieve little themselves and serve to call
 <b orange>            </b>  other units that are responsible for services, filesystems ...
 <b orange>            </b>  (equivalent to the classical SysV runlevels)
*<b orange>.service    </b>: handle services that SysV-init-based distributions will typically
 <b orange>            </b>  start or end using init scripts.
*<b orange>.(auto)mount</b>: mounting and unmounting filesystems
*<b orange>.path       </b>: allow systemd to monitor files and directories specified
 <b orange>            </b>  when an access happens in path, systemd will start the appropriate unit
*<b orange>.socket     </b>: create one or more sockets for socket activation.
 <b orange>            </b>  service unit associated will start the service when a connection request
 <b orange>            </b>  is received.
</pre>

CONFIG. FILE LAYOUT:
<pre xxxsmall zoom>
(NOTE: /etc takes precedence over /usr)
<b orange>Maintainer   </b>: /usr/lib/systemd/system              ( + $ systemctl daemon-reload)
<b orange>Administrator</b>: /etc/systemd/system/[name.type.d]/ ) ( + $ systemctl daemon-reload)
<b orange>runtime      </b>: /runtime/systemd/system
</pre>

<b>Log Filtering (Journalctl):</b>
<pre xxxsmall zoom>
# journalctl                      → all logs
# journalctl -b                   → Boot Messages
# journalctl -b -1                → Last Boot Messages
# journalctl --list-boots         → list system boots
# journalctl --since "3 hour ago" → Time range
                     "2 days ago"
    --until "2015-06-26 23:20:00"
# journalctl -u nginx.service     → by unit (can be specified multiple times)
# journalctl -f                   → Follow ("tail")
# journalctl -n 50                → most recent (50) entries
# journalctl -r                   → reverse chronological order
# journalctl -b -1  -p "crit"     → By priority: -b -1 : FROM emergency , -p "crit" : TO: Critical
# journalctl _UID=108             → By _UID
---------------------------------------------------------------------
Output Formats ( -o parameter )

   json: json one long-line
   json-pretty:
   verbose:
   cat:  very short form, without any date/time or source server names
   short: (default), syslog style
   short-monotonic: similar to short, but the time stamp second value is shown with precision
</pre>
</td>  
</tr>
</table>
<table>
<tr>

<td>
  <span TODO>YUM <span xsmall>(RedHat/CentOS package manager)</span></span><br/>
  <a href="https://www.softwarecollections.org/en/">Software Collections</a>
  <span xsmall>build,install,use multiple package versions</span>
<pre xxxsmall zoom>
  <a href="https://www.softwarecollections.org/en/">Software Collections CentOS install </a>
Ex:
$ python --version
Python 2.7.5

$ scl enable rh-python35 bash
$ python --version
Python 3.5.1
</pre>

<div floatl>
<pre xxxsmall zoom>
# Check enabled repositories:
$ sudo yum (-v) repolist
  (commented output)
  repo id                 repo name
  # CentOS standard: base + update
  base/7/x86_64           CentOS-7 - Base
  updates/7/x86_64        CentOS-7 - Updates

  # <a href="https://wiki.centos.org/SpecialInterestGroup/SCLo">https://wiki.centos.org/SpecialInterestGroup/SCLo</a>
  centos-sclo-rh/x86_64   CentOS-7 - SCLo rh
  centos-sclo-sclo/x86_64 CentOS-7 - SCLo sclo
  # <a href="http://fedoraproject.org/wiki/EPEL">http://fedoraproject.org/wiki/EPEL</a>
  """ Extra Packages for Enterprise Linux (or EPEL) is a Fedora Special Interest
    Group that creates, maintains, and manages a high quality set of additional
    packages for Enterprise Linux, including, but not limited to, Red Hat 
    Enterprise Linux (RHEL), CentOS ... usually based on their Fedora counterparts
    and will never conflict with or replace packages in the base Enterprise
    Linux distributions....  """
  epel/x86_64             (E)xtra (P)ackages 4 (E)nter.(L)inux
  extras/7/x86_64         CentOS-7 - Extras

  # nice to have
  docker-ce-stable/x86_64 Docker CE Stable - x86_64
  ...
  # ... repos for PostgreSQL, Go-lang, ... exists

# Install from given repository:
$ sudo yum --disablerepo=\* --enablerepo=my-cool-repo install myPackage

yum grouplist | grep Dev
...
Development Tools
...
yum groupinfo "Development Tools"
...
sudo yum groupinstall "Development Tools"
</pre>
<!-- {
TODO:  Yum
To search for a specific package by name, use the list function. To search for the package tsclient, use the command:

su -c 'yum list tsclient'

Enter the password for the root account when prompted.

To make your queries more precise, specify packages with a name that include other attributes, such as version or hardware architecture. To search for version 0.132 of the application, use the command:

su -c 'yum list tsclient-0.132'

[Note]  Valid Package Attributes

Refer to Section 2.4, “Understanding Package Names” for information on package name formats and the attributes that they include.
5.2. Advanced Searches

If you do not know the name of the package, use the search or provides options. Alternatively, use wild cards or regular expressions with any yum search option to broaden the search critieria.

The search option checks the names, descriptions, summaries and listed package maintainers of all of the available packages to find those that match. For example, to search for all packages that relate to PalmPilots, type:

su -c 'yum search PalmPilot'

Enter the password for the root account when prompted.

The provides function checks both the files included in the packages and the functions that the software provides. This option requires yum to download and read much larger index files than with the search option.

To search for all packages that include files called libneon, type:

su -c 'yum provides libneon'

To search for all packages that either provide a MTA (Mail Transport Agent) service, or include files with mta in their name:

su -c 'yum provides MTA'

For each command, at the prompt enter the password for the root account.

Use the standard wildcard characters to run any search option with a partial word or name: ? to represent any one character, and * to mean zero or more characters. Always add the escape character (\) before wildcards.

To list all packages with names that begin with tsc, type:

su -c 'yum list tsc\*'

[Tip]   Regular Expressions

Use Perl or Python regular expressions to carry out more complex queries.
5.3. Understanding Matches

Searches with yum show all of the packages that match your criteria. Packages must meet the terms of the search exactly to be considered matches, unless you use wildcards or a regular expression.

For example, a search query for shadowutils or shadow-util would not produce the package shadow-utils. This package would match and be shown if the query was shadow-util\?, or shadow\*.
} -->
</div>
<div floatl>
<pre xxxsmall zoom>
# Erase package
$ sudo yum erase myPackage
</pre>
</div>
</td>
<td>
  <span TODO>APT <span xsmall>(Debian... package manager)</span></span>
<pre xxxsmall zoom>
Installing from testing/unstable:
/etc/apt/sources.list

deb http://ftp.us.debian.org/debian squeeze main
deb http://ftp.us.debian.org/debian testing main contrib non-free # <- add this line
deb http://ftp.us.debian.org/debian unstable main contrib non-free # <- add this line

$ sudo apt-get update
$ sudo apt-get install gcc/testing
______________
Show package info:
$ apt-cache show gcc
______________

apt-get aptitude
dselect
dpkg (state)
apt-cache
______________
</pre>

</td>
<td TODO >
  <a href="https://www.flatpak.org/">FlatPak</a>
  contanerized multi-distro software package manager
</td>
</tr>
</table>


<table>
<tr>
  <th colspan=12 header_delimit>Storage</th>
<tr>
<td>
Check disk free/used space:
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/0/df">man 1 df</a> 
$ df -kh  # Check free space

<a href="https://linux.die.net/man/1/du">man 1 du</a>
$ du -sch dir1 dir2  # check disk ussage of dir1 dir2
</pre>

Monitor files open:
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/8/lsof">man 8 lsof</a>
# list files open by process "pID"
$ sudo lsof -p <b orange>511</b> #
(output can be similar ...)
COMMAND   <b orange>PID</b>  USER   FD      TYPE     DEVICE SIZE/OFF    NODE NAME
avahi-dae <b orange>511</b> avahi  cwd       DIR        8,1       67 1274283 /etc/avahi
avahi-dae <b orange>511</b> avahi  rtd       DIR        8,1       67 1274283 /etc/avahi
avahi-dae <b orange>511</b> avahi  txt       REG        8,1   136264 2568376 /usr/sbin/avahi-daemon
avahi-dae <b orange>511</b> avahi  DEL       REG        8,1          1713236 /usr/lib64/libnss_sss.so.2;5ae2fcc0
avahi-dae <b orange>511</b> avahi  DEL       REG        8,1          1390813 /usr/lib64/...
avahi-dae <b orange>511</b> avahi    0r      CHR        1,3      0t0    1028 /dev/null
avahi-dae <b orange>511</b> avahi    1u     unix 0xff222c00      0t0   20500 socket
avahi-dae <b orange>511</b> avahi    3u     unix 0xffb84400      0t0   18699 /var/run/avahi-daemon/socket
avahi-dae <b orange>511</b> avahi    7w     FIFO        0,8      0t0   20324 pipe
avahi-dae <b orange>511</b> avahi   11r  a_inode        0,9        0    7017 inotify
avahi-dae <b orange>511</b> avahi   12u     IPv4      21553      0t0     UDP *:mdns
avahi-dae <b orange>511</b> avahi   13u     IPv4      21554      0t0     UDP *:44720
avahi-dae <b orange>511</b> avahi   14u  netlink                 0t0   21555 ROUTE
...

# list processes using any file in etc
$ sudo lsof <b orange>/etc/*</b>
(output can be similar ...)
COMMAND     PID      USER   FD   TYPE DEVICE SIZE/OFF      NODE NAME
avahi-dae   511     avahi  cwd    DIR    8,1       67 101274283 <b orange>/etc/</b>avahi
avahi-dae   511     avahi  rtd    DIR    8,1       67 101274283 <b orange>/etc/</b>avahi
java      41043 azureuser  296r   REG    8,1      393       154 <b orange>/etc/</b>os-release
java      41043 azureuser  297r   REG    8,1      393       154 <b orange>/etc/</b>os-release
</pre>
Monitor file/dir. access
<pre xxxsmall zoom>
<a href="https://linux.die.net/man/1/inotifywait">man 1 inotifywait</a>: Wait for changes, then execute someCommand
while  true ; do
    inotifywait -q -e modify fileToMonitor1 fileToMonitor2 ... ;  someCommandToExecute ; done
done

<a TODO href="https://linux.die.net/man/1/inotifywatch">man 1 inotifywatch</a>: gather filesystem access statistics
</pre>

</td>
<td>
  <a TODO href="https://en.wikipedia.org/wiki/Device_mapper">Device Mapper(dm)</a>
</td>
<td>
  <a TODO href="https://en.wikipedia.org/wiki/Logical_Volume_Manager_%28Linux%29">LVM</a><br/>
  <spam xsmall>Device Mapper target providing logical volume management</a>
</td>
<td>
  BTRFS (By SuSE, Oracle, Facebook, Fujitsu)
</td>
<td>
  <a href="https://opensource.com/article/18/4/stratis-lessons-learned">Stratis (by RedHat)</a>
  <a xxsmall href="https://stratis-storage.github.io/StratisSoftwareDesign.pdf">REF Design(PDF)</a>
  <br/>
</td>
<td>
  Storage encryption 
  <ul xxxsmall>
  <li>can be performed at the file system level or the block level.</li>
  <li>Linux file system encryption options include eCryptfs and EncFS, while 
    FreeBSD uses PEFS.</li>
  <li>Block level or full disk encryption options include dm-crypt + LUKS on 
    Linux and GEOM modules geli and gbde on FreeBSD.</li>
  </ul>
</td>

</tr>
</table>


<table>
<tr>
  <th colspan=12 header_delimit>SELinux Mandatory Access Control (MAC)</th>
</tr>
<tr>
<td>
  <a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-selinux-on-centos-7-part-1-basic-concepts">REF:</a> 
  <b>SELinux Policy:</b><br/>
  "bunch of rules" saying:
<pre xxxsmall zoom>
-  so-and-so <b orange>users  </b> can assume only so-and-so <b orange>roles</b>,                    <b>AND</b>
-  so-and-so <b orange>roles  </b> will be authorized to access only so-and-so <b orange>domains</b> <b>AND</b>
-  so-and-so <b orange>domains</b> in turn can access only so-and-so <b orange>file types</b> (Type Enforcement)
</pre>
  <br/>
  <ul xxxsmall zoom>
  <li>Every regular running process is called a subject and such subject is in a defined domain</li>
  <li>Rols are more like filters than user groups</li>
  <li>Object: regular file, directory, port, IP socket, ...  All objects are "tagged" with a
    type indicating the object's purpose. ("this file is web page", or 
    "file belongs to the /etc directory" or "the file's owner is a SELinux user
    'std_user'", ...).  </li>
  <li>The actions that a subject can perform inside a context/domain on an object are the 
    subject's permissions</li>
  <li>SELinux modes: Enforcing | Permissive | Disabled</li>
  <li><code>/etc/selinux/config</code>
<pre>
$ vim  # Reboot is needed after changes to this file
# This file controls the state of SELinux on the system.
# SELINUX := enforcing permissive
disabled
SELINUX=enforcing
# SELINUXTYPE= can take one of these two values:
#     <b>targeted</b>: Only list of targeted processes are protected (default)
#                     In deny-by-default every access is denied unless approved by policy
#     <b>minimum </b>: Modification of targeted policy. Only selected processes are protected. 
#     <b>mls     </b>: Multi Level Security protection.
SELINUXTYPE=targeted
</pre>
  </li>
  <li>Debugging:
<pre> 
# Errors
#~ cat /var/log/messages | grep "SELinux is preventing"
# Other
#~ cat /var/log/messages | grep "SELinux"
</pre>
  </li>
  <li>SELinux users and roles do not have to be related to the actual system users and roles:<br/>
          For every current user, process, files, sockets, messages, network interfaces and ports, and
          other hardware <span xbig>SELinux assigns a three string context consisting of <code>(username, role, domain)</code>(domain and type are synonims)</li>
  <li>as a rule, most of the real users share the same SELinux username, and all access control is managed through the third tag, the <b orange>domain</b>.</li>
  <li><code>runcon</code> allows to launch processes into an specified context (user, role and domain) if allowed by SELinux policies</li>
  <li>SELinux context for remote FS can be specified at mount time.</li>
  <li><code orange>-Z  switch</code> is added to standard shell commands <code>ls, ps,  ...</code> to show context info</li>
  <li>A typical policy uses a mapping (labeling) file, a rule file, and an interface file, defining allowed domain transition.  These files <b>must be compiled</b> together to produce a single policy file that the kernel can load </li>
<!--  TODO:
    cached information on access-decisions via the Access Vector Cache (AVC)
-->
      <li TODO><a href="http://blog.siphos.be/2015/07/restricting-even-root-access-to-a-folder/">Restricting event root access to a folder</a></li>
      <li>
        <b>SELinux Policy Behavior</b>
        When an SELinux-enabled system starts, the policy is loaded into memory organized in modules.
        <code><b>se</b>module</code> can be used for a number other tasks like installing,
        removing, reloading, upgrading, enabling and disabling SELinux policy modules.
        
<pre>
#~ <b>se</b>module -l # lists modules currently loaded
(output will be similar to ...)
abrt    1.2.0
accountsd       1.0.6
acct    1.5.1
afs     1.8.2
...
</pre>
        <br/>
        Although you can't read the (binary) policy module files, there's a simple way to tweak their settings.
<pre>
#~ <b>se</b>manage boolean -l 
ftp_home_dir                   (off  ,  off)  Allow ftp to home dir
smartmon_3ware                 (off  ,  off)  Allow smartmon to 3ware
mpd_enable_homedirs            (off  ,  off)  Allow mpd to enable homedirs
...

#~ set<b>se</b>bool -P ftpd_home_dir on  # -P flag: make permanent (by default reseted after reboot)
</pre>
       <br/>
  </li>
  <li>
   <code>#~ <b>se</b>status:</code>
<pre xxxsmall zoom>
SELinux status:                 enabled
SELinuxfs mount:                /sys/fs/selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             targeted
Current mode:                   permissive
Mode from config file:          error (Success)
Policy MLS status:              enabled
Policy deny_unknown status:     allowed
Max kernel policy version:      28
</pre>
  </li>
  <li>Switch permissive/enforcing:
<pre>
#~ setenforce permissive: Temporarely change enforce status.
#~ setenforce enforcing
</pre>
  </li>
  <li>Suffix Naming Conventions
<pre>
"_u" -> user
"_r" -> role 
"_t" -> types (for files) or domains (for processes)
</pre>
  </li>
  </ul>
</td>  
<td>
    OBJECT("FILE") SECURITY CONTEXT:
<pre xxxsmall zoom >
Ej:
#~ ls -Z /etc/logrotate.conf
... <b green>system_u</b> : <b brown>object_r</b> :<b orange>etc_t    </b>: <b blue>s0   </b>    /etc/logrotate.conf
    <b green>^       </b>   <b brown>^       </b>  <b orange> ^       </b>  <b blue>^    </b>
    <b green>user    </b>   <b brown>role    </b>  <b orange>*type*   </b>  <b blue>MLS  </b>
    <b green>context </b>                          <b orange>"classif.</b>  <b blue>level</b>
                                                   <b orange>attribute</b>
</pre>
    SUBJECT(PROCESS) CONTEXTS:
<pre xxxsmall zoom >
#~  ps -efZ | grep 'httpd'
<b green>system_u</b>:<b brown>system_r</b>:<b orange>httpd_t</b>:<b blue>s0 </b> root   ... /usr/sbin/httpd
<b green>system_u</b>:<b brown>system_r</b>:<b orange>httpd_t</b>:<b blue>s0 </b> apache ... /usr/sbin/httpd
<b green>...     </b>
<b green>^       </b> <b brown>^       </b> <b orange>^      </b> <b blue>^  </b>
<b green>user    </b> <b brown>role    </b> <b orange>domain </b> <b blue>MLS</b> 
</pre>
    How Processes Access Resources
    <ul xxxsmall zoom>
      <li> A process/subject (tries to) perform some action (open, read, modify, or execute) on files.
        SELinux access rules follow a standard allow statement structure:
<pre xxxsmall zoom>     
allow <b orange>&lt;domain&gt; &lt;type&gt;</b>:<b blue>&lt;class&gt;</b> { <b green>&lt;permissions&gt;</b> };

<b blue>class := (file, directory, symbolic link, device, ports, cursor ...</b>
</pre>
     Must be read as:<br/>
     <span cite> """ If a process is of certain <b orange>domain</b>
      And the resource object it's trying to access is of certain <b blue>class</b> and <b orange>type</b><br/>
      Then allow the access</br>
      Else deny access """</span>
      </li>
    </ul>
    <code><b>se</b>search</code>:
<pre xxxsmall zoom>
search access allowed for source/target domains:
#~ <b>se</b>search --allow \
   --source <b orange>httpd_t</b>              # domain for apache process
   --target <b orange>httpd_sys_content_t</b>  # type   for /var/www/html files
   --class <b blue>file</b> 
(output will be similar to...)
Found 4 semantic av rules:
   allow <b  orange>httpd_t httpd_sys_content_t</b> : <b blue>file</b> <b green>{ ioctl read getattr lock open }</b> ;
   allow <b  orange>httpd_t httpd_content_type </b> : <b blue>file</b> <b green>{ ioctl read getattr lock open }</b> ;
   allow <b  orange>httpd_t httpd_content_type </b> : <b blue>file</b> <b green>{ ioctl read getattr lock open }</b> ;
   allow <b  orange>httpd_t httpdcontent       </b> : <b blue>file</b> <b green>{ ioctl read write create getattr setattr lock append unlink link rename execute open }</b> ;
</pre }>
    Preserve context in file copy
<pre xxxsmall zoom >
#~ cp <b>--preserver=context</b> /var/www/html/index.html ~/html
(context is preserved with "mv")
</pre>
    changing context of file temporally:
<pre xxxsmall zoom >
# (file system relabel will revert to original context)
#~ chcon --type <b orange>var_t</b> /var/www/html/index.html
# Restore with:
#~ restorecon -v /var/www/html/index.html
restorecon reset /var/www/html/index.html context unconfined_u:object_r:<b orange>var_t</b>:s0->unconfined_u:object_r:<b orange>httpd_sys_content_t</b>:s0
</pre>
  </td>
  <td colspan=2>
    Context database
    <ul xxsmall zoom>
      <li>Conveniently, SELinux "remembers" the context of every file or directory in the server. </li>
      <li> Next ddbb files are used by <code>restorecon</code>:
<pre xxxsmall zoom >
(RedHat/CentOS 7)
(/etc/selinux/targeted/contexts/files/):
/file_contexts      : lists every file type associated with every application supported by the Linux distribution.
/file_contexts.local: Contexts of new directories and files 

Ej: #~ cat /etc/selinux/targeted/contexts/files/file_contexts
...
/usr/(.*/)?lib(/.*)?    system_u:object_r:lib_t:s0
/opt/(.*/)?man(/.*)?    system_u:object_r:man_t:s0
...
</pre>
      </li>
    </ul>
    changing context of file permanently:
<pre xxxsmall zoom >
# <b>STEP 1: write new context to file_contexts.local: (it won't relabel the file itself</b>
#~ <b>se</b>manage <b orange>fcontext</b> --add --type httpd_sys_content_t "/www(/.*)?"
#~ <b>se</b>manage <b orange>fcontext</b> --add --type httpd_sys_content_t "/www/html(/.*)?"
# STEP 1.1: check
#~ cat /etc/selinux/targeted/contexts/files/file_contexts.local
...
/www(/.*)?    system_u:object_r:httpd_sys_content_t:s0
/www/html(/.*)?    system_u:object_r:httpd_sys_content_t:s0
...

# <b>STEP 2:relabel file or directory with what's been recorded in the previous step</b>
#~ restorecon -Rv /www # Will reset context in /www and subdirectories
</pre>
    </td>
    <td colspan=2>
    <b>Domain Transition</b> 
<pre xxxsmall zoom >
proc_a @ contexta_t   → run app_x     → proc_b running @ contextb_t
                            ↑
                        entrypoint to
                         new context 

Ex:
#~ ls -Z /usr/sbin/vsftpd 
-r-x------ root root system_u:object_r:<b orange>ftpd_exec_t</b>:s0 /usr/sbin/vsftpd
                                       <b orange>^entrypoint</b> 
                                       <b orange>to  new    </b> 
                                       <b orange>context    </b>

#~ps -eZ  | egrep "(init_t|vsftpd)"
system_u:system_r:<b orange>init_t</b>:s0 ... systemd
system_u:system_r:<b orange>ftpd_t</b>:s0 ... vsftpd
</pre>
    Domain transition rules:
    <ul xxxsmall zoom>
      <li>source domain (proc_a) must have execute permission for entrypoint (app_x)</li>
      <li>app_x file context must be identified as an entrypoint for the target domain</li>
      <li>original domain (contexta_t) must be allowed to transition to the target domain (contextb_t)</li>
    </ul>
    In the previous example:
<pre xxxsmall zoom>
# Check source domain <b orange>init_t</b> have execute permission on ftpd_exec_t entrypoint:
#~ <b>se</b>search -s init_t -t ftpd_exec_t -c file -p execute -Ad
|(output)
|    allow init_t ftpd_exec_t : file { read getattr execute open } ;

# check binary file is entrypoint for the target domain <b orange>ftpd_t</b>:
#~ <b>se</b>search -s <b orange>ftpd_t</b> -t <b orange>ftpd_exec_t</b> -c file -p <b green>entrypoint</b> -Ad
|(output)
|  allow ftpd_t ftpd_exec_t : file { ioctl read getattr lock execute execute_no_trans <b green>entrypoint</b> open } ;

# check source domain init_t have transition permission to target ftpd_t:
#~ <b>se</b>search -s <b orange>init_t</b> -t <b orange>ftpd_t</b> -c process -p transition -Ad
|(output)
|  allow init_t ftpd_t : process transition ;
</pre>
    <br/>
  </td>
  <td col1 colspan=4 >
    <b>Workflow</b>
    <ol xxsmall zoom >
      <li>Policies are normally tested in permissive mode first, where violations are logged but allowed</li>
      <li><code>audit2allow</code> tool can be used later to produce additional rules that extend the policy to
          allow all legitimate activities of the application being confined</li>
    </ol>
    <hr/>
    <b>Command-line utilities</b><br/>
<pre xxxsmall zoom>
<a href="http://linuxcommand.org/man_pages/chcon1.html">chcon</a>
<a href="http://linux.die.net/man/8/restorecon">restorecon(8)</a>
<a href="http://linux.die.net/man/8/restorecond">restorecond(8)</a>
<a href="http://linux.die.net/man/1/runcon">runcon(1)</a>
<a href="http://linux.die.net/man/1/secon">secon(1)</a>
<a href="http://linux.die.net/man/8/fixfiles">fixfiles(8): fix file security ctxs</a>
<a href="http://linux.die.net/man/8/setfiles">setfiles(8): set file security ctxs</a>
<a href="http://linux.die.net/man/8/load_policy">load_policy(8) </a>
<a href="http://linux.die.net/man/8/booleans">booleans(8) </a>
<a href="http://linux.die.net/man/8/getsebool">getsebool(8) set bool value</a>
<a href="http://linux.die.net/man/8/setsebool">setsebool(8)</a>
<a href="http://linux.die.net/man/8/togglesebool">togglesebool(8) </a>
$ sudo setenforce 1  # put into enforce mode
$ getenforce         # get status
semodule
postfix-nochroot
check-selinux-installation
semodule_package
checkmodule
selinux-config-enforcing
selinuxenabled
selinux-policy-upgrade
</pre>
    
    <b>Troubleshooting</b>:<br/>
   <a href="http://stackoverflow.com/questions/23851452/cant-resolve-domain-names-in-php-under-apache/24019910#24019910">Problems with Apache and DNS:</a>
<pre xxsmall zoom>
# -P => change also boot-time default
$ setsebool -P nis_enabled 0  
$ setsebool -P httpd_can_network_connect 1
</pre>
    Verify current file ctx against file_context(.local) ddbb 
<pre xxxsmall zoom >
#~ matchpathcon -V /www/html/index.html # -V: Verify
In case of mismatch an error similar to next one will be displayed:
/www/html/index.html has context unconfined_u:object_r:default_t:s0, should be system_u:object_r:httpd_sys_content_t:s0 
</pre>
<br/>
</td>  
<!-- 
TODO:
<a href="https://opensource.com/article/18/2/understanding-selinux-labels-container-runtimes">Understanding SELinux labels for container runtimes</a>, <br/>
What happens to a container's MCS label when the container is rebuilt or upgraded?

____________________________________________
SELinux users access fine-tune:


You do not create an SELinux user with a command, 
nor does it have its own login access to the server.

SELinux users are defined in the policy loaded into memory at boot time
, and there are only a few of these users. 

To view this Linux/SELinux user mapping:

#~ <b>se</b>manage login -l

In CentOS 7, this is what we may see:

Login Name           SELinux User         MLS/MCS Range        Service

__default__          unconfined_u         s0-s0:c0.c1023       *
root                 unconfined_u         s0-s0:c0.c1023       *
system_u             system_u             s0-s0:c0.c1023       *

The first column in this table, "Login Name", represents the local Linux user accounts. But there are only three listed here, you may ask, didn't we create a few accounts in the second part of this tutorial? Yes, and they are represented by the entry shown as default. Any regular Linux user account is first mapped to the default login. This is then mapped to the SELinux user called unconfined_u. In our case, this is the second column of the first row. The third column shows the multilevel security / Multi Category Security (MLS / MCS) class for the user. For now, let's ignore that part and also the column after that (Service).

Next, we have the root user. Note that it's not mapped to the "default" login, rather it has been given its own entry. Once again, root is also mapped to the unconfined_u SELinux user.

system_u is a different class of user, meant for running processes or daemons.

To see what SELinux users are available in the system, we can run the semanage user command:

semanage user -l

The output in our CentOS 7 system should look like this:

                 Labeling   MLS/       MLS/
SELinux User    Prefix     MCS Level  MCS Range        SELinux Roles

guest_u         user       s0         s0               guest_r
root            user       s0         s0-s0:c0.c1023   staff_r sysadm_r system_r unconfined_r
staff_u         user       s0         s0-s0:c0.c1023   staff_r sysadm_r system_r unconfined_r
sysadm_u        user       s0         s0-s0:c0.c1023   sysadm_r
system_u        user       s0         s0-s0:c0.c1023   system_r unconfined_r
unconfined_u    user       s0         s0-s0:c0.c1023   system_r unconfined_r
user_u          user       s0         s0               user_r
xguest_u        user       s0         s0               xguest_r

What does this bigger table mean? First of all, it shows the different SELinux users defined by the policy. We had seen users like unconfined_u and system_u before, but we are now seeing other types of users like guest_u, staff_u, sysadm_u, user_u and so on. The names are somewhat indicative of the rights associated with them. For example, we can perhaps assume that the sysadm_u user would have more access rights than guest_u.

To verify our guest, let's look at the fifth column, SELinux Roles. If you remember from the first part of this tutorial, SELinux roles are like gateways between a user and a process. We also compared them to filters: a user may enter a role, provided the role grants it. If a role is authorized to access a process domain, the users associated with that role will be able to enter that process domain.

Now from this table we can see the unconfined_u user is mapped to the system_r and unconfined_r roles. Although not evident here, SELinux policy actually allows these roles to run processes in the unconfined_t domain. Similarly, user sysadm_u is authorized for the sysadmr role, but guestu is mapped to guest_r role. Each of these roles will have different domains authorized for them.

Now if we take a step back, we also saw from the first code snippet that the default login maps to the unconfinedu user, just like the root user maps to the unconfined_u user. Since the **default_** login represents any regular Linux user account, those accounts will be authorized for system_r and unconfined_r roles as well.

So what this really means is that any Linux user that maps to the unconfined_u user will have the privileges to run any app that runs within the unconfined_t domain.

To demonstrate this, let's run the id -Z command as the root user:

id -Z

This shows the SELinux security context for root:

unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023

So the root account is mapped to the unconfined_u SELinux user, and unconfined_u is authorized for the unconfined_r role, which in turn is authorized to run processes in the unconfined_t domain.

We suggest that you take the time now to start four new SSH sessions with the four users you created from separate terminal windows. This will help us switch between different accounts when needed.

    regularuser
    switcheduser
    guestuser
    restricteduser

Next, we switch to the terminal session logged in as the regularuser. If you remember, we created a number of user accounts in the second tutorial, and regularuser was one of them. If you have not already done so, open a separate terminal window to connect to your CentOS 7 system as regularuser. If we execute the same id -Z command from there, the output will look like this:

[regularuser@localhost ~]$ id -Z

unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023

In this case, regulauser account is mapped to the unconfined_u SELinux user account and it can assume the unconfined_r role. The role can run processes in an unconfined domain. This is the same SELinux user/role/domain the root account also maps to. That's because SELinux targeted policy allows logged in users to run in unconfined domains.

We had seen the list of a number of SELinux users before:

    guest_u: This user doesn't have access to X-Window system (GUI) or networking and can't execute su / sudo command.
    xguest_u: This user has access to GUI tools and networking is available via Firefox browser.
    user_u: This user has more access than the guest accounts (GUI and networking), but can't switch users by running su or sudo.
    staff_u: Same rights as user_u, except it can execute sudo command to have root privileges.
    system_u: This user is meant for running system services and not to be mapped to regular user accounts.

SELinux in Action 1: Restricting Switched User Access

To see how SELinux can enforce security for user accounts, let's think about the regularuser account. As a system administrator, you now know the user has the same unrestricted SELinux privileges as the root account and you would like to change that. Specifically, you don't want the user to be able to switch to other accounts, including the root account.

Let's first check the user's ability to switch to another account. In the following code snippet, the regularuser switches to the switcheduser account. We assume he knows the password for switcheduser:

[regularuser@localhost ~]$ su - switcheduser
Password:
[switcheduser@localhost ~]$

Next, we go back to the terminal window logged in as the root user and change regularuser's SELinux user mapping. We will map regularuser to user_u.

semanage login -a -s user_u regularuser

So what are we doing here? We are adding (-a) the regularuser account to the SELinux (-s) user account user_u. The change won't take effect until regularuser logs out and logs back in.

Going back to regularuser's terminal window, we first switch back from switcheduser:

[switcheduser@localhost ~]$ logout

Next the regularuser also logs out:

[regularuser@localhost ~]$ logout

We then open a new terminal window to connect as regularuser. Next, we try to change to switcheduser again:

[regularuser@localhost ~]$ su - switcheduser

Password:

This is what we see now:

su: Authentication failure

If we now run the id -Z command again to see the SELinux context for regularuser, we will see the output is quite different from what we saw before: regularuser is now mapped to user_u.

[regularuser@localhost ~]$ id -Z

user_u:user_r:user_t:s0

So where would you use such restrictions? You can think of an application development team within your IT organization. You may have a number of developers and testers in that team coding and testing the latest app for your company. As a system administrator you know developers are switching from their account to some of the high-privileged accounts to make ad-hoc changes to your server. You can stop this from happening by restricting their ability to switch accounts. (Mind you though, it still doesn't stop them from logging in directly as the high-privileged user).
SELinux in Action 2: Restricting Permissions to Run Scripts

Let's see another example of restricting user access through SELinux. Run these commands from the root session.

By default, SELinux allows users mapped to the guest_t account to execute scripts from their home directories. We can run the getsebool command to check the boolean value:

getsebool allow_guest_exec_content

The output shows the flag is on.

guest_exec_content - -> on

To verify its effect, let's first change the SELinux user mapping for the guestuser account we created at the beginning of this tutorial. We will do it as the root user.

semanage login -a -s guest_u guestuser

We can verify the action by running the semanage login -l command again:

semanage login -l

As we can see, guestuser is now mapped to the guest_u SELinux user account.

Login Name           SELinux User         MLS/MCS Range        Service

__default__          unconfined_u         s0-s0:c0.c1023       *
guestuser            guest_u              s0                   *
regularuser          user_u               s0                   *
root                 unconfined_u         s0-s0:c0.c1023       *
system_u             system_u             s0-s0:c0.c1023       *

If we have a terminal window open as guestuser, we will log out from it and log back in a new terminal window as guestuser.

Next we will create an extremely simple bash script in the user's home directory. The following code blocks first checks the home directory, then creates the file and reads it on console. Finally the execute permission is changed.

Verify that you are in the guestuser home directory:

[guestuser@localhost ~]$ pwd

/home/guestuser

Create the script:

[guestuser@localhost ~]$ vi myscript.sh

Script contents:

#!/bin/bash
echo "This is a test script"

Make the script executable:

chmod u+x myscript.sh

When we try to execute the script as guestuser, it works as expected:

[guestuser@localhost ~]$ ~/myscript.sh

This is a test script

Next we go back to the root terminal window and change the boolean setting allow_guest_exec_content to off and verify it:

setsebool allow_guest_exec_content off
getsebool allow_guest_exec_content

guest\_exec\_content - -> off

Going back to the console logged in as guestuser we try to run the script again. This time, the access is denied:

[guestuser@localhost ~]$ ~/myscript.sh

-bash: /home/guestuser/myscript.sh: Permission denied

So this is how SELinux can apply an additional layer of security on top of DAC. Even when the user has full read, write, execute access to the script created in their own home directory, they can still be stopped from executing it. Where would you need it? Well, think about a production system. You know developers have access to it as do some of the contractors working for your company. You would like them to access the server for viewing error messages and log files, but you don't want them to execute any shell scripts. To do this, you can first enable SELinux and then ensure the corresponding boolean value is set.

We will talk about SELinux error messages shortly, but for now, if we are eager to see where this denial was logged we can look at the /var/log/messages file. Execute this from the root session:

grep "SELinux is preventing" /var/log/messages

The last two messages in the file in our CentOS 7 server show the access denial:

Aug 23 12:59:42 localhost setroubleshoot: SELinux is preventing /usr/bin/bash from execute access on the file . For complete SELinux messages. run sealert -l 8343a9d2-ca9d-49db-9281-3bb03a76b71a
Aug 23 12:59:42 localhost python: SELinux is preventing /usr/bin/bash from execute access on the file .

The message also shows a long ID value and suggests we run the sealert command with this ID for more information. The following command shows this (use your own alert ID):

sealert -l 8343a9d2-ca9d-49db-9281-3bb03a76b71a

And indeed, the output shows us greater detail about the error:

SELinux is preventing /usr/bin/bash from execute access on the file .

*****  Plugin catchall_boolean (89.3 confidence) suggests   ******************

If you want to allow guest to exec content
Then you must tell SELinux about this by enabling the 'guest\_exec\_content' boolean.
You can read 'None' man page for more details.
Do
setsebool -P guest\_exec\_content 1

*****  Plugin catchall (11.6 confidence) suggests   **************************

...

It's a large amount of output, but note the few lines at the beginning:

SELinux is preventing /usr/bin/bash from execute access on the file .

That gives us a pretty good idea where the error is coming from.

The next few lines also tell you how to fix the error:

If you want to allow guest to exec content
Then you must tell SELinux about this by enabling the 'guest\_exec\_content' boolean.
...
setsebool -P guest\_exec\_content 1

SELinux in Action 3: Restricting Access to Services

In the first part of this series we talked about SELinux roles when we introduced the basic terminology of users, roles, domains, and types. Let's now see how roles also play a part in restricting user access. As we said before, a role in SELinux sits between the user and the process domain and controls what domains the user's process can get into. Roles are not that important when we see them in file security contexts. For files, it's listed with a generic value of object_r. Roles become important when dealing with users and processes.

Let's first make sure that the httpd daemon is not running in the system. As the root user, you can run the following command to make sure the process is stopped:

service httpd stop

Next, we switch to the terminal window we had logged in as restricteduser and try to see the SELinux security context for it. If you don't have the terminal window open, start a new terminal session against the system and log in as the restricteduser account we had created at the beginning of this tutorial.

[restricteduser@localhost ~]$ id -Z
unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023

So the account has the default behaviour of running as unconfined_u user and having access to unconfined_r role. However, this account does not have the right to start any processes within the system. The following code block shows that restricteduser is trying to start the httpd daemon and getting an access denied error:

[restricteduser@localhost ~]$ service httpd start
Redirecting to /bin/systemctl start  httpd.service
Failed to issue method call: Access denied

Next we move back to the root user terminal window and make sure the restricteduser account has been added to the /etc/sudoers file. This action will enable the restricteduser account to use root privileges.

visudo

And then in the file, add the following line, save and exit:

restricteduser ALL=(ALL)      ALL

If we now log out of the restricteduser terminal window and log back in again, we can start and stop the httpd service with sudo privileges:

[restricteduser@localhost ~]$ sudo service httpd start


We trust you have received the usual lecture from the local System
Administrator. It usually boils down to these three things:

    #1) Respect the privacy of others.
    #2) Think before you type.
    #3) With great power comes great responsibility.

[sudo] password for restricteduser:
Redirecting to /bin/systemctl start  httpd.service

The user can also stop the service now:

[restricteduser@localhost ~]$ sudo service httpd stop

Redirecting to /bin/systemctl stop  httpd.service

That's all very normal: system administrators give sudo access to user accounts they trust. But what if you want to stop this particular user from starting the httpd service even when the user's account is listed in the sudoers file?

To see how this can be achieved, let's switch back to the root user's terminal window and map the restricteduser to the SELinux user_r account. This is what we did for the regularuser account in another example.

semanage login -a -s user_u restricteduser

Going back to restricteduser's terminal window, we log out and log back in again in a new terminal session as restricteduser.

Now that restricteduser has been restricted to user_u (and that means to role user_r and domain user_t), we can verify its access using the seinfo command from our root user's window:

seinfo -uuser_u -x

The output shows the roles user_u can assume. These are object_r and user_r:

   user_u
      default level: s0
      range: s0
      roles:
         object_r
         user_r

Taking it one step further, we can run the seinfo command to check what domains the user_r role is authorized to enter:

seinfo -ruser_r -x

There are a number of domains user_r is authorized to enter:

   user_r
      Dominated Roles:
         user_r
      Types:
         git_session_t
         sandbox_x_client_t
         git_user_content_t
         virt_content_t
         policykit_grant_t
         httpd_user_htaccess_t
         telepathy_mission_control_home_t
         qmail_inject_t
         gnome_home_t
         ...
         ...

But does this list show httpd_t as one of the domains? Let's try the same command with a filter:

seinfo -ruser_r -x | grep httpd

There are a number of httpd related domains the role has access to, but httpd_t is not one of them:

         httpd_user_htaccess_t
         httpd_user_script_exec_t
         httpd_user_ra_content_t
         httpd_user_rw_content_t
         httpd_user_script_t
         httpd_user_content_t

Taking this example then, if the restricteduser account tries to start the httpd daemon, the access should be denied because the httpd process runs within the httpd_t domain and that's not one of the domains the user_r role is authorized to access. And we know user_u (mapped to restricteduser) can assume user_r role. This should fail even if the restricteduser account has been granted sudo privilege.

Going back to the restricteduser account's terminal window, we try to start the httpd daemon now (we were able to stop it before because the account was granted sudo privilege):

[restricteduser@localhost ~]$ sudo service httpd start

The access is denied:

sudo: PERM_SUDOERS: setresuid(-1, 1, -1): Operation not permitted

So there is another example of how SELinux can work like a gatekeeper.
SELinux Audit Logs

As a system administrator, you would be interested to look at the error messages logged by SELinux. These messages are logged in specific files and they can provide detailed information about access denials. In a CentOS 7 system you can look at two files:

    /var/log/audit/audit.log
    /var/log/messages

These files are populated by the auditd daemon and the rsyslogd daemon respectively. So what do these daemons do? The man pages say the auditd daemon is the userspace component of the Linux auditing system and rsyslogd is the system utility providing support for message logging. Put simply, these daemons log error messages in these two files.

The /var/log/audit/audit.log file will be used if the auditd daemon is running. The /var/log/messages file is used if auditd is stopped and rsyslogd is running. If both the daemons are running, both the files are used: /var/log/audit/audit.log records detailed information while an easy-to-read version is kept in /var/log/messages.
Deciphering SELinux Error Messages

We looked at one SELinux error message in an earlier section (refer to "SELinux in Action 2: Restricting Permissions to Run Scripts"). We were then using the grep command to sift through /var/log/messages file. Fortunately SELinux comes with a few tools to make life a bit easier than that. These tools are not installed by default and require installing a few packages, which you should have installed in the first part of this tutorial.

The first command is ausearch. We can make use of this command if the auditd daemon is running. In the following code snippet we are trying to look at all the error messages related to the httpd daemon. Make sure you are in your root account:

ausearch -m avc -c httpd

In our system a number of entries were listed, but we will concentrate on the last one:

----
time->Thu Aug 21 16:42:17 2014
...
type=AVC msg=audit(1408603337.115:914): avc:  denied  { getattr } for  pid=10204 comm="httpd" path="/www/html/index.html" dev="dm-0" ino=8445484 scontext=system_u:system_r:httpd_t:s0 tcontext=unconfined_u:object_r:default_t:s0 tclass=file

Even experienced system administrators can get confused by messages like this unless they know what they are looking for. To understand it, let's take apart each of the fields:

    type=AVC and avc: AVC stands for Access Vector Cache. SELinux caches access control decisions for resource and processes. This cache is known as the Access Vector Cache (AVC). That's why SELinux access denial messages are also known as "AVC denials". These two fields of information are saying the entry is coming from an AVC log and it's an AVC event.

    denied { getattr }: The permission that was attempted and the result it got. In this case the get attribute operation was denied.

    pid=10204. This is the process id of the process that attempted the access.

    comm: The process id by itself doesn't mean much. The comm attribute shows the process command. In this case it's httpd. Immediately we know the error is coming from the web server.

    path: The location of the resource that was accessed. In this case it's a file under /www/html/index.html.

    dev and ino: The device where the target resource resides and its inode address.

    scontext: The security context of the process. We can see the source is running under the httpd_t domain.

    tcontext: The security context of the target resource. In this case the file type is default_t.

    tclass: The class of the target resource. In this case it's a file.

If you look closely, the process domain is httpd_t and the file's type context is default_t. Since the httpd daemon runs within a confined domain and SELinux policy stipulates this domain doesn't have any access to files with default_t type, the access was denied.

We have already seen the sealert tool. This command can be used with the id value of the error message logged in the /var/log/messages file.

In the following code snippet we again grep through the the /var/log/message file for SELinux related errors:

cat /var/log/messages | grep "SELinux is preventing"

In our system, we look at the very last error. This is the error that was logged when our restricteduser tried to run the httpd daemon:

...
Aug 25 11:59:46 localhost setroubleshoot: SELinux is preventing /usr/bin/su from using the setuid capability. For complete SELinux messages. run sealert -l e9e6c6d8-f217-414c-a14e-4bccb70cfbce

As suggested, we ran sealert with the ID value and were able to see the details (your ID value should be unique to your system):

sealert -l e9e6c6d8-f217-414c-a14e-4bccb70cfbce

SELinux is preventing /usr/bin/su from using the setuid capability.

...

Raw Audit Messages
type=AVC msg=audit(1408931985.387:850): avc:  denied  { setuid } for  pid=5855 comm="sudo" capability=7  scontext=user_u:user_r:user_t:s0 tcontext=user_u:user_r:user_t:s0 tclass=capability


type=SYSCALL msg=audit(1408931985.387:850): arch=x86_64 syscall=setresuid success=no exit=EPERM a0=ffffffff a1=1 a2=ffffffff a3=7fae591b92e0 items=0 ppid=5739 pid=5855 auid=1008 uid=0 gid=1008 euid=0 suid=0 fsuid=0 egid=0 sgid=1008 fsgid=0 tty=pts2 ses=22 comm=sudo exe=/usr/bin/sudo subj=user_u:user_r:user_t:s0 key=(null)

Hash: su,user_t,user_t,capability,setuid

We have seen how the first few lines of the output of sealert tell us about the remediation steps. However, if we now look near the end of the output stream, we can see the "Raw Audit Messages" section. The entry here is coming from the audit.log file, which we discussed earlier, so you can use that section to help you interpret the output here.
Multilevel Security

Multilevel security or MLS is the fine-grained part of an SELinux security context.

So far in our discussion about security contexts for processes, users, or resources we have been talking about three attributes: SELinux user, SELinux role, and SELinux type or domain. The fourth field of the security context shows the sensitivity and optionally, the category of the resource.

To understand it, let's consider the security context of the FTP daemon's configuration file:

ls -Z /etc/vsftpd/vsftpd.conf

The fourth field of the security context shows a sensitivity of s0.

-rw-------. root root system_u:object_r:etc_t:s0       /etc/vsftpd/vsftpd.conf

The sensitivity is part of the hierarchical multilevel security mechanism. By hierarchy, we mean the levels of sensitivity can go deeper and deeper for more secured content in the file system. Level 0 (depicted by s0) is the lowest sensitivity level, comparable to say, "public." There can be other sensitivity levels with higher s values: for example, internal, confidential, or regulatory can be depicted by s1, s2, and s3 respectively. This mapping is not stipulated by the policy: system administrators can configure what each sensitivity level mean.

When a SELinux enabled system uses MLS for its policy type (configured in the /etc/selinux/config file), it can mark certain files and processes with certain levels of sensitivity. The lowest level is called "current sensitivity" and the highest level is called "clearance sensitivity".

Going hand-in-hand with sensitivity is the category of the resource, depicted by c. Categories can be considered as labels assigned to a resource. Examples of categories can be department names, customer names, projects etc. The purpose of categorization is to further fine-tune access control. For example, you can mark certain files with confidential sensitivity for users from two different internal departments.

For SELinux security contexts, sensitivity and category work together when a category is implemented. When using a range of sensitivity levels, the format is to show sensitivity levels separated by a hyphen (for example, s0-s2). When using a category, a range is shown with a dot in between. Sensitivity and category values are separated by a colon (:).

Here is an example of sensitivity / category pair:

user_u:object_r:etc_t:s0:c0.c2  

There is only one sensitivity level here and that's s0. The category level could also be written as c0-c2.

So where do you assign your category levels? Let's find the details from the /etc/selinux/targeted/setrans.conf file:

cat /etc/selinux/targeted/setrans.conf

#
# Multi-Category Security translation table for SELinux
#
#
# Objects can be categorized with 0-1023 categories defined by the admin.
# Objects can be in more than one category at a time.
# Categories are stored in the system as c0-c1023.  Users can use this
# table to translate the categories into a more meaningful output.
# Examples:
# s0:c0=CompanyConfidential
# s0:c1=PatientRecord
# s0:c2=Unclassified
# s0:c3=TopSecret
# s0:c1,c3=CompanyConfidentialRedHat
s0=SystemLow
s0-s0:c0.c1023=SystemLow-SystemHigh
s0:c0.c1023=SystemHigh

We won't go into the details of sensitivities and categories here. Just know that a process is allowed read access to a resource only when its sensitivity and category level is higher than that of the resource (i.e. the process domain dominates the resource type). The process can write to the resource when its sensitivity/category level is less than that of the resource.
Conclusion

We have tried to cover a broad topic on Linux security in the short span of this three-part-series. If we look at our system now, we have a simple Apache web server installed with its content being served from a custom directory. We also have an FTP daemon running in our server. There were a few users created whose access have been restricted. As we went along, we used SELinux packages, files, and commands to cater to our security needs. Along the way we also learned how to look at SELinux error messages and make sense of them.

Entire books have been written on the SELinux topic and you can spend hours trying to figure out different packages, configuration files, commands, and their effects on security. So where do you go from here?

One thing I would do is caution you not to test anything on a production system. Once you have mastered the basics, start playing with SELinux by enabling it on a test replica of your production box. Make sure the audit daemons are running and keep an eye on the error messages. Check any denials preventing services from starting. Play around with the boolean settings. Make a list of possible steps for securing your system, like creating new users mapped to least-privilged SELinux accounts or applying the right context to non-standard file locations. Understand how to decipher an error log. Check the ports for various daemons: if non-standard ports are used, make sure they are correctly assigned to the policy.

It will all come together with time and practice. :)
-->
</table>

</body>
<!--

____________________________________________


______________________
TODO: HHRR
Ioannis Koustoudis: LFCS­Linux sysadmin from Kavala, Greece. He works for the ministry of education and supports almost 200 school units in their infrastructure. If he is not in front of a computer screen, he plays music (he is a multi­-instrumentalist) or take care of his two lovely kids.
_______________________
https://lists.gnu.org/archive/html/bug-coreutils/2008-09/msg00085.html
Re: Bug in date?
From:   James Youngman
Subject:    Re: Bug in date?
Date:   Tue, 9 Sep 2008 19:52:53 +0100

On Tue, Sep 9, 2008 at 1:47 PM, Enrique Arizón Benito
<address@hidden> wrote:

> Upps, I forgot it.
>
>  #date -s "1970-01-01 00:00:01"
>  date: cannot set date: Invalid argument

It looks like date is simply reporting an error that it received from
the operating system.   The strace utility (or some platform-specific
replacement if you are not using Linux) should be able to confirm
this.

>  Thu Jan 1 00:00:01 CET 1970
>
> Curiosly after the Invalid argument error, date properly prints the new hour
> but doesn't change it.

This is almost certainly because the date program understands the date
you refer to, but failed in its attempt to set the system clock to
that value.

> That's what makes me think it's really a bug.

More likely it's because CET is 1h ahead of UTC and therefore the time
you specified is before the Epoch.    But Eric already said that, so
perhaps you ruled out that possibility but did not say so.

James


_________________________

Turning on Linux ACLs:
   https://wiki.archlinux.org/index.php/Access_Control_Lists
_____________________
$ ps -efZ | grep sshd
system_u:system_r:sshd_t:s0-s0:c0.c1023 root 80388   1  0 Mar14 ?        00:00:00 /usr/sbin/sshd -D
system_u:system_r:sshd_t:s0-s0:c0.c1023 root 93132 80388  0 14:11 ?      00:00:00 sshd: azureuser [priv]
unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 azureus+ 93137 93132  0 14:11 ? 00:00:00 sshd: azureuser@notty
_________________
https://upload.wikimedia.org/wikipedia/commons/3/30/IO_stack_of_the_Linux_kernel.svg
______________________
https://www.infoq.com/news/2015/02/under-hood-containers
_____________
https://en.wikipedia.org/wiki/Executable_and_Linkable_Format
___________
How to configure and Install Config Server Firewall & Login failure Daemon
https://techarena51.com/blog/how-to-configure-and-install-config-server-firewall-login-failure-daemon/?utm_source=devopswiki
_____________
https://grsecurity.net/
Grsecurity® is an extensive security enhancement to the Linux kernel that defends against a wide range of security threats through intelligent access control, memory corruption-based exploit prevention, and a host of other system hardening that generally require no configuration.

It has been actively developed and maintained for the past 17 years. Commercial support for grsecurity is available through Open Source Security, Inc


Comparation grsecurity SELinux AppArmor KSPP
   https://www.grsecurity.net/compare.php

https://en.wikipedia.org/wiki/Grsecurity#PaX
   """A major component bundled with grsecurity is PaX. Among other features, 
  the patch flags data memory, the stack, for example, as non-executable and 
  program memory as non-writable. The aim is to prevent memory from being 
  overwritten, which can help to prevent many types of security vulnerabilities,
  such as buffer overflows. PaX also provides address space layout randomization
  (ASLR), which randomizes important memory addresses to reduce the probability
  of attacks that rely on easily predicted memory addresses."""

Hardening Debian for the Desktop Using Grsecurity
   https://micahflee.com/2016/01/debian-grsecurity/
_________________
  "Real time" backup with rsync and bash:
  https://github.com/Leo-G/backup-bash
________
  Important files in /etc:
/etc/hosts
/etc/...
___________________
http://clusterlabs.org/
The ClusterLabs stack unifies a large group of Open Source projects related to High Availability into a cluster offering suitable for both small and large deployments. Together, Corosync, Pacemaker, DRBD, ScanCore, and many other projects have been enabling detection and recovery of machine and application-level failures in production clusters since 1999. The ClusterLabs stack supports practically any redundancy configuration imaginable.
__________________
https://www.linbit.com/en/products-and-services/drbd-sds/
High Availability for software-defined storage

The revolutionary Block Storage Replication tool. Companies implement 
oftware-defined storage (SDS) in order to easily provision and manage data 
storage, independent of the underlying hardware. LINBIT’s groundbreaking SDS 
product ties together data availability, performance, and scale, making it 
perfect for your cloud storage environment.
____________________________________________________
https://www.tutorialspoint.com/operating_system/pdf/os_linux.pdf
____________________________________________________
How to Use Systemd Timers as a Cron Replacement
https://www.maketecheasier.com/use-systemd-timers-as-cron-replacement/
____________________________________________________
GNU Findutils: Finding files in FS
https://www.gnu.org/software/findutils/manual/html_mono/find.html

Ex: https://serverfault.com/questions/295929/how-do-i-find-and-report-on-broken-symbolic-links-automatically/433273
______________________________________

http://www.enterprisestorageforum.com/storage-technology/open-source-storage-64-applications.html

       Open Source Storage: 64 Applications for Data Storage
       19-24 minutes
       
       As data storage needs continue to grow and many organizations move toward software-defined infrastructure, more enterprises are using open source software to meet some of their storage needs. Projects like Hadoop, Ceph, Gluster and others have become very common at large enterprises.
       
       Home users and small businesses can also benefit from open source storage software. These applications can make it possible to set up your own NAS or SAN device using industry-standard hardware without paying the high prices vendors charge for dedicated storage appliances. Open source software also offers users the option to set up a cloud storage solution where they have control over security and privacy, and it can also offer affordable options for backup and recovery.
       
       The list below features 64 open source storage projects that are among the best options available for enterprises, SMBs and individual users. Please note that this is not a ranking. Entries are organized into categories and then alphabetized within the categories.
       undefined 100%
       
       If you know of additional open source storage applications that you believe should be on our list, feel free to note them in the Comments section below.
       NAS/SAN Software
       
       1. Ceph
       Red Hat's Ceph offers unified object and block storage capabilities. It's a distributed storage solution that boasts excellent performance, scalability and reliability. Well-known users include Cisco, DreamHost, CERN, Bloomberg, and Deutsche Telekom. Operating System: Linux
       
       2. CryptoNAS
       This project aims to simplify the process of setting up an encrypted fileserver. It comes in a live-CD package or a server package that adds a web front-end. Operating System: Linux
       
       3. ESOS
       Short for Enterprise Storage OS, ESOS is a Linux distribution for setting up a storage array on your own hardware. Commercial support is available. Operating System: Linux
       
       4. FreeNAS
       FreeNAS claims to be the "the World's #1 storage OS with over 10+ million downloads." It counts the United Nations, the University of Florida, the Salvation Army, Reuters, Michigan State University, the Department of Homeland Security and many other organizations among its users. It can be installed on nearly any hardware to turn it into a network attached storage (NAS) device. Paid, supported enterprise solutions based on the same technology are available under the TrueNAS brand name. Operating System: FreeBSD
       
       5. NAS4Free
       Another option for do-it-yourself NAS, NAS4Free claims to be "the simplest and fastest way to create a centralized and easily-accessible server for all kinds of data." Key features include the ZFS file system, software RAID (levels 0, 1 or 5) and disk encryption. Operating System: FreeBSD
       
       6. Openfiler
       As a unified storage solution, Openfiler aims to combine the best features of NAS storage with the best features on SAN storage. Key features include high availability/failover, block replication and Web-based management. Its users include Motorola, Pratt & Whitney, Bill Me Later and the London Metropolitan Police. A paid commercial edition is available. Operating System: Linux
       
       7. OpenMediaVault
       Based on Debian Linux, OpenMediaVault describes itself as a "next-generation network attached storage (NAS) solution." It was designed to provide NAS for home users or small offices. It offers a Web-based administration console and includes software RAID capabilities. Operating System: Linux
       
       8. Turnkey Linux File Server
       The Turnkey Linux project offers images for setting up Linux-based servers for a variety of purposes, including an image for creating a simple NAS device. It includes support for SMB, SFTP, NFS, WebDAV and rsync file transfer protocols. Operating System: Linux
       Filesystems
       
       9. Btrfs
       A joint project supported by Facebook, Fujitsu, Intel, the Linux Foundation, Netgear, Novell, Oracle, Red Hat and others, Btrfs is a copy on write (CoW) filesystem for Linux. It focuses on "fault tolerance, repair and easy administration." Operating System: Linux
       
       10. Ext4
       Included in most popular Linux distributions, Ext4 supports file systems up to 1 EB in size with up to 16 TB per file. Other key features include extents, multiblock allocation, delayed allocation, Fast fsck, journal checksumming, "no journaling" mode, online defragmentation and more. Operating System: Linux
       
       11. GlusterFS
       A Red Hat project, GlusterFS is a highly scalable file system built for applications like media streaming and big data analytics. Professional support is available through third-party vendors. It has a large and active user community, and the website includes links to many Gluster-related blogs. Operating System: Linux
       
       12. Lustre
       Built to handle the needs of high-performance computing (HPC) environments, Lustre is a scalable parallel file system. It was first developed at Carnegie Mellon University, and its first users included various U.S. Department of Energy National Laboratories. The latest version, released in April, supports Data on MDT, file-level redundancy, lock ahead and more. Operating System: Linux
       
       13. ZFS
       Also incorporated into many Linux distributions, including Arch, Debian, Fedora, Ubuntu and others, ZFS is another highly scalable file system. It includes compression, protection against data corruption, snapshots, RAID support and more. Operating System: Linux, macOS, FreeBSD
       RAID
       
       14. DRBD
       DRBD is an open source solution for building high-availability storage clusters based on RAID-1. Commercial products, including software-defined storage, disaster recovery and high availability solutions based on the same technology, are available through project sponsor Linbit. Operating System: Linux
       
       15. Mdadm
       Built into the Linux kernel, mdadm makes it easy to create, manage and monitor storage arrays. It can also move spares between RAID arrays. More information is also available on the Linux RAID wiki. Operating System: Linux
       
       16. Raider
       Raider is a bash shell script that allows users convert any Linux disk into a RAID array with software RAID 1, 4, 5, 6 or 10. It works with many of the most popular Linux distributions, including Ubuntu, Debian, OpenSUSE, Fedora, Linux Mint and others. Operating System: Linux
       
       17. RaidEye
       RaidEye isn't so much a tool for creating RAID devices as a utility for monitoring RAID volumes. It works with the RAID capabilities built into macOS and notifies users of problems via a sound alarm, popup dialog and email. Operating System: macOS
       
       18. SnapRAID
       SnapRAID arrays can recover from up to six disk failures. The tool was built for home media servers or other environments with a lot of big files that rarely change. Key features include data hashing, the ability to recover deleted files and no lock-in. Operating System: Windows, Linux, macOS
       Backup and Synchronization
       
       19. AMANDA
       The Advanced Maryland Automatic Network Disk Archiver, or AMANDA, is a popular network backup solution that can save data from Linux, Unix or Windows systems to hard drives, tape or optical media. It was last updated in December 2017. Zmanda, which sponsors the project, offers commercial products based on the same technology. Operating System: Windows, Linux, macOS.
       
       20. Areca Backup
       Designed for personal use, Area is a simple but versatile backup solution. Key features include delta backup, compression, encryption, filters, as-of-date recovery and more. Operating System: Windows, Linux
       
       21. BackupPC
       Robust enough for enterprise use, BackupPC backs up data from Linux and Windows systems to disk. Noteworthy features include a unique pooling scheme, optional compression, a web interface and support for mobile devices. It claims to be highly configurable and easy to install and maintain. Operating System: Windows, Linux
       
       22. Bacula
       Another option for enterprises, Bacula is a network backup solution that aims to be easy to use and very efficient. It claims to be the most popular open source backup program. Commercial support and services for the solution are available through Bacula Systems. Operating System: Windows, Linux, macOS
       
       23. Bareos
       Forked from Bacula, Bareos is a popular open source backup option that is under very active development with the latest version released in February 2018. The Bareos.com website offers paid support and services for the tool. Operating System: Windows, Linux, macOS
       
       24. Box Backup
       This "completely automatic" backup solution creates backups continuously and can also create snapshots when desired. It includes encryption and optional RAID capabilities, and old file versions and deleted files remain available. Operating System: Windows, Linux
       
       25. BURP
       Short for "BackUp And Restore Program," BURP is a network backup solution. It offers a choice of two different protocols: one based on librsync (see below) and one that uses variable length chunking for inline deduplication. It is designed to be easier to configure than some other open source solutions, and it can do delta backups. Operating System: Windows, Linux
       
       26. Clonezilla
       Designed to replace Acronis True Image or Norton Ghost, Clonezilla is useful for both system deployment and backup and recovery. It comes in two flavors: live for standalone systems and SE for network backup or cloning multiple systems at once. The SE version can clone 40 or more systems at once. Operating System: Linux
       
       27. Create Synchronicity
       Powerful but lightweight, this backup tool takes up only 220KB of space on your hard drive. It supports multiple languages, has an intuitive interface and includes a scheduler. It is also helpful for syncing photos, music and other files across devices. Operating System: Windows
       
       28. DAR
       Disk Archive, a.k.a. DAR, is an older command-line tool for backup, but it is still being updated regularly with the most recent version released in April 2018. For those who prefer a GUI, one is available through the DarGUI project. Operating System: Windows, Linux, macOS
       
       29. DirSync Pro
       This "small but powerful," utility offers incremental backup, filtering and scheduling capabilities. It also boasts an intuitive interface, and it offers the ability to analyze two sets of files or folders and detect the changes between them. It also includes a helpful real-time synchronization option. Operating System: Windows
       
       30. Duplicati
       Duplicati works with cloud storage services like AWS S3, Microsoft OneDrive, Google Drive and Box to create backups with AES-256 encryption. It does a full backup on first use and incremental backups after that; it also offers data deduplication capabilities. Operating System: Windows, Linux, macOS
       
       31. FOG
       FOG offers cross-platform cloning and imaging capabilities plus remote management for networks of any size. It offers support through forums and a wiki. Operating System: Linux, Windows, macOS.
       
       32. FreeFileSync
       A tool for standalone systems, FreeFileSync aims to save users time when setting up and running backups. It is cross-platform and includes 64-bit support. Tutorials and a manual are available on the website. Operating System: Linux, Windows, macOS
       
       33. FullSync
       Although it was designed to help web developers push updates to their sites, FullSync can also be used by anyone to create backups. Key features include multiple modes, flexible rules, buffered filesystems, support for multiple file transfer protocols and more. Note that development on this project has slowed somewhat as it hasn’t been updated since April 2016. Operating System: Linux, Windows, macOS
       
       34. Grsync
       Grsync takes the older rsync synchronization tool and adds an easy-to-use GUI. Noteworthy features include unlimited sessions, highlighted errors, batch capabilities, simulations, support for multiple languages and more. Operating System: Linux, Windows, macOS
       
       35. Mondo Rescue
       For Linux and FreeBSD only, Mondo Rescue is a disaster recovery solution that supports tape, disk, network or optical media backups. According to its website, its users include "Lockheed-Martin, Nortel Networks, Siemens, HP, IBM, and dozens of smaller companies." The most recent update was released in April 2016. Operating System: Linux, Free BSD
       
       36. Partimage
       This tool saves partitions of drives as image files, making it useful for backup or installing the same image on multiple systems. It can run across networks or on a standalone PC. It can also be used to create a SystemRescueCD. Operating System: Linux
       
       37. Redo
       Redo boasts that its bare-metal restore capabilities can get a crashed system back up and running in as little as 10 minutes. It's very easy to use and can also recover deleted images and files. Operating System: Windows, Linux
       
       38. Rsync
       Rsync is a Unix-based file-transfer utility with synchronization capabilities that make it suitable for creating backups or mirroring. It's a useful tool but is best used by advanced users. The most recent version was released in January 2018. Operating System: Linux, Windows, macOS
       
       39. Synkron
       While this app is focused primarily on synchronization, it can be used for creating backups as well. Key features include analysis capabilities, blacklisting, restores and cross-platform support. Documentation is available in both German and English. Operating System: Windows, Linux, macOS
       
       40. Unison
       Like Synkron, Unison is a file synchronization tool. It can copy files between any two systems connected to the internet, and it has features in common with source code management tools as well as with backup utilities. Its advantage over some other synchronization tools is that it can combine two sets of files where both sets have undergone changes. Operating System: Windows, Unix
       
       41. UrBackup
       This client-server backup solution does both image and file backups. It promises "both data safety and a fast restoration time." It makes backups while the system is in use without interrupting normal operation. Operating System: Windows, Linux
       
       42. Weex
       The Weex developers intended it primarily as a tool for pushing content to websites, but it can also be used to synchronize or backup files. It supports FTP file transfer and uses caching to speed data transfer. Operating System: Windows, Linux
       Online/Cloud Data Storage
       
       43. CloudStack
       This Apache Foundation project is open source cloud computing platform that includes cloud storage capabilities. Noteworthy features include compute orchestration, network as a service capabilities, user and account management, resource accounting and support for multiple hypervisors. Operating System: Windows, Linux
       
       44. CloudStore
       This Dropbox alternative synchronizes data between a system and online storage. It promises strong encryption, password-less authentication, flexible synchronization, fast setup and auto-resumes for interrupted data transfers. Operating System: Linux
       
       45. Cozy
       Cozy is both an open source project for storing personal data online and a free service for managing and securing sensitive data. Note that the free hosting is for up to 5GB of data; additional storage will require a fee. Operating System: Linux
       
       46. FTPbox
       Want to set up your own cloud storage server? FTPbox makes it easy to be your own cloud provider, with all files transferred via FTP. Operating System: Windows
       
       47. OpenStack
       Probably the best-known open source cloud computing platform, OpenStack offers a complete operating system for controlling compute, networking and, of course, storage in the cloud. It incorporates three sub-projects related to storage: Cinder, Swift and Manila. Operating System: Windows
       
       48. Perkeep
       Formerly known as Camlistore, Perkeep describes itself as "a set of open source formats, protocols, and software for modeling, storing, searching, sharing and synchronizing data in the post-PC era." It's still under very active development and will require some technical knowhow to use. Operating System: Linux
       
       49. Pydio
       Downloaded more than a million times, Pydio counts the University of Cambridge, Seagate, Guitar Center, Washington State University and Nikon among its users. It offers cloud-based file management and sharing. A paid enterprise distribution is available. Operating System: Windows, Linux (Android and iOS clients available)
       
       50. Rockstor
       Rockstor makes it possible to create your own NAS or cloud storage solution based on Linux and BTRFS. It comes in both personal and SMB versions. Operating System: Linux
       
       51. SeaFile
       SeaFile describes itself as "an enterprise file hosting platform with high reliability and performance." You can download the code for free or use the paid pro edition that includes support. Operating System: Windows, Linux, macOS, Android, iOS
       
       52. SparkleShare
       SparkleShare creates a special folder on your system that is automatically synchronized with a host folder stored on your server or in the cloud. It includes encryption capabilities, and it is a good option for collaborating on documents that change frequently. Operating System: Windows, Linux, macOS
       
       53. StackSync
       Create your own scalable personal cloud with StackSync. It encrypts all data on the client side and works with cloud storage services or your own server. Operating System: Windows, Linux
       
       54. Syncthing
       Like many of the other projects in this category, Syncthing offers an alternative to Dropbox. It keeps data completely private with encryption and authentication requirements. Operating System: Windows, Linux, macOS
       Storage Management
       
       55. Libvirt Storage Management
       Libvirt is an API for creating storage pools and volumes on a host system. It supports a wide variety of storage pool types including directory, filesystem, network filesystem, logical volume, disk, iSCSI, SCSI, Gluster, ZFS and more. Operating System: Linux
       
       56. openAttic
       This tool offers management and monitoring capabilities for the Ceph distributed storage platform. It offers a dashboard, as well as tools for managing pools, block devices, iSCSI, NFS, Ceph Object Gateway and Ceph nodes. Operating System: Linux
       Distributed Storage/Big Data Tools
       
       57. Alluxio
       Alluxio (Formerly known as Tachyon) describes itself as "open-source memory-speed virtual distributed storage." It works with tools like Spark, Hadoop, Flink, Zeppelin and Presto to speed performance on big data queries. Operating System: Linux, macOS
       
       58. Hadoop
       Nearly synonymous with big data, Hadoop is a widely used open source distributed storage platform for processing data. It is an Apache Foundation project, and the organization also oversees dozens of related projects. Operating System: Windows, Linux, macOS
       
       59. HPCC
       This Hadoop alternative also offers distributed storage and massive scalability. Paid enterprise services are available. Operating System: Linux
       
       60. Sheepdog
       The Sheepdog website describes this project as "a distributed object storage system for volume and container services and manages the disks and nodes intelligently." It supports snapshotting, cloning and thin provisioning, and it is compatible with OpenStack Swift and Amazon S3. Operating System: Linux
       Compression
_______________________
https://docs.fedoraproject.org/f27/system-administrators-guide/

https://wiki.centos.org/AdditionalResources/Repositories/SCL
__________
https://en.wikipedia.org/wiki/Avahi_(software) ZeroConf Linux impl.
__________
https://www.2daygeek.com/zstandard-a-super-faster-data-compression-tool-for-linux/
Zstandard super-fast compression tool
__________
TODO: journalctrl
the journal is "synchronous". Eacth time someone tries to write it checks if
ther is space or something needs to be deleted. (vs remove each 24 day,...)
 $ journalctrl [tab] ...
______________
https://gluster.readthedocs.io
____________
List and sort the versions available in
your repo:

YUM: sorting by version number:                    | APT:
                                                   | 
$ yum list docker-ce --showduplicates | sort -r    | apt-cache madison docker-ce
________________________
yum upgrade forces the removal of obsolete packages, while yum update may or may not also do this. The removal of obsolete packages can be risky, as it may remove packages that you use.

This makes yum update the safer option.

From man yum:

    update

    If run without any packages, update will update every currently installed package. If one or more packages or package globs are specified, Yum will only update the listed packages. While updating packages, yum will ensure that all dependencies are satisfied. (See Specifying package names for more information) If the packages or globs specified match to packages which are not currently installed then update will not install them. update operates on groups, files, provides and filelists just like the "install" command. If the main obsoletes configure option is true (default) or the --obsoletes flag is present yum will include package obsoletes in its calculations - this makes it better for distro-version changes, for example: upgrading from somelinux 8.0 to somelinux 9.

    upgrade

    Is the same as the update command with the --obsoletes flag set. See update for more details




</html>
