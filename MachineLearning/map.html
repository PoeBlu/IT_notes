<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>DeepLearning_theory_map(alpha) <!-- ignore --></title>
<a href="https://ml-cheatsheet.readthedocs.io">https://ml-cheatsheet.readthedocs.io</a>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>

<body>
<br/>
 Mathematical Foundations
<table>
<tr>
<td>
 Linear Algebra
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Lagrange Optimization
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Probability Theory
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Gaussian Derivatives and Integrals
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Hypothesis Testing
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Information Theory
<pre xxxsmall zoom>
</pre>
</td>

<td>
 Computational Complexity
<pre xxxsmall zoom>
</pre>
</td>

</tr>
</table>
<br/> <br/>

<table>
<tr>
<td>
  DECISION THEORY
<pre xxxsmall zoom bgorange>
There is an overall single cost associated with our decision,
and our true task is to make a decision rule (i.e., set a decision boundary)
so as to minimize such a cost.

This is the central task of decision theory of which pattern
classification is (perhaps) the most important subfiled.

Classification is, at base, the task of recovering the model that generated
the patterns.

Different classification techniques are useful depending on the
type of candidate models themselfs.

 Statistical pattern recognition models focus on the statistical
   properties of the patterns. When not enought (training) data is available,
 knowledge of the problem domain is also used.

 Other models focus on the logical rules like syntactic pattern recognition,
  where rules or grammars describe our decision. 

 Patter classification differs from classical statistical *hypothesis testing*,
wherein the sensed data are used to decide whether or not to reject a *null hypothesis*
in favor of some alternative hypothesis. In this case, if the null-Hypothesis falls
below a "significance" threshold, we reject the null-hypothesis in favor of the
alternative.


 Because perfect classification performance is often impossible, a more general
task is to determine the probability for each of the possible categories.

sensing -> segmentation -> feature extraction -> classification -> post-processing
           ^^^^^^^^^^^^                                            (costs)        
           "one of the deepest                                                    
           problems in pattern
           recognition"

The design of a pattern recognition system usually entails the repetition of a
number of different activities: 
 - data collection: "large cost" of the development.
 - feature choice : Choice of distinguishing features.
 - model   choice : How to know whether a given model performs better
 - training       : Process of using data to determine the classifier
 - evaluation 

</pre>

  Vocabulary
<pre xxxsmall zoom>

Feature:  Or Property is the data output from a "feature extractor" process
         Values are passed to a classfier.

Model: Determines the set of features used for the classifier.
      It can be a single specific set of features.

Feature-vector: A given vector (ordered set of features). The "dimensions" of
    the vector are provided by the model.

Feature-space: N-dimensional space of  feature inputs.
      Classification can be seen as the split of the feature-space in
      regions where the decision-cost is minimized.

Classifier: Takes feature values inputs and evaluates the "evidence" to make
            a decision or classification, assigning the input feature-vector to
            an output classification.
          The central aim of designing a classifier is to suggest actions when
          presented with not-yet-seen patterns. This is the issue of generalization.

Segmentation: Part of the pre-processing where objects of interest are "extracted"
            from background.

Feature Extraction: Process that takes-in a pattern and produces feature values.
    Number of features is virtually always chosen to be fewer than the total 
    necessary to describe the complete taret of interest, and this leads to a loss
    in information. 

     In acts of associate-memory, the ssytem takes-in a pattern and emits another 
    pattern which is representative of a general group of patterns. It thus reduces
    the information somewhat, but rarely to the extent that pattern classification
    does. In short, because of the crucial role of a decision in pattern recognition
    information, it is fundamentally an information reduction process.

    The conceptual boundary between feature-extraction and classification is arbitrary.


Subset and SUperset problem: Formally part of *mereology*, the study of part/whole
    relationships. It appears as though the best classifiers try to incorporate
    as much of the input into the categorization as "makes sense" but not too much.

Risk: Total spected cost  of making a wrong classification/Decision.

stochastic: The property of having a random probability distribution or pattern
      that may be analysed statistically but may not be predicted precisely.
</pre>
 
  Regression , Interpolation , Density Estimation
<pre xxxsmall zoom>
Regression: We seek to find some functional description of data, often with the
    goal of predicting values for new input. 
    Linear regression - in which the function is linear in the input variables-
    is the most popular and well studied form or regression.
Interpolation: In this case we known or can easily deduce, the function for 
    certain ranges of input; the problem is then to infer the function for intermediate
    ranges of input. 

Density estimation: is the problem of estimating the density (or probability) that
    a memeber of a certain category will be found to have particular features.
</pre>

   Learning 
<pre xxxsmall zoom>
Learning: "Any method" that incorporates information from training samples in the
     design of a classifier.
     Formally, it refers to some form of algorithm for reducing the error on a 
     set of training data. 

Supervised-learning:  A teacher provides a category label or cost for each pattern
    in a training set, and seeks to reduce the sum of the cost for thes patterns.

UnSupervised-learning (Clustering): There is no explicit teacher, and the system
    forms clusters or "natural groupings" of the input patterns.
    "Natural" is always defined explicitly or implicitly in the clustering system
    itself.
    Different clusting algorithms lead to different Clusters.

Reinformcement Learning:
    The most typical way to train a classifer is to present an input, 
     compute its tentative category label, and use th known target categorylabel to
    inprove
    might be an images of a character, the actual output of the classifier the 
    category label "R" and the desired otuput a "B". In the reinforcement learning
    or learning-with-a-critic, no desired category signal is given; instead, the
    only teaching feedback is that the tentative category is right or wrong.

gradient-descent: A range of *gradient-descent* algorithms that alter a 
     classifier's parameters in order to reduce an error measure now permeate the
     field of statistical pattern recognition.

</pre>
<br/><br/>

  Who-is-Who
<pre xxxsmall zoom>
  - <a href="https://en.wikipedia.org/wiki/Richard_O._Duda">Richard O. Duda</a>: Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81332496778">ACM Digital Library Refs</a>

  - <a href="https://en.wikipedia.org/wiki/Peter_E._Hart"  >Peter E. Hart</a>  : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100122968">ACM Digital Library Refs</a>

  - David G. Stork : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100152072">ACM Digital Library refs</a>
</pre>
</td>

<td>
  Bayesina Decision Theory
<pre xxxsmall zoom>
- Ideal case in which the probability structure underlying the categories is known perfectly.

  <b>While not very realistic, it permits us to determine the optimal (Bayes) classifier
  against which we can compare all other classifiers.</b>

</pre>
</td>
<td>
  Maxium-likelihood and Bayesian Parameter Estimation
<pre xxxsmall zoom>
- We address the case when the full probability structure underlying the
  categories is not known, but the general forms of their distributions are.
  Thus the uncertainty about a probability distribuition is represented by 
  the values of someh unkown parameter, and we seek to deteermine these parameters
  to attain the best categorization.
</pre>
</td>
<td>
  NonParametric Techniches
<pre xxxsmall zoom>
- We have no prior parameterized knowledge about the underlying probability
  structure;
  Our classification will be based on information provided by training samples alone.
</pre>
</td>
<td>
  Linear Discriminant Functions
<pre xxxsmall zoom>
- General approach of parameter estimation. We shall assume that the so-called
  "discriminat functions" are of a very particular form - namely linear-
  in order to derive a class of incremental training rules.
</pre>
</td>
</tr>
</table>
<table>
<tr>
<td>
  Multilayer Neural Networks
<pre xxxsmall zoom>
- We extend the "linear discrimant functions" to a class of very powerful
  algorithms for training multilayer neural networks;
</pre>
</td>

<td>
  Stochastic Methods
<pre xxxsmall zoom>
- We discuss simulate annealing, the Boltmann learning algorithm and other
  sotchastic methods which can avoid some the estimation problems that plague
  other neural methods.
</pre>
</td>

<td>
  Nonmetric Methods
<pre xxxsmall zoom>
- We move from statistical to logical rules.
  - tree-based algorithms (CARTS)
  - syntactic-based methods based on grammars.
</pre>
</td>

<td>
  Algorithm-independent Machine Learning
<pre xxxsmall zoom>
- <b>The "most" important and difficult chapter of the book</b>.
- Some of the results described here - those related to bias and variance,
 degress of freedom, the desire for "simple" classifers, and computatinal
 complexity- are subtle and crucial both theorically and practically.
  The rest of the concepts can ONLY be fully understood (or used) in light
 of the results presented here.
</pre>
</td>

<td>
  Unsupervised Learnind and Clustering
<pre xxxsmall zoom>
- Address the case when input training patterns are not labeled, and
  where our recognizer must determine the cluster structure. We also treat
  a related problem, that of learning with a critic, in which the teacher 
  provides only a single bit of information during the presentation of a
  training pattern - "yes", to indicate that the classification provided
  is correct or "not" otherwise.
</pre>
</td>

</tr>
</table>

</body>

<!--
REF: https://media.consensys.net/using-machine-learning-to-understand-the-ethereum-blockchain-1778485d603a
Using Machine Learning to Understand the Ethereum Blockchain

A hotbed field of study in data science analysis at the moment is machine learning, a form of AI that uses algorithms to study large sets of data. It’s used for everything from sequencing DNA to studying financial markets and brain-machine interfaces. There are many different kinds of machine learning, with differing data requirements and objectives. In the past year, ConsenSys has made a push to develop its analytics and data science capabilities with projects like Alethio, an analytics platform helps users visualize, interpret, and react to blockchain data in real time.

The immutable, public records and decentralized nature of blockchain networks provide an exciting sandbox for data scientists, offering whole new world of data to analyze and patterns to recognize. To begin understanding how we go about pulling meaning out of this seemingly chaotic data environment, we’ll begin by describing two main categories of machine learning that are being developed by data scientists at Consensys, and give a few examples of how each can be applied in practice.
Supervised vs. Unsupervised Learning

Unsupervised Learning involves finding patterns in a large data sets and using them to extract meaning. Unsupervised learning models are not predictive in nature — though they could play a role in a larger predictive modeling system. Rather, unsupervised learning seeks to reduce a large and complex dataset to simpler high-level patterns or themes. These themes can then be used as a reference to characterize individual data points and put them into a useful context.

Anomaly and novelty detection systems are examples of unsupervised learning models. By reducing a large dataset into a small number of common themes, one can learn what it means for a particular transaction or account point to be “normal.” By comparing any given transaction or account to this learned definition of normal, we can determine the extent to which they are anomalous compared to the global average (anomaly detection), or compared to a recent historical average (novelty detection). These anomaly detection systems can then be used to alert users whether anything unusual is happening on the whole blockchain, or within a particular subset of interesting accounts or transactions. Alethio currently offers an anomaly detection system for transactions, blocks, and accounts.

Other kinds of analysis offered by Alethio that could arguably be considered unsupervised learning including ranking algorithms, or influence analysis like page rank. While these are not commonly referred to as machine learning algorithms at all (rather, just algorithms), they do serve the same purpose of finding overall patterns in a dataset and using them to add context.

Supervised learning seeks to take a set of observations with known features, and uses them to estimate the corresponding value of some other variable (a response or label) for each observation. This could be broken down into two common categories: prediction and classification. Trying to use historical data to estimate the future value of variable (a response) is known as prediction. Trying to use existing data about an entity to determine whether that entity belongs to a certain category (assigning a “label”) is known as classification.

Generally speaking, the “knowns” on the blockchain consist of raw, protocol-level data that is available on-chain, such as transaction data. This raw data can be used to extract features for accounts, such as their total balance, average transaction frequency, average age of currency held, etc. Recent efforts by Alethio to augment protocol-level data with semantic lifting have expanded the set of “knowns” beyond the protocol layer to include application-level data, such as whether a contract is a token, and to which standard it complies. All of these known quantities can be used as the basis for features in a supervised learning model.

On the other hand, the unknown quantity (the label or response) is by definition not a piece of currently-available on-chain data; otherwise it would already be known and captured by our data pipelines. The unknown quantity might be the future value of some on-chain data, such as the balance of an account on some future date. More commonly, the unknown quantity is some value that is never available on-chain at all. If you are trying to predict whether the account belongs to some category, such as being a decentralized exchange, a DOS account, or a Ponzi scheme, you will need to look off-chain for this data.

The Importance of Datasets

This is where the data requirements for unsupervised learning on the blockchain become an important problem (read: opportunity!). In order to train and calibrate a supervised learning model, there must be some large initial set of data for which the value of the labels or responses is known. This calibrates the model so that the predicted and actual response are as close as possible. This means that when a new observation comes in where the response is unknown, the prediction will be close to the true value, assuming the new observation is being generated by a similar process that generated the original dataset. Once the training phase is complete and the model calibrated, it can then be applied to new observations where the response is unknown.

In the case of price prediction, this means having a large database of historical prices. In the case of classification of accounts, this means having an initial set of accounts that are already labeled as being a decentralized exchange, a DOS account, or a Ponzi.

In these classification examples, the labels in the dataset used for training are often only available through significant effort. One possibility would be to pull data from websites like coinmarketcap or etherscan, building ETLs to import interesting data from other blockchain businesses, or through the painstaking effort of trained research assistants who gather data about on-chain accounts by surfing the web and analyzing source code.

The realization of the importance of gathering external data about accounts (metadata) for the purposes of machine learning was the motivation for creating a new spoke at ConsenSys called Rakr. Through collaboration with Alethio and other spokes and services within the mesh, Rakr hopes to provide a platform for gathering and sharing this valuable metadata. While the implications of integrating blockchain metadata with raw on-chain data go far beyond machine learning, the applicability of this metadata for supervised machine learning will continue to be a primary use case for the Rakr platform. By combining Alethio’s powerful analytics platform with the valuable metadata provided by Rakr, the applications of data science at ConsenSys will be limited only by the imagination.
In Practice

The first example of a supervised learning model produced at ConsenSys was the Ponzi model developed by Alethio, which will be described in more detail during the sequel to this article. The development of this model lays the groundwork for many future analytics possibilities for Alethio. Alethio hopes to expand this model to a more general fraud model in the near term.

More generally, the feature extraction pipelines built during this model development effort can be reused to classify any account according to one of the labels in the Rakr database, including whether an account/contract is an exchange, an art DAO, a casino, a DOS-related account, and much more. As the set of interesting metadata provided by Rakr continues to grow, more new models will become possible. And as the analytics capabilities of Alethio grow and more useful features are created, these models will become more powerful and versatile.

Being able to know whether a given account is a fraud or related to a DOS attack is crucial for managing financial and network risk on the Ethereum network. If we want to productionize models that provide actionable insights about new accounts and very recent behavioral data, they must satisfy special requirements. For example, we must make sure that they are being updated in real time, and that the features being used for classification and prediction are reliable and complete at the time the model is run. This means that certain features that can be used for classification of “old” accounts, such as “whether a contract eventually self-destructed,” cannot be applied to accounts in real-time. Since the value of the feature may change in the future, it’s true value is not really known at the time the model is run.

Real-time machine learning models present unique challenges and opportunities that go beyond those of historical modeling techniques. With that said, the ability to classify accounts as frauds goes beyond real-time risk management; classification models can still be valuable even if they are applied “in the past”. Being able to accurately classify historical frauds is useful for research purposes, even if those accounts are no longer active. More generally, attaching tags to accounts on the blockchain allows users to define semantically interesting subsets of accounts on the blockchain (such as “ICOs” or “exchanges”), rendering the blockchain searchable based on criteria that humans care about.

Creating a database of empirical human knowledge about on-chain entities is already a valuable and challenging task, and a necessary foundation for many other products and services. But with over 30,000,000 Ethereum accounts and contracts to date and roughly 100,000 new accounts created every day, it is simply impossible for humans to tag the entire history of ethereum accounts, most of which have no useful information (such as contract source, a website, or any other identifying information) that could be used by humans to classify or tag them. This is why the machine learning models are crucial: because they are infinitely scalable, and can be used to classify accounts using only the raw data characterizing their on-chain behavior.

By augmenting human knowledge about the blockchain with powerful analytics and machine learning, we envision a blockchain where every account and entity is enriched with useful classifications and properties, whether empirical and created by humans, or predicted and created by statistical models. This will be a major step forward for the transparency and accessibility of knowledge on the blockchain, which are an essential aspects required for blockchain technology to flourish.

Keep an eye out for the next article by Paul Lintilhac, which will give an exposition of one of Alethio’s recent data science initiatives: the Ponzi Model.
___________________________

Unsupervised: 

Supervised:
___________
https://en.wikipedia.org/wiki/Kalman_filter
____________
https://github.com/wireservice/agate

agate is a Python data analysis library that is optimized for humans instead of machines. It is an alternative to numpy and pandas that solves real-world problems with readable code.

_________________
https://datanalytics.com/libro_r/
_________________
http://www.elmomentodecisivo.com/
________________
https://www.datanalytics.com/
_________________
https://www.infoq.com/presentations/algorithms-counting-reddit?utm_source=notification_email&utm_campaign=notifications&utm_medium=link&utm_content=content_in_followed_topic&utm_term=daily
____________________
https://www.infoq.com/presentations/data-ml-pipelines-stitchfix?utm_source=notification_email&utm_campaign=notifications&utm_medium=link&utm_content=content_in_followed_topic&utm_term=daily
_______________
https://ai.googleblog.com/2018/08/moving-beyond-translation-with.html
_______________
https://ai.googleblog.com/
_______________
https://ai.google/
___________________
REF: https://dzone.com/articles/consensus-clustering-via-apache-spark
    In this article, we will discuss a technique called Consensus Clustering to assess the stability
    of clusters generated by a clustering algorithm with respect to small perturbations in the data
    set. We will review a sample application built using the Apache Spark machine learning library 
    to show how consensus clustering can be used with K-means, Bisecting K-means, and Gaussian 
    Mixture, three distinct clustering algorithms

___________________
Ontology (Aristoteles) : http://classics.mit.edu/Aristotle/categories.1.1.html
_________________________________________
https://www.serverwatch.com/server-news/nvidia-accelerates-server-workloads-with-rapids-gpu-advances.html
!!!!  
_____________________
https://www.linux.com/blog/holberton/2018/10/sourced-engine-simple-elegant-way-analyze-your-code

source{d} Engine: A Simple, Elegant Way to Analyze your Code
With the recent advances in machine learning technology, it is only a matter of time before developers can expect to run full diagnostics and information retrieval on their own source code. This can include autocompletion, auto-generated user tests, more robust linters, automated code reviews and more. I recently reviewed a new product in this sphere -- the source{d} Engine.
source{d} offers a suite of applications that uses machine learning on code to complete source code analysis and assisted code reviews. Chief among them is the source{d} Engine, now in public beta; it uses a suite of open source tools (such as Gitbase, Babelfish, and Enry) to enable large-scale source code analysis. Some key uses of the source{d} Engine include language identification, parsing code into abstract syntax trees, and performing SQL Queries on your source code such as:

    What are the top repositories in a codebase based on number of commits?

    What is the most recent commit message in a given repository?

    Who are the most prolific contributors in a repository
___________________________
https://www.eleconomista.es/empresas-finanzas/noticias/9449298/10/18/COMUNICADO-Huawei-lanza-una-plataforma-de-desarrollo-de-IA-con-ciclo-de-vida-completo-mas-rapida.html
"ModelArts es una plataforma de desarrollo de inteligencia artificial más rápida e inclusiva que cualquier otra plataforma de desarrollo de IA del mercado", dijo Zheng Yelai, vicepresidente de Huawei y presidente de la unidad de negocio Huawei Cloud. "Creemos que los desarrolladores de IA sabrán apreciar lo rápido que se inicia, completa entrenamientos e implanta modelos".

El etiquetado y la preparación de datos es un proceso largo en el desarrollo de la inteligencia artificial, y representa casi el 50% del tiempo necesario. ModelArts tiene un marco de gobernanza de datos integrado para el etiquetado y la preparación de datos durante el desarrollo de IA. El marco implementa un entrenamiento iterativo para reducir el volumen de datos que tienen que ser etiquetados manualmente, lo que aumenta por 100 la eficiencia del etiquetado y la preparación de datos.

Además, ModelArts integra diversas tecnologías de optimización, especialmente el sistema de paralelo híbrido con cascada para reducir a la mitad el entrenamiento requerido en un determinado modelo, conjunto de datos o conjunto de recursos de hardware.

La implantación de modelos de IA es un proceso complejo. Con ModelArts, los modelos de entrenamiento pueden moverse a dispositivos, la periferia y la nube con solo un clic. Los trabajos de inferencia en línea o por lotes se proporcionan a través de la nube para cumplir con los diferentes requisitos de las aplicaciones, como la implantación simultánea o distribuida.

ModelArts también incorpora varias tecnologías de IA, como el aprendizaje automático, el diseño de modelos y la configuración de parámetros para acelerar el desarrollo de la inteligencia artificial.

En términos de gestión del ciclo de vida del desarrollo de IA, ModelArts abarca la recogida de datos sin procesar, el etiquetado de datos, la creación de trabajos de entrenamiento, la selección de algoritmos, la creación de modelos y la creación de servicios de inferencia. ModelArts permite a los desarrolladores de IA compartir datos, modelos y API de inteligencia artificial.
Visión de IA

Por otra parte, HiLens consta de una plataforma de desarrollo de aplicaciones de visión con IA y de un dispositivo visual potenciado con capacidades de IA. HiLens cuenta con Skill, un nuevo concepto de desarrollo de IA. Skill consiste en un código de control y modelos entrenados en ModelArts. HiLens también es compatible con modelos entrenados en otros marcos convencionales. Las capacidades desarrolladas en HiLens pueden implantarse en cualquier dispositivo que tenga integrados los chips Ascend de IA.

El dispositivo visual HiLens se compone de una cámara inteligente compatible con inferencias. Los desarrolladores pueden usar el dispositivo HiLens para crear aplicaciones de visión e implantarlas en dispositivos y en la nube. El dispositivo visual HiLens integra el chip Ascend 310, que puede procesar 100 fotogramas por segundo y detectar caras en milisegundos. Además, los livianos contenedores integrados minimizan el uso de recursos y de ancho de banda de red, y pueden descargarse e iniciarse de forma rápida
_________________________________________
https://www.infoq.com/news/2018/11/PyTorch-Developer-Preview
_________________________________________
IA Classification:
  • Cognitive Processing (including Natural Language Processing, Computer Vision, Speech Recognition)
  • Conversasional Systems and Virtual Assistants (Question&Answering, ChatBots)
  • Machine Learning & Deep Learning
  • Reference frameworks (as IBM Watson, Microsoft Cognitive, Cognitive Services in AWS, and Google and others)
_____________________________
https://www.infoq.com/news/2018/11/Google-AI-Voice
_____________________________
______________________
Learn to clearly differentiate between the buzzwords—for example, machine learning, artificial intelligence, deep learning, data science, computer vision, and robotics. Read or listen to talks by experts on each of them. Watch this <a href="https://www.youtube.com/watch?v=tKa0zDDDaQk" target="_blank">amazing video by Brandon Rohrer</a>, an influential data scientist. Or this video about the <a href="https://www.youtube.com/watch?v=Ura_ioOcpQI" target="_blank">clear differences between various roles</a> associated with data science.
______________________
!!!
https://opensource.com/article/18/10/machine-learning-python-essential-hacks-and-tricks
Includes cheatsheets for NumPy, Pandas, Matplotlib and Seaborn, Scikit-learn
______________________

Narrow AI Taxonomy

Applications      RPA     Chatbots    Document Systems     ....


Narrow AI

      Domains   Vision    Sound   NLP      Knowledge&Reasoning   Multiagent-Systems

      IA         Machine-Learning      Genetic       Network    Robotics&Signals
                  (Deep-Learning)      Algorithms    Analysis

      Core       Planning,        Statistics and      Simulation
                 Search and       data mining
                 Optimization

      Infra     Cognitive API's     On-premises     Edge-computing    CPU/GPU/ASIC
_____________________________
https://github.com/autumnai/leaf

Open Machine Intelligence Framework for Hackers. (GPU/CPU)

Leaf is a few months old, but thanks to its architecture and Rust, it is already one of the fastest Machine Intelligence Frameworks available.

    See more Deep Neural Networks benchmarks on [Deep Learning Benchmarks][deep-learning-benchmarks-website].

Leaf is portable. Run it on CPUs, GPUs, and FPGAs, on machines with an OS, or on machines without one. Run it with OpenCL or CUDA. Credit goes to Collenchyma and Rust.


https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb

We started with the development of Leaf briefly before Google released Tensorflow. For two weeks Leaf’s hypothesis seemed unique.

Although Leaf has top-notch performance and an uniquely simple yet expressive API, it will lose against Tensorflow. Leaf’s current theoretical benefits[1] are less significant, than the benefits that Tensorflow provides[2] over the early, scientific frameworks like Torch, Caffe, Theano.

The next generation of tools, that help developers to build machine learning applications will build on Tensorflow, or more specifically on higher-level frameworks, like Keras, who abstract over multiple AI Engines[3]. Back in November, when we started, this trend was less obvious to us[4].

Now that good-enough tools, to build maintainable machine-learning applications, like Tensorflow and Keras, exist, venture capital flows more and more into companies who try to create immense value in verticals with new AI-driven applications, instead of infrastructure providers.

We wanted Leaf to become the #1 machine learning framework for developers, but it became apparent, that Leaf will not receive substantial traction outside the Rust community.

Which is why Max and I will suspend the development of Leaf and focus on new ventures.

I am staying in the space of startups and AI, working with a VC to explore a new type of early stage investment fund.

Thank you so much everyone who supported us on the way to more than 4.000 Github stars and almost into Github’s Top 1000. We are very grateful.

We will continue to give back to the community with our future projects.

[1]: Significantly easier/slimmer abstractions over computation and scheduling, first-class citizen support for CUDA/OpenCL/Rust and co., clean foundation for auto diff via dual numbers and differentiable programming, compression of neural network models.

[2]: Tensorflow and its ecosystem (incl. GCloud) provides a proven solution/process for testing, deploying and maintaining models.

[3]: E.g. Facebook is working on Flow, AutoML and Asimo, which are tools to make the creation of machine learning models even easier. If they build on Tensorflow or Torch or another framework needs to be seen.

[4]: This is why the the other frameworks will vanish or take niche positions. This includes Microsoft’s CNTK.


_____________________________
https://www.wired.com/2016/05/facebook-trying-create-ai-can-create-ai/


    Finally, Neural Networks That Actually Work

"It's almost like being the coach rather than the player," says Demis Hassabis, co-founder of DeepMind, the Google outfit behind the history-making AI that beat the world's best Go player. "You're coaxing these things, rather than directly telling them what to do."

That's why many of these companies are now trying to automate this trial and error—or at least part of it. If you automate some of the heavily lifting, the thinking goes, you can more rapidly push the latest machine learning into the hands of rank-and-file engineers—and you can give the top minds more time to focus on bigger ideas and tougher problems. This, in turn, will accelerate the progress of AI inside the Internet apps and services that you and I use every day.

In other words, for computers to get smarter faster, computers themselves must handle even more of the grunt work. The giants of the Internet are building computing systems that can test countless machine learning algorithms on behalf of their engineers, that can cycle through so many possibilities on their own. Better yet, these companies are building AI algorithms that can help build AI algorithms. No joke. Inside Facebook, engineers have designed what they like to call an "automated machine learning engineer," an artificially intelligent system that helps create artificially intelligent systems. It's a long way from perfection. But the goal is to create new AI models using as little human grunt work as possible.
Feeling the Flow

After Facebook's $104 billion IPO in 2012, Hussein Mehanna and other engineers on the Facebook ads team felt an added pressure to improve the company's ad targeting, to more precisely match ads to the hundreds of millions of people using its social network. This meant building deep neural networks and other machine learning algorithms that could make better use of the vast amounts of data Facebook collects on the characteristics and behavior of those hundreds of millions of people.

    'The more ideas you try, the better. The more data you try, the better.'

According to Mehanna, Facebook engineers had no problem generating ideas for new AI, but testing these ideas was another matter. So he and his team built a tool called Flow. "We wanted to build a machine-learning assembly line that all engineers at Facebook could use," Mehanna says. Flow is designed to help engineers build, test, and execute machine learning algorithms on a massive scale, and this includes practically any form of machine learning—a broad technology that covers all services capable of learning tasks largely on their own.

Basically, engineers could readily test an endless stream of ideas across the company's sprawling network of computer data centers. They could run all sorts of algorithmic possibilities—involving not just deep learning but other forms of AI, including logistic regression to boosted decision trees—and the results could feed still more ideas. "The more ideas you try, the better," Mehanna says. "The more data you try, the better." It also meant that engineers could readily reuse algorithms that others had built, tweaking these algorithms and applying them to other tasks.

Soon, Mehanna and his team expanded Flow for use across the entire company. Inside other teams, it could help generate algorithms that could choose the links for your Faceboook News Feed, recognize faces in photos posted to the social network, or generate audio captions for photos so that the blind can understand what's in them. It could even help the company determine what parts of the world still need access to the Internet.

With Flow, Mehanna says, Facebook trains and tests about 300,000 machine learning models each month. Whereas it once rolled a new AI model onto its social network every 60 days or so, it can now release several new models each week.
The Next Frontier

The idea is far bigger than Facebook. It's common practice across the world of deep learning. Last year, Twitter acquired a startup, WhetLab, that specializes in this kind of thing, and recently, Microsoft described how its researchers use a system to test a sea of possible AI models. Microsoft researcher Jian Sun calls it "human-assisted search."

    Engineers even built their own 'automated machine learning engineer.'

Mehanna and Facebook want to accelerate this. The company plans to eventually open source Flow, sharing it with the world at large, and according to Mehanna, outfits like LinkedIn, Uber, and Twitter are already interested in using it. Mehanna and team have also built a tool called AutoML that can remove even more of the burden from human engineers. Running atop Flow, AutoML can automatically "clean" the data needed to train neural networks and other machine learning algorithms—prepare it for testing without any human intervention—and Mehanna envisions a version that could even gather the data on its own. But more intriguingly, AutoML uses artificial intelligence to help build artificial intelligence.

As Mehana says, Facebook trains and tests about 300,000 machine learning models each month. AutoML can then use the results of these tests to train another machine learning model that can optimize the training of machine learning models. Yes, that can be a hard thing to wrap your head around. Mehanna compares it to Inception. But it works. The system can automatically chooses algorithms and parameters that are likely to work. "It can almost predict the result before the training," Mehanna says.

Inside the Facebook ads team, engineers even built that automated machine learning engineer, and this too has spread to the rest of the company. It's called Asimo, and according to Facebook, there are cases where it can automatically generate enhanced and improved incarnations of existing models—models that human engineers can then instantly deploy to the net. "It cannot yet invent a new AI algorithm," Mehanna says. "But who knows, down the road..."

It's an intriguing idea—indeed, one that has captivated science fiction writers for decades: an intelligent machine that builds itself. No, Asimo isn't quite as advanced—or as frightening—as Skynet. But it's a step toward a world where so many others, not just the field's sharpest minds, will build new AI. Some of those others won't even be human.

-->

____________________
</html>
