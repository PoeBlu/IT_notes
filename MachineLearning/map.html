<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>DeepLearning_theory_map(alpha) <!-- ignore --></title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>


<body>
<div group>
    <span title>Mathematical Foundations</span>
<div groupv>
<pre zoom>
  <a xsmall TODO href="XXX">Linear Algebra</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Lagrange Optimization</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Probability Theory</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Gaussian Derivatives and Integrals</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Hypothesis Testing</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Information Theory</a>
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Computational Complexity</a>
</pre>
</div>

<div groupv>
<pre zoom bgorange>
  <span xsmall>DECISION THEORY</span>
There is an overall single cost associated with our decision,
and our true task is to make a decision rule (i.e., set a decision boundary)
so as to minimize such a cost.

This is the central task of decision theory of which pattern
classification is (perhaps) the most important subfiled.

Classification is, at base, the task of recovering the model that generated
the patterns.

Different classification techniques are useful depending on the
type of candidate models themselfs.

 Statistical pattern recognition models focus on the statistical
   properties of the patterns. When not enought (training) data is available,
 knowledge of the problem domain is also used.

 Other models focus on the logical rules like syntactic pattern recognition,
  where rules or grammars describe our decision.

 Patter classification differs from classical statistical ºhypothesis testingº,
wherein the sensed data are used to decide whether or not to reject a ºnull hypothesisº
in favor of some alternative hypothesis. In this case, if the null-Hypothesis falls
below a "significance" threshold, we reject the null-hypothesis in favor of the
alternative.


 Because perfect classification performance is often impossible, a more general
task is to determine the probability for each of the possible categories.

sensing -˃ segmentation -˃ feature extraction -˃ classification -˃ post-processing*
           ^^^^^^^^^^^^                                            (costs)
           "one of the deepest
           problems in pattern
           recognition"

The design of a pattern recognition system usually entails the repetition of a
number of different activities:
 - data collection: "large cost" of the development.
 - feature choice : Choice of distinguishing features.
 - model   choice : How to know whether a given model performs better
 - training       : Process of using data to determine the classifier
 - evaluation

</pre>
<pre zoom>
  <span xsmall>Vocabulary</span>
Feature:  Or Property is the data output from a "feature extractor" process
         Values are passed to a classfier.

Model: Determines the set of features used for the classifier.
      It can be a single specific set of features.

Feature-vector: A given vector (ordered set of features). The "dimensions" of
    the vector are provided by the model.

Feature-space: N-dimensional space of  feature inputs.
      Classification can be seen as the split of the feature-space in
      regions where the decision-cost is minimized.

Classifier: Takes feature values inputs and evaluates the "evidence" to make
            a decision or classification, assigning the input feature-vector to
            an output classification.
          The central aim of designing a classifier is to suggest actions when
          presented with not-yet-seen patterns. This is the issue of generalization.

Segmentation: Part of the pre-processing where objects of interest are "extracted"
            from background.

Feature Extraction: Process that takes-in a pattern and produces feature values.
    Number of features is virtually always chosen to be fewer than the total
    necessary to describe the complete taret of interest, and this leads to a loss
    in information.

     In acts of associate-memory, the ssytem takes-in a pattern and emits another
    pattern which is representative of a general group of patterns. It thus reduces
    the information somewhat, but rarely to the extent that pattern classification
    does. In short, because of the crucial role of a decision in pattern recognition
    information, it is fundamentally an information reduction process.

    The conceptual boundary between feature-extraction and classification is arbitrary.


Subset and SUperset problem: Formally part of ºmereologyº, the study of part/whole
    relationships. It appears as though the best classifiers try to incorporate
    as much of the input into the categorization as "makes sense" but not too much.

Risk: Total spected cost  of making a wrong classification/Decision.

stochastic: The property of having a random probability distribution or pattern
      that may be analysed statistically but may not be predicted precisely.
</pre>

<pre zoom>
 <span xsmall>Regression</span>
 <span xsmall>Interpolation</span>
 <span xsmall>Density Estimation</span>
Regression: We seek to find some functional description of data, often with the
    goal of predicting values for new input.
    Linear regression - in which the function is linear in the input variables-
    is the most popular and well studied form or regression.
Interpolation: In this case we known or can easily deduce, the function for
    certain ranges of input; the problem is then to infer the function for intermediate
    ranges of input.

Density estimation: is the problem of estimating the density (or probability) that
    a memeber of a certain category will be found to have particular features.
</pre>

<pre zoom>
   <span xsmall>Learning</span>
Learning: "Any method" that incorporates information from training samples in the
     design of a classifier.
     Formally, it refers to some form of algorithm for reducing the error on a
     set of training data.

Supervised-learning:  A teacher provides a category label or cost for each pattern
    in a training set, and seeks to reduce the sum of the cost for thes patterns.

UnSupervised-learning (Clustering): There is no explicit teacher, and the system
    forms clusters or "natural groupings" of the input patterns.
    "Natural" is always defined explicitly or implicitly in the clustering system
    itself.
    Different clusting algorithms lead to different Clusters.

Reinformcement Learning:
    The most typical way to train a classifer is to present an input,
     compute its tentative category label, and use th known target categorylabel to
    inprove
    might be an images of a character, the actual output of the classifier the
    category label "R" and the desired otuput a "B". In the reinforcement learning
    or learning-with-a-critic, no desired category signal is given; instead, the
    only teaching feedback is that the tentative category is right or wrong.

gradient-descent: A range of ºgradient-descentº algorithms that alter a
     classifier's parameters in order to reduce an error measure now permeate the
     field of statistical pattern recognition.
</pre>

<pre zoom>
  <span xsmall TODO>Who is Who</span>
  - <a href="https://en.wikipedia.org/wiki/Richard_O._Duda">Richard O. Duda</a>: Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81332496778">ACM Digital Library Refs</a>
  - <a href="https://en.wikipedia.org/wiki/Peter_E._Hart"  >Peter E. Hart</a>  : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100122968">ACM Digital Library Refs</a>
  - David G. Stork : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100152072">ACM Digital Library refs</a>
</pre>

<pre zoom>
  <a xsmall TODO href="XXX">Bayesian Decision Theory</a>
- Ideal case in which the probability structure underlying the categories is known perfectly.

 ºWhile not very realistic, it permits us to determine the optimal (Bayes) classifierº
 ºagainst which we can compare all other classifiers.º
</pre>

<pre zoom>
  <a xsmall TODO href="XXX">Max.likelihood&amp;Bay.Param.Estimation</a>
- We address the case when the full probability structure underlying the
  categories is not known, but the general forms of their distributions are.
  Thus the uncertainty about a probability distribuition is represented by
  the values of someh unkown parameter, and we seek to deteermine these parameters
  to attain the best categorization.
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">NonParametric Techn.</a>
- We have no prior parameterized knowledge about the underlying probability
  structure;
  Our classification will be based on information provided by training samples alone.
</pre>
<pre zoom>
  <a xsmall TODO href="XXX">Linear Discriminant Functions</a>
- General approach of parameter estimation. We shall assume that the so-called
  "discriminat functions" are of a very particular form - namely linear-
  in order to derive a class of incremental training rules.
</pre>
</div>
</div>
<div groupv>
<pre zoom labels="">
<span xsmall>Machine Learning Summary</span>

ºSUPERVISED LEARNINGº
- Direct feedback
- Prediction of future outpus
  from input results

   1) INPUT  →  NON-trained Machine  → Wrong     Predictive Output

┌─ 2) Learing: Train from training data set to tune the Machine params
│                                                       ^^^^^^^^^^^^^^
│                                                    - Percepton params
│                                                    - Matrix/es of weights
│                                                    - Tree params
│                                                    - ....
│
│  3) Model Evaluation: Test trained-data against test data
│
│  4) INPUT  →      trained Machine  → "Correct" Predictive Output
│
│
└─→ TRAINING STEPS:
    Fectch
    Training                                      Machine
    data                       Data               Learing
    set                     →  Preprocessing   →  Procedure

    ^^^^^^^^^^^^^^^^^          ^^^^^^^^^^^^^      ^^^^^^^^^

    [x~1_1,x~1_2,..] tag1     - Remove/Replace   - Percepton
    [x~2_1,x~2_2,..] tag2       missing data     - Adaline
    [x~3_1,x~3_2,..] tag3     - Split data into  - (M)ulti(L)ayer(P)er.
    ...              ^          train/test       - Deep N.N.
      ^^    ^^       |        - L1/L2 r12n       - Recurrent N.N.
   Nomenclature:     |        - Rescale          - Decission Trees
   ~"N": Sample  "N" |        - decrease dimmen.   and fores
   _"M": Feature "M" |        - increase dimmen.
                     |
          - In ºREINFORCED LEARNINGº tags are replaced with a reward-function for
            calculated ouput.
          - If tag value is actually a continuous output regression analysis
            is used.

   tagged data               Continuous data (Regression)
   Fit curve to split        Fit curve to approach
   different categories      output data
   │     +       /    ─      │             /
   │   +        /            │            /  +
   │         + /   ─         │         + /
   │  +   +   /              │          /+
   │         /   ─    ─      │      +  /
   │ +      /  ─             │        /  +
   │     + /                 │       / +
   │  +  +/  ─   ─    ─      │     +/
   └────────────────────     └────────────────────


ºUNSUPERVISED LEARNINGº
- Find hidden structures or groups in a given dataset
  - Clustering: Find clusters (meaninful subgroups)
   │ ┌─────┐  ┌────┐
   │ │x x  │  │ y  │
   │ │ x  x│  │y y │
   │ └─────┘  │   y│
   │ ┌────┐   └────┘
   │ │ z  │
   │ │z  z│
   │ └────┘
   └────────────────


</pre>
</div>

<div groupv>
<span title>Neuronal Networks</span>
<pre zoom>
  <a xsmall TODO href="XXX">Multilayer Neural Networks</a>
- We extend the "linear discrimant functions" to a class of very powerful
  algorithms for training multilayer neural networks;
</pre>
</div>

<div groupv>
<span title>Non Classified</span>

<pre zoom>
  <a xsmall TODO href="XXX">Stochastic Methods</a>
- We discuss simulate annealing, the Boltmann learning algorithm and other
  sotchastic methods which can avoid some the estimation problems that plague
  other neural methods.
</pre>

<pre zoom>
  <a xsmall TODO href="XXX">Nonmetric Methods</a>
- We move from statistical to logical rules.
  - tree-based algorithms (CARTS)
  - syntactic-based methods based on grammars.
</pre>

<pre zoom>
  <a xsmall TODO href="XXX">Algorithm-independent Machine Learning</a>
- ºThe "most" important and difficult chapter of the bookº.
- Some of the results described here - those related to bias and variance,
 degress of freedom, the desire for "simple" classifers, and computatinal
 complexity- are subtle and crucial both theorically and practically.
  The rest of the concepts can ONLY be fully understood (or used) in light
 of the results presented here.
</pre>

<pre zoom>
  <a xsmall TODO href="XXX">Unsupervised Learning&amp;Clustering</a>
- Address the case when input training patterns are not labeled, and
  where our recognizer must determine the cluster structure. We also treat
  a related problem, that of learning with a critic, in which the teacher
  provides only a single bit of information during the presentation of a
  training pattern - "yes", to indicate that the classification provided
  is correct or "not" otherwise.
</pre>
</div>

<div group>
    <span title>Keras</span><br/>
<div groupv>
<pre zoom labels="">
<span xsmall>External Lins</span>
@[https://keras.io/]
@[https://github.com/keras-team/keras/tree/master/examples]
@[https://keras.io/getting-started/faq/#how-can-i-use-stateful-rnns]
</pre>

<pre zoom>
<span xsmall>Summary</span>
standard flow:
 define network → compile → train
</pre>

<pre zoom>
<span xsmall>Sequential model</span>
<span xsmall>(linear stack of layers)</span>
<span xsmall>LAYER CREATION</span>
- pass list of layer instances to the constructor:

from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential(                 # ºSTEP 1 Define layersº
 [                                  # (one input layer in this example)
    Dense(32, input_shape=(784,)),  # ← Model needs FIRST LAYER input shape.
                                    #   input shape set through 'input_dim'                 (2D layers)
                                    #                           'input_dim'r+'input_length' (3D temp layers)
                                    # 32 : 32 hidden units (layers?)
    Activation('relu'),             fixed batch size     : (stateful recurrent nets): set through 'batch_size'
    Dense(10),
    Activation('softmax'),
 ]
)
</pre>

<pre zoom>
<span xsmall>Compile (multi-class, binary, mean-sq.err,custom)</span>
+----------------------------------------------------------------------------------------------------+
|                                COMPILES ARGUMENTS                                                  |
+----------------------------------------------------------------------------------------------------+

OPTIMIZER:                      | LOSS FUNCTION:                         | LIST OF METRICS:
string-ID of existing optimizer | string-ID of existing loss funct       | string-ID
 ('rmsprop', 'adagrad',...)     | ('categorical_crossentropy', 'mse',..) |  (metrics=['accuracy'])
OR Optimizer class instance.    | OR objective function.                 | OR Custom metric function


MULTI-CLASS CLASS.PROBLEM         | BINARY CLASS.PROBLEM         | MEAN SQUARED ERROR    | # CUSTOM METRICS
model.compile(                    | model.compile(               | REGRE.PROBLEM         | import keras.backend as K
  optimizer='rmsprop',            |   optimizer='rmsprop',       | model.compile(        |
  loss='categorical_crossentropy',|   loss='binary_crossentropy',|   optimizer='rmsprop',| def mean_pred(y_true, y_pred):
  metrics=['accuracy'])           |   metrics=['accuracy'])      |   loss='mse')         |   return K.mean(y_pred)
                                                                                         |
                                                                                         | model.compile(
                                                                                         |   optimizer='rmsprop',
                                                                                         |   loss='binary_crossentropy',
                                                                                         |   metrics=['accuracy', mean_pred])
</pre>

<pre zoom>
<span xsmall>TRAINING</span>
Ex.
import numpy as np              # ← INPUT DATA/LABELS ARE NUMPY ARRAYS.
input_data = np.random.random(  # ← Dummy data (input_layer.input_dim=100)
       (1000, 100))

BINARY CLASSIFICATION PROBLEM  | MULTI-CLASS (10) Class.problem
input_labels =                 | input_labels =
  np.random.randint(           |   np.random.randint(
  2, size=(1000, 1))           |   10, size=(1000, 1))
                               |
                               | # Convert labels → cat.one-hot encoding
                               | input_one_hot_lbls =  #
                               |    keras.utils.       #
                               |     to_categorical(
                               |       labels, num_classes=10)
                               |
model.fit(                     | model.fit(            # ← train the model, (typically using 'fit')
 input_data,                   |   input_data,         #   input data
 input_labels,                 |   input_one_hot_lbls, #   input labels
 epochs=10,                    |   epochs=10,          #   10 epochs iteration
 batch_size=32                 |   batch_size=32       #   batches of 32 samples
)                              | )

</pre>
</div>
<div groupv>
<span title>Examples</span>
<pre zoom>
  <span xsmall>multilayer perceptron</span>
  <span xsmall> (mlp) for multi-class</span>
  <span xsmall>softmax c12n</span>
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

import numpy as np                      # Generate dummy data
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(
  np.random.randint(10, size=(1000, 1)),
  num_classes=10)
x_test = np.random.random((100, 20))
y_test = keras.utils.to_categorical(
  np.random.randint(10, size=(100, 1)),
   num_classes=10)

model = Sequential()
# Dense(64) is a fully-connected layer with 64 hidden units.
# in the first layer, you must specify the expected input data shape:
# here, 20-dimensional vectors.
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
</pre>
<pre zoom>
  <span xsmall>MLP for </span>
  <span xsmall>binary c12n</span>
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Generate dummy data
x_train = np.random.random((1000, 20))
y_train = np.random.randint(2, size=(1000, 1))
x_test = np.random.random((100, 20))
y_test = np.random.randint(2, size=(100, 1))

model = Sequential()
model.add(Dense(64, input_dim=20, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
</pre>

<pre zoom>
  <span xsmall>VGG-like</span>
  <span xsmall>convnet</span>
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.optimizers import SGD

# Generate dummy data
x_train = np.random.random((100, 100, 100, 3))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
x_test = np.random.random((20, 100, 100, 3))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)

model = Sequential()
# input: 100x100 images with 3 channels → (100, 100, 3) tensors.
# this applies 32 convolution filters of size 3x3 each.
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)

model.fit(x_train, y_train, batch_size=32, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=32)
</pre>

<pre zoom>
<span xsmall>Sequence c12n</span>
<span xsmall>with LSTM:</span>
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import LSTM

max_features = 1024

model = Sequential()
model.add(Embedding(max_features, output_dim=256))
model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)
</pre>

<pre zoom>
  <span xsmall>Sequence c12n</span>
  <span xsmall>with 1D convolutions</span>
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D

seq_length = 64

model = Sequential()
model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))
model.add(Conv1D(64, 3, activation='relu'))
model.add(MaxPooling1D(3))
model.add(Conv1D(128, 3, activation='relu'))
model.add(Conv1D(128, 3, activation='relu'))
model.add(GlobalAveragePooling1D())
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)

Stacked LSTM for sequence classification

In this model, we stack 3 LSTM layers on top of each other, making the model
capable of learning higher-level temporal representations.

The first two LSTMs return their full output sequences, but the last one only
returns the last step in its output sequence, thus dropping the temporal
dimension (i.e. converting the input sequence into a single vector).
</pre>

<pre zoom>
  <span xsmall>stacked LSTM</span>
from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

data_dim = 16
timesteps = 8
num_classes = 10

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(32, return_sequences=True,
               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32))  # return a single vector of dimension 32
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Generate dummy training data
x_train = np.random.random((1000, timesteps, data_dim))
y_train = np.random.random((1000, num_classes))

# Generate dummy validation data
x_val = np.random.random((100, timesteps, data_dim))
y_val = np.random.random((100, num_classes))

model.fit(x_train, y_train,
          batch_size=64, epochs=5,
          validation_data=(x_val, y_val))
</pre>

<pre zoom>
<span xsmall>Same stacked LSTM</span>
<span xsmall>model rendered</span>
<span xsmall>"stateful"</span>
- Stateful recurrent model:  is one for which the internal states (memories)
   obtained after processing a batch of samples are reused as initial states for
   the samples of the next batch.
     This allows to process longer sequences while keeping computational
   complexity manageable.

You can read more about stateful RNNs in the FAQ.

from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

data_dim = 16
timesteps = 8
num_classes = 10
batch_size = 32

# Expected input batch shape: (batch_size, timesteps, data_dim)
# Note that we have to provide the full batch_input_shape since the network is stateful.
# the sample of index i in batch k is the follow-up for the sample i in batch k-1.
model = Sequential()
model.add(LSTM(32, return_sequences=True, stateful=True,
               batch_input_shape=(batch_size, timesteps, data_dim)))
model.add(LSTM(32, return_sequences=True, stateful=True))
model.add(LSTM(32, stateful=True))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Generate dummy training data
x_train = np.random.random((batch_size * 10, timesteps, data_dim))
y_train = np.random.random((batch_size * 10, num_classes))

# Generate dummy validation data
x_val = np.random.random((batch_size * 3, timesteps, data_dim))
y_val = np.random.random((batch_size * 3, num_classes))

model.fit(x_train, y_train,
          batch_size=batch_size, epochs=5, shuffle=False,
          validation_data=(x_val, y_val))

</pre>
</div>
<div groupv>
<span title>Tunning</span>
<pre zoom>
<a xsmall TODO href="https://keras.io/optimizers/">Usage of optimizers</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/losses/">Usage of loss functions</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/models/sequential/">The Sequential Model API</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/getting-started/functional-api-guide/">Functional API (Complex Models)</a>
- functional API is the way to go for defining complex models (multi-output models,
  directed acyclic graphs, or models with shared layers)

Ex 1: a densely-connected network
 (Sequential model is probably better for this simple case)
- tensor → layer instance → tensor

from keras.layers import Input, Dense
from keras.models import Model

inputs = Input(shape=(784,)) # ← input tensor/s
x = Dense(64, activation='relu')(inputs) # ←x: layer instances
x = Dense(64, activation='relu')(x)      # ←y: layer instances
predictions = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=predictions)    // @ma
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(data, labels)  # starts training

All models are callable, just like layers

With the functional API, it is easy to reuse trained models: you can treat any model as if it were a layer, by calling it on a tensor. Note that by calling a model you aren't just reusing the architecture of the model, you are also reusing its weights.

x = Input(shape=(784,))
# This works, and returns the 10-way softmax we defined above.
y = model(x)

This can allow, for instance, to quickly create models that can process sequences of inputs. You could turn an image classification model into a video classification model, in just one line.

from keras.layers import TimeDistributed

# Input tensor for sequences of 20 timesteps,
# each containing a 784-dimensional vector
input_sequences = Input(shape=(20, 784))

# This applies our previous model to every timestep in the input sequences.
# the output of the previous model was a 10-way softmax,
# so the output of the layer below will be a sequence of 20 vectors of size 10.
processed_sequences = TimeDistributed(model)(input_sequences)

Multi-input and multi-output models

Here's a good use case for the functional API: models with multiple inputs and outputs. The functional API makes it easy to manipulate a large number of intertwined datastreams.

Let's consider the following model. We seek to predict how many retweets and likes a news headline will receive on Twitter. The main input to the model will be the headline itself, as a sequence of words, but to spice things up, our model will also have an auxiliary input, receiving extra data such as the time of day when the headline was posted, etc. The model will also be supervised via two loss functions. Using the main loss function earlier in a model is a good regularization mechanism for deep models.

Here's what our model looks like:

multi-input-multi-output-graph

Let's implement it with the functional API.

The main input will receive the headline, as a sequence of integers (each integer encodes a word). The integers will be between 1 and 10,000 (a vocabulary of 10,000 words) and the sequences will be 100 words long.

from keras.layers import Input, Embedding, LSTM, Dense
from keras.models import Model

# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.
# Note that we can name any layer by passing it a "name" argument.
main_input = Input(shape=(100,), dtype='int32', name='main_input')

# This embedding layer will encode the input sequence
# into a sequence of dense 512-dimensional vectors.
x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)

# A LSTM will transform the vector sequence into a single vector,
# containing information about the entire sequence
lstm_out = LSTM(32)(x)

Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model.

auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)

At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:

auxiliary_input = Input(shape=(5,), name='aux_input')
x = keras.layers.concatenate([lstm_out, auxiliary_input])

# We stack a deep densely-connected network on top
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)

# And finally we add the main logistic regression layer
main_output = Dense(1, activation='sigmoid', name='main_output')(x)

This defines a model with two inputs and two outputs:

model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])

We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.

model.compile(optimizer='rmsprop', loss='binary_crossentropy',
              loss_weights=[1., 0.2])

We can train the model by passing it lists of input arrays and target arrays:

model.fit([headline_data, additional_data], [labels, labels],
          epochs=50, batch_size=32)

Since our inputs and outputs are named (we passed them a "name" argument), we could also have compiled the model via:

model.compile(optimizer='rmsprop',
              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},
              loss_weights={'main_output': 1., 'aux_output': 0.2})

# And trained it via:
model.fit({'main_input': headline_data, 'aux_input': additional_data},
          {'main_output': labels, 'aux_output': labels},
          epochs=50, batch_size=32)

Shared layers

Another good use for the functional API are models that use shared layers. Let's take a look at shared layers.

Let's consider a dataset of tweets. We want to build a model that can tell whether two tweets are from the same person or not (this can allow us to compare users by the similarity of their tweets, for instance).

One way to achieve this is to build a model that encodes two tweets into two vectors, concatenates the vectors and then adds a logistic regression; this outputs a probability that the two tweets share the same author. The model would then be trained on positive tweet pairs and negative tweet pairs.

Because the problem is symmetric, the mechanism that encodes the first tweet should be reused (weights and all) to encode the second tweet. Here we use a shared LSTM layer to encode the tweets.

Let's build this with the functional API. We will take as input for a tweet a binary matrix of shape (280, 256), i.e. a sequence of 280 vectors of size 256, where each dimension in the 256-dimensional vector encodes the presence/absence of a character (out of an alphabet of 256 frequent characters).

import keras
from keras.layers import Input, LSTM, Dense
from keras.models import Model

tweet_a = Input(shape=(280, 256))
tweet_b = Input(shape=(280, 256))

To share a layer across different inputs, simply instantiate the layer once, then call it on as many inputs as you want:

# This layer can take as input a matrix
# and will return a vector of size 64
shared_lstm = LSTM(64)

# When we reuse the same layer instance
# multiple times, the weights of the layer
# are also being reused
# (it is effectively ºthe sameº layer)
encoded_a = shared_lstm(tweet_a)
encoded_b = shared_lstm(tweet_b)

# We can then concatenate the two vectors:
merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)

# And add a logistic regression on top
predictions = Dense(1, activation='sigmoid')(merged_vector)

# We define a trainable model linking the
# tweet inputs to the predictions
model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.fit([data_a, data_b], labels, epochs=10)

Let's pause to take a look at how to read the shared layer's output or output shape.
The concept of layer "node"

Whenever you are calling a layer on some input, you are creating a new tensor (the output of the layer), and you are adding a "node" to the layer, linking the input tensor to the output tensor. When you are calling the same layer multiple times, that layer owns multiple nodes indexed as 0, 1, 2...

In previous versions of Keras, you could obtain the output tensor of a layer instance via layer.get_output(), or its output shape via layer.output_shape. You still can (except get_output() has been replaced by the property output). But what if a layer is connected to multiple inputs?

As long as a layer is only connected to one input, there is no confusion, and .output will return the one output of the layer:

a = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)

assert lstm.output == encoded_a

Not so if the layer has multiple inputs:

a = Input(shape=(280, 256))
b = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)
encoded_b = lstm(b)

lstm.output

˃˃ AttributeError: Layer lstm_1 has multiple inbound nodes,
hence the notion of "layer output" is ill-defined.
Use `get_output_at(node_index)` instead.

Okay then. The following works:

assert lstm.get_output_at(0) == encoded_a
assert lstm.get_output_at(1) == encoded_b

Simple enough, right?

The same is true for the properties input_shape and output_shape: as long as the layer has only one node, or as long as all nodes have the same input/output shape, then the notion of "layer output/input shape" is well defined, and that one shape will be returned by layer.output_shape/layer.input_shape. But if, for instance, you apply the same Conv2D layer to an input of shape (32, 32, 3), and then to an input of shape (64, 64, 3), the layer will have multiple input/output shapes, and you will have to fetch them by specifying the index of the node they belong to:

a = Input(shape=(32, 32, 3))
b = Input(shape=(64, 64, 3))

conv = Conv2D(16, (3, 3), padding='same')
conved_a = conv(a)

# Only one input so far, the following will work:
assert conv.input_shape == (None, 32, 32, 3)

conved_b = conv(b)
# now the `.input_shape` property wouldn't work, but this does:
assert conv.get_input_shape_at(0) == (None, 32, 32, 3)
assert conv.get_input_shape_at(1) == (None, 64, 64, 3)

More examples

Code examples are still the best way to get started, so here are a few more.
Inception module

For more information about the Inception architecture, see Going Deeper with Convolutions.

from keras.layers import Conv2D, MaxPooling2D, Input

input_img = Input(shape=(256, 256, 3))

tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)

tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)

tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)
tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)

output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)

Residual connection on a convolution layer

For more information about residual networks, see Deep Residual Learning for Image Recognition.

from keras.layers import Conv2D, Input

# input tensor for a 3-channel 256x256 image
x = Input(shape=(256, 256, 3))
# 3x3 conv with 3 output channels (same as input channels)
y = Conv2D(3, (3, 3), padding='same')(x)
# this returns x + y.
z = keras.layers.add([x, y])

Shared vision model

This model reuses the same image-processing module on two inputs, to classify whether two MNIST digits are the same digit or different digits.

from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten
from keras.models import Model

# First, define the vision modules
digit_input = Input(shape=(27, 27, 1))
x = Conv2D(64, (3, 3))(digit_input)
x = Conv2D(64, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
out = Flatten()(x)

vision_model = Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = Input(shape=(27, 27, 1))
digit_b = Input(shape=(27, 27, 1))

# The vision model will be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = keras.layers.concatenate([out_a, out_b])
out = Dense(1, activation='sigmoid')(concatenated)

classification_model = Model([digit_a, digit_b], out)

Visual question answering model

This model can select the correct one-word answer when asked a natural-
language question about a picture.

It works by encoding the question into a vector, encoding the image into a
vector, concatenating the two, and training on top a logistic regression over
some vocabulary of potential answers.

from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from keras.models import Model, Sequential

# First, let's define a vision model using a Sequential model.
# This model will encode an image into a vector.
vision_model = Sequential()
vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))
vision_model.add(Conv2D(64, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(128, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Flatten())

# Now let's get a tensor with the output of our vision model:
image_input = Input(shape=(224, 224, 3))
encoded_image = vision_model(image_input)

# Next, let's define a language model to encode the question into a vector.
# Each question will be at most 100 word long,
# and we will index words as integers from 1 to 9999.
question_input = Input(shape=(100,), dtype='int32')
embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Let's concatenate the question vector and the image vector:
merged = keras.layers.concatenate([encoded_question, encoded_image])

# And let's train a logistic regression over 1000 words on top:
output = Dense(1000, activation='softmax')(merged)

# This is our final model:
vqa_model = Model(inputs=[image_input, question_input], outputs=output)

# The next stage would be training this model on actual data.

Video question answering model

Now that we have trained our image QA model, we can quickly turn it into a
video QA model. With appropriate training, you will be able to show it a
short video (e.g. 100-frame human action) and ask a natural language question
about the video (e.g. "what sport is the boy playing?" → "football").

from keras.layers import TimeDistributed

video_input = Input(shape=(100, 224, 224, 3))
# This is our video encoded via the previously trained vision_model (weights are reused)
encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors
encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector

# This is a model-level representation of the question encoder, reusing the same weights as before:
question_encoder = Model(inputs=question_input, outputs=encoded_question)

# Let's use it to encode the question:
video_question_input = Input(shape=(100,), dtype='int32')
encoded_video_question = question_encoder(video_question_input)

# And this is our video question answering model:
merged = keras.layers.concatenate([encoded_video, encoded_video_question])
output = Dense(1000, activation='softmax')(merged)
video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)
</pre>
</div>
</div>
</body>
</html>
<!--
___________________________
set up development environment for deep learning
(Anaconda + PIP + PyCharm + ???)
https://www.programcreek.com/2017/01/set-up-development-environment-for-deep-learning/

___________________________
https://www.programcreek.com/2013/05/collection-of-natural-language-processing-tools/
Top 8 Java Tools for Natural Language Processing 
_____________________
JAVA RNN
https://www.programcreek.com/2017/07/recurrent-neural-network-example-ai-programmer-1/
https://www.programcreek.com/2017/07/build-an-ai-programmer-using-recurrent-neural-network-2/
https://www.programcreek.com/2017/07/build-an-ai-programmer-using-recurrent-neural-network-3/
https://www.programcreek.com/2017/02/different-types-of-recurrent-neural-network-structures/

_______________
https://www.programcreek.com/2017/01/how-to-select-the-right-tool-for-deep-learning/
_______________
Unsupervised:

Supervised:
___________
https://en.wikipedia.org/wiki/Kalman_filter
____________
https://github.com/wireservice/agate

agate is a Python data analysis library that is optimized for humans instead of machines. It is an alternative to numpy and pandas that solves real-world problems with readable code.

_________________
https://datanalytics.com/libro_r/
_________________
http://www.elmomentodecisivo.com/
________________
https://www.datanalytics.com/
_________________
https://www.infoq.com/presentations/algorithms-counting-reddit
____________________
https://www.infoq.com/presentations/data-ml-pipelines-stitchfix
_______________
https://ai.googleblog.com/2018/08/moving-beyond-translation-with.html
_______________
https://ai.googleblog.com/
_______________
https://ai.google/
___________________
REF: https://dzone.com/articles/consensus-clustering-via-apache-spark
    In this article, we will discuss a technique called Consensus Clustering to assess the stability
    of clusters generated by a clustering algorithm with respect to small perturbations in the data
    set. We will review a sample application built using the Apache Spark machine learning library
    to show how consensus clustering can be used with K-means, Bisecting K-means, and Gaussian
    Mixture, three distinct clustering algorithms

___________________
Ontology (Aristoteles) : http://classics.mit.edu/Aristotle/categories.1.1.html
_________________________________________
https://www.serverwatch.com/server-news/nvidia-accelerates-server-workloads-with-rapids-gpu-advances.html
!!!!
_____________________
https://www.linux.com/blog/holberton/2018/10/sourced-engine-simple-elegant-way-analyze-your-code

source{d} Engine: A Simple, Elegant Way to Analyze your Code
With the recent advances in machine learning technology, it is only a matter of time before developers can expect to run full diagnostics and information retrieval on their own source code. This can include autocompletion, auto-generated user tests, more robust linters, automated code reviews and more. I recently reviewed a new product in this sphere -- the source{d} Engine.
source{d} offers a suite of applications that uses machine learning on code to complete source code analysis and assisted code reviews. Chief among them is the source{d} Engine, now in public beta; it uses a suite of open source tools (such as Gitbase, Babelfish, and Enry) to enable large-scale source code analysis. Some key uses of the source{d} Engine include language identification, parsing code into abstract syntax trees, and performing SQL Queries on your source code such as:

    What are the top repositories in a codebase based on number of commits?

    What is the most recent commit message in a given repository?

    Who are the most prolific contributors in a repository
___________________________
https://www.eleconomista.es/empresas-finanzas/noticias/9449298/10/18/COMUNICADO-Huawei-lanza-una-plataforma-de-desarrollo-de-IA-con-ciclo-de-vida-completo-mas-rapida.html
"ModelArts es una plataforma de desarrollo de inteligencia artificial más rápida e inclusiva que cualquier otra plataforma de desarrollo de IA del mercado", dijo Zheng Yelai, vicepresidente de Huawei y presidente de la unidad de negocio Huawei Cloud. "Creemos que los desarrolladores de IA sabrán apreciar lo rápido que se inicia, completa entrenamientos e implanta modelos".

El etiquetado y la preparación de datos es un proceso largo en el desarrollo de la inteligencia artificial, y representa casi el 50% del tiempo necesario. ModelArts tiene un marco de gobernanza de datos integrado para el etiquetado y la preparación de datos durante el desarrollo de IA. El marco implementa un entrenamiento iterativo para reducir el volumen de datos que tienen que ser etiquetados manualmente, lo que aumenta por 100 la eficiencia del etiquetado y la preparación de datos.

Además, ModelArts integra diversas tecnologías de optimización, especialmente el sistema de paralelo híbrido con cascada para reducir a la mitad el entrenamiento requerido en un determinado modelo, conjunto de datos o conjunto de recursos de hardware.

La implantación de modelos de IA es un proceso complejo. Con ModelArts, los modelos de entrenamiento pueden moverse a dispositivos, la periferia y la nube con solo un clic. Los trabajos de inferencia en línea o por lotes se proporcionan a través de la nube para cumplir con los diferentes requisitos de las aplicaciones, como la implantación simultánea o distribuida.

ModelArts también incorpora varias tecnologías de IA, como el aprendizaje automático, el diseño de modelos y la configuración de parámetros para acelerar el desarrollo de la inteligencia artificial.

En términos de gestión del ciclo de vida del desarrollo de IA, ModelArts abarca la recogida de datos sin procesar, el etiquetado de datos, la creación de trabajos de entrenamiento, la selección de algoritmos, la creación de modelos y la creación de servicios de inferencia. ModelArts permite a los desarrolladores de IA compartir datos, modelos y API de inteligencia artificial.
Visión de IA

Por otra parte, HiLens consta de una plataforma de desarrollo de aplicaciones de visión con IA y de un dispositivo visual potenciado con capacidades de IA. HiLens cuenta con Skill, un nuevo concepto de desarrollo de IA. Skill consiste en un código de control y modelos entrenados en ModelArts. HiLens también es compatible con modelos entrenados en otros marcos convencionales. Las capacidades desarrolladas en HiLens pueden implantarse en cualquier dispositivo que tenga integrados los chips Ascend de IA.

El dispositivo visual HiLens se compone de una cámara inteligente compatible con inferencias. Los desarrolladores pueden usar el dispositivo HiLens para crear aplicaciones de visión e implantarlas en dispositivos y en la nube. El dispositivo visual HiLens integra el chip Ascend 310, que puede procesar 100 fotogramas por segundo y detectar caras en milisegundos. Además, los livianos contenedores integrados minimizan el uso de recursos y de ancho de banda de red, y pueden descargarse e iniciarse de forma rápida
_________________________________________
https://www.infoq.com/news/2018/11/PyTorch-Developer-Preview
_________________________________________
IA Classification:
  • Cognitive Processing (including Natural Language Processing, Computer Vision, Speech Recognition)
  • Conversasional Systems and Virtual Assistants (Question&Answering, ChatBots)
  • Machine Learning & Deep Learning
  • Reference frameworks (as IBM Watson, Microsoft Cognitive, Cognitive Services in AWS, and Google and others)
_____________________________
https://www.infoq.com/news/2018/11/Google-AI-Voice
_____________________________
______________________
Learn to clearly differentiate between the buzzwords—for example, machine learning, artificial intelligence, deep learning, data science, computer vision, and robotics. Read or listen to talks by experts on each of them. Watch this <a href="https://www.youtube.com/watch?v=tKa0zDDDaQk" target="_blank">amazing video by Brandon Rohrer</a>, an influential data scientist. Or this video about the <a href="https://www.youtube.com/watch?v=Ura_ioOcpQI" target="_blank">clear differences between various roles</a> associated with data science.
______________________
!!!
https://opensource.com/article/18/10/machine-learning-python-essential-hacks-and-tricks
Includes cheatsheets for NumPy, Pandas, Matplotlib and Seaborn, Scikit-learn
______________________

Narrow AI Taxonomy

Applications      RPA     Chatbots    Document Systems     ....


Narrow AI

      Domains   Vision    Sound   NLP      Knowledge&Reasoning   Multiagent-Systems

      IA         Machine-Learning      Genetic       Network    Robotics&Signals
                  (Deep-Learning)      Algorithms    Analysis

      Core       Planning,        Statistics and      Simulation
                 Search and       data mining
                 Optimization

      Infra     Cognitive API's     On-premises     Edge-computing    CPU/GPU/ASIC
_____________________________
https://github.com/autumnai/leaf

Open Machine Intelligence Framework for Hackers. (GPU/CPU)

Leaf is a few months old, but thanks to its architecture and Rust, it is already one of the fastest Machine Intelligence Frameworks available.

    See more Deep Neural Networks benchmarks on [Deep Learning Benchmarks][deep-learning-benchmarks-website].

Leaf is portable. Run it on CPUs, GPUs, and FPGAs, on machines with an OS, or on machines without one. Run it with OpenCL or CUDA. Credit goes to Collenchyma and Rust.


https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb

We started with the development of Leaf briefly before Google released Tensorflow. For two weeks Leaf’s hypothesis seemed unique.

Although Leaf has top-notch performance and an uniquely simple yet expressive API, it will lose against Tensorflow. Leaf’s current theoretical benefits[1] are less significant, than the benefits that Tensorflow provides[2] over the early, scientific frameworks like Torch, Caffe, Theano.

The next generation of tools, that help developers to build machine learning applications will build on Tensorflow, or more specifically on higher-level frameworks, like Keras, who abstract over multiple AI Engines[3]. Back in November, when we started, this trend was less obvious to us[4].

Now that good-enough tools, to build maintainable machine-learning applications, like Tensorflow and Keras, exist, venture capital flows more and more into companies who try to create immense value in verticals with new AI-driven applications, instead of infrastructure providers.

We wanted Leaf to become the #1 machine learning framework for developers, but it became apparent, that Leaf will not receive substantial traction outside the Rust community.

Which is why Max and I will suspend the development of Leaf and focus on new ventures.

I am staying in the space of startups and AI, working with a VC to explore a new type of early stage investment fund.

Thank you so much everyone who supported us on the way to more than 4.000 Github stars and almost into Github’s Top 1000. We are very grateful.

We will continue to give back to the community with our future projects.

[1]: Significantly easier/slimmer abstractions over computation and scheduling, first-class citizen support for CUDA/OpenCL/Rust and co., clean foundation for auto diff via dual numbers and differentiable programming, compression of neural network models.

[2]: Tensorflow and its ecosystem (incl. GCloud) provides a proven solution/process for testing, deploying and maintaining models.

[3]: E.g. Facebook is working on Flow, AutoML and Asimo, which are tools to make the creation of machine learning models even easier. If they build on Tensorflow or Torch or another framework needs to be seen.

[4]: This is why the the other frameworks will vanish or take niche positions. This includes Microsoft’s CNTK.


_____________________________
https://www.wired.com/2016/05/facebook-trying-create-ai-can-create-ai/


    Finally, Neural Networks That Actually Work

"It's almost like being the coach rather than the player," says Demis Hassabis, co-founder of DeepMind, the Google outfit behind the history-making AI that beat the world's best Go player. "You're coaxing these things, rather than directly telling them what to do."

That's why many of these companies are now trying to automate this trial and error—or at least part of it. If you automate some of the heavily lifting, the thinking goes, you can more rapidly push the latest machine learning into the hands of rank-and-file engineers—and you can give the top minds more time to focus on bigger ideas and tougher problems. This, in turn, will accelerate the progress of AI inside the Internet apps and services that you and I use every day.

In other words, for computers to get smarter faster, computers themselves must handle even more of the grunt work. The giants of the Internet are building computing systems that can test countless machine learning algorithms on behalf of their engineers, that can cycle through so many possibilities on their own. Better yet, these companies are building AI algorithms that can help build AI algorithms. No joke. Inside Facebook, engineers have designed what they like to call an "automated machine learning engineer," an artificially intelligent system that helps create artificially intelligent systems. It's a long way from perfection. But the goal is to create new AI models using as little human grunt work as possible.
Feeling the Flow

After Facebook's $104 billion IPO in 2012, Hussein Mehanna and other engineers on the Facebook ads team felt an added pressure to improve the company's ad targeting, to more precisely match ads to the hundreds of millions of people using its social network. This meant building deep neural networks and other machine learning algorithms that could make better use of the vast amounts of data Facebook collects on the characteristics and behavior of those hundreds of millions of people.

    'The more ideas you try, the better. The more data you try, the better.'

According to Mehanna, Facebook engineers had no problem generating ideas for new AI, but testing these ideas was another matter. So he and his team built a tool called Flow. "We wanted to build a machine-learning assembly line that all engineers at Facebook could use," Mehanna says. Flow is designed to help engineers build, test, and execute machine learning algorithms on a massive scale, and this includes practically any form of machine learning—a broad technology that covers all services capable of learning tasks largely on their own.

Basically, engineers could readily test an endless stream of ideas across the company's sprawling network of computer data centers. They could run all sorts of algorithmic possibilities—involving not just deep learning but other forms of AI, including logistic regression to boosted decision trees—and the results could feed still more ideas. "The more ideas you try, the better," Mehanna says. "The more data you try, the better." It also meant that engineers could readily reuse algorithms that others had built, tweaking these algorithms and applying them to other tasks.

Soon, Mehanna and his team expanded Flow for use across the entire company. Inside other teams, it could help generate algorithms that could choose the links for your Faceboook News Feed, recognize faces in photos posted to the social network, or generate audio captions for photos so that the blind can understand what's in them. It could even help the company determine what parts of the world still need access to the Internet.

With Flow, Mehanna says, Facebook trains and tests about 300,000 machine learning models each month. Whereas it once rolled a new AI model onto its social network every 60 days or so, it can now release several new models each week.
The Next Frontier

The idea is far bigger than Facebook. It's common practice across the world of deep learning. Last year, Twitter acquired a startup, WhetLab, that specializes in this kind of thing, and recently, Microsoft described how its researchers use a system to test a sea of possible AI models. Microsoft researcher Jian Sun calls it "human-assisted search."

    Engineers even built their own 'automated machine learning engineer.'

Mehanna and Facebook want to accelerate this. The company plans to eventually open source Flow, sharing it with the world at large, and according to Mehanna, outfits like LinkedIn, Uber, and Twitter are already interested in using it. Mehanna and team have also built a tool called AutoML that can remove even more of the burden from human engineers. Running atop Flow, AutoML can automatically "clean" the data needed to train neural networks and other machine learning algorithms—prepare it for testing without any human intervention—and Mehanna envisions a version that could even gather the data on its own. But more intriguingly, AutoML uses artificial intelligence to help build artificial intelligence.

As Mehana says, Facebook trains and tests about 300,000 machine learning models each month. AutoML can then use the results of these tests to train another machine learning model that can optimize the training of machine learning models. Yes, that can be a hard thing to wrap your head around. Mehanna compares it to Inception. But it works. The system can automatically chooses algorithms and parameters that are likely to work. "It can almost predict the result before the training," Mehanna says.

Inside the Facebook ads team, engineers even built that automated machine learning engineer, and this too has spread to the rest of the company. It's called Asimo, and according to Facebook, there are cases where it can automatically generate enhanced and improved incarnations of existing models—models that human engineers can then instantly deploy to the net. "It cannot yet invent a new AI algorithm," Mehanna says. "But who knows, down the road..."

It's an intriguing idea—indeed, one that has captivated science fiction writers for decades: an intelligent machine that builds itself. No, Asimo isn't quite as advanced—or as frightening—as Skynet. But it's a step toward a world where so many others, not just the field's sharpest minds, will build new AI. Some of those others won't even be human.


____________________
https://rocm.github.io/
____________________
https://course.elementsofai.com/
____________________
- Cognitive Processing (including NLP, Computer Vision, Speech Recog.)
___________________________
OpenCV Python Tutorial - Find Lanes for Self-Driving Cars (Computer Vision Basics Tutorial)
- https://www.youtube.com/watch?v=eLTLtUVuuy4
______________________________
https://www.infoq.com/news/2019/01/amazon-sustainability-datasets
__________________
https://www.infoq.com/news/2019/01/exploring-quantum-neural-nets
__________________
https://www.infoq.com/presentations/ml-research-production
__________________
https://github.com/jpmorganchase/swblocks-decisiontree
____________________
https://opensource.com/article/19/2/mycroft-voice-assistant

_______________________
Tensorflow tagged by votes questions in https://datascience.stackexchange.com/

https://datascience.stackexchange.com/questions/tagged/tensorflow?sort=votes&pageSize=15
_____________________
https://github.com/dformoso/machine-learning-mindmap
___________________________
https://serverfault.com/questions/959018/apache-tuning-for-512gb-ram
______________________
Who-is-Who:
https://www.xataka.com/inteligencia-artificial/premio-turing-para-tres-principales-responsables-actual-auge-inteligencia-artificial
________________________
Neural Network Zoo!! (perceptron, feed forward, ...):
http://www.asimovinstitute.org/neural-network-zoo/
___________________
https://stackoverflow.com/questions/20923574/whats-the-difference-between-convolutional-and-recurrent-neural-networks
_________________
https://www.infoq.com/news/2019/03/TensorFlow-Privacy
_______________________
https://www.infoq.com/news/2019/04/facebook-pytorch-biggraph
PyTorch-BigGraph: distributed system that can learn embeddings for graphs with billions of nodes.

A graph is a data structure that represents relationships (or edges) between entities (or nodes).
One challenge of using a graph as input to machine learning is that the size of the data structure
is proportional to the square of the number of entities. Using such a data structure as an input
for machine learning can lead to extremely large models. Similar problems occur in natural
language processing (NLP), and one common solution is to use an embedding as the first stage
in the model.

An embedding is a mapping from a vector space with higher dimensions to one with fewer,
that preserves some feature of the original space. NLP tasks often use a word embedding
such as word2vec; in this embedding, the coordinates for words with similar meaning are
closer to each other than to words with different meanings. Similarly, in a graph embedding,
nodes that share an edge would have coordinates closer to each other than to nodes with no
shared edge. Once an embedding is created, it can be used by machine learning tasks to
transform input data into a more compact form, making the subsequent model much simpler.
Graph embeddings often map from an original space with millions of dimensions into one
with fewer than one thousand.

However, embeddings themselves are constructed from a deep-neural-network (DNN) trained
using unsupervised learning techniques, and the large space of the input data makes that
task difficult: training takes a long time, and the DNN model has so many parameters that
they may not fit into the memory of the server performing the training.

To overcome the latter problem, PyTorch-BigGraph (PBG) divides the nodes of the graph
into multiple partitions, sized such that two partitions can fit into a machine's
memory. The edges are partitioned into "buckets", with a bucket containing the edges
that connect nodes from one partition with the nodes from another partition. Training
is performed on one bucket at a time. The training can be done on one machine, or across
multiple machines using distributed training to decrease training time.

In a paper that was presented at the recent SysML Conference, experimental results
on publicly available social graph data sets show that "PBG outperforms competing
methods," such as DeepWalk and MILE.

In addition to releasing the source code, Facebook has also published a pre-trained
model containing embeddings of the full WikiData graph. This model contains 78
million entities mapped into a 200-dimensional vector space. Facebook hopes that
their work "encourages practitioners to release and experiment with even larger data sets."
_______________________________
https://www.infoq.com/news/2019/04/Google-Document-Understanding
__________________________
https://www.infoq.com/news/2019/04/Google-ML-Kit
__________________________
https://towardsdatascience.com/no-machine-learning-is-not-just-glorified-statistics-26d3952234e3
_____________________________
DVC.org


DVC is a brainchild of a data scientist and an engineer, that was created to fill in the gaps in the ML processes tooling and evolved into a successful open source project. While working on DVC we adopt best ML practices and turn them into Git-like command line tool. DVC versions multi-gigabyte datasets and ML models, make them shareable and reproducible. The tool helps to organize a more rigorous process around datasets and the data derivatives. Your favorite cloud storage (S3, GCS, or bare metal SSH server) could be used with DVC as a data file backend.

Read the organization's project ideas for Season of Docs.

Contact: Sveta at info@dvc.org
_________________________________
https://www.infoq.com/news/2019/05/google-snorkel-drybell
____________________________
https://www.infoq.com/news/2019/05/pytorch-release-performance
____________________________
OReilly
Text Analysis for Business Analytics with Python
Extracting Insight from Text Data
Walter Paczkowski, Ph.D.
June 12, 2019
""" Unlike well-structured and organized numbers-oriented data of the pre-Internet era,
text data are highly unstructured and chaotic. Some examples include:
survey verbatim responses, call center logs, field representatives notes, customer emails,
of online chats, warranty claims, dealer technician lines, and report orders.
Yet, they are data, a structure can be imposed, and they must be analyzed to extract
useful information and insight for decision making in areas such as new product
development, customer services, and message development.
... This course will show you how to work with text data to extract meaningful insight such
as sentiments (positive and negative) about products and the company itself, opinions,
suggestions and complaints, customer misunderstandings and confusions, and competitive
and positions.
By the end of this live, hands-on, online course, you’ll understand:
- the unstructured nature of text data, including the concepts of a document and a corpus
- the issues involved in preparing text data for analysis, including data
  cleaning, the importance of stop-words, and how to deal with inconsistencies
  in spelling, grammar, and punctuation
- how to summarize text data using Text Frequency/Inverse Document Frequency (TF/IDF) weights
- the very important Singular Value Decomposition (SVD) of a document-term matrix (DTM)
- how to extract meaning from a DTM: keywords, phrases, and topics
- which Python packages are used for text analysis, and when to use each

And you’ll be able to:
- impose structure on text data
- use text analysis tools to extract keywords, phrases, and topics from text data
- take a new business text dataset and analyze it for key insights using the Python packages
- apply all of the techniques above to business problems
__________________________________________
DEBUGGING DATA SCIENCE
Hands-on applied machine learning with Python
Jonathan Dinu

 The focus will be on debugging machine learning problems that arise during
the model training process and seeing how to overcome these issues to improve
the effectiveness of the model.

What you'll learn-and how you can apply it
- Properly evaluate machine learning models with advanced metrics and diagnose learning problems.
- Improve the performance of a machine learning model through
  feature selection, data augmentation, and hyperparameter optimization.
- Walk through an end-to-end applied machine learning problem applying
  cost-sensitive learning to optimize “profit.”

https://www.oreilly.com/library/view/data-science-fundamentals/9780134660141/
https://www.oreilly.com/library/view/strata-hadoop/9781491944608/video243981.html

About Jonathan Dinu :
Jonathan Dinu is currently pursuing a Ph.D. in Computer Science at Carnegie Mellon’s Human Computer Interaction Institute (HCII) where he is working to democratize machine learning and artificial intelligence through interpretable and interactive algorithms. Previously, he co-founded Zipfian Academy (an immersive data science training program acquired by Galvanize), has taught classes at the University of San Francisco, and has built a Data Visualization MOOC with Udacity.

    In addition to his professional data science experience, he has run data science trainings for a Fortune 100 company and taught workshops at Strata, PyData, & DataWeek (among others). He first discovered his love of all things data while studying Computer Science and Physics at UC Berkeley and in a former life he worked for Alpine Data Labs developing distributed machine learning algorithms for predictive analytics on Hadoop.

___________________
https://liliputing.com/2019/05/google-assistant-is-getting-10x-faster-thanks-to-on-device-language-processing.html
_____________________
TODO: BigData classify Patchyderm
http://www.pachyderm.io/open_source.html
_________________________
https://www.infoq.com/news/2019/05/bing-nns-algorithm-open-sourced/
___________________________
https://www.infoq.com/news/2019/05/openai-sparse-transformers/
______________________________________
https://www.infoq.com/news/2019/05/google-tpu-pods-beta-available/
______________________________________
https://www.infoq.com/news/2019/05/google-tensorflow-graphics/
______________________________________
https://ignite.apache.org/features/machinelearning.html
_______________________
https://www.xataka.com/inteligencia-artificial/llevamos-anos-usando-mal-redes-neuronales-ahora-sabemos-como-hacerlas-10-veces-pequenas-perder-rendimiento
______________________
https://www.infoq.com/news/2019/04/tensorflow-chrome-dinosaur-game/
____________
https://press.aboutamazon.com/news-releases/news-release-details/aws-announces-general-availability-amazon-textract
fully managed service that uses machine learning to automatically extract text and data, including from tables and forms, in virtually any document without the need for manual review, custom code, or machine learning experience.
___________________________
https://www.infoq.com/news/2019/06/open-source-automl-tool/
__________________
https://www.infoq.com/presentations/scale-dl-petaflops/
__________________
https://www.infoq.com/presentations/scale-dl-petaflops/
________________________
https://www.infoq.com/news/2019/06/open-source-automl-tool/

ºMIT Researchers Open-Source AutoML Visualization Tool ATMSeerº
A research team from MIT, Hong Kong University, and Zhejiang University has open-sourced ATMSeer, a tool for visualizing and controlling automated machine-learning processes.
________________________________
https://github.com/EdjeElectronics/TensorFlow-Object-Detection-on-the-Raspberry-Pi
A tutorial showing how to set up TensorFlow's Object Detection API on the Raspberry Pi
________________________________
https://openai.com/blog/better-language-models/
Better Language Models
and Their Implications

We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.
___________________________________
https://m.europapress.es/ciencia/laboratorio/noticia-algoritmos-son-capaces-descubrir-conocimiento-cientifico-oculto-20190704110622.html
_____________________________
https://www.infoq.com/news/2019/07/google-dlc-beta-release/
________________________________
Taxonomy:
https://datascience.stackexchange.com/tags
__________________________________
https://opendata.stackexchange.com/tags
__________________________________
Open Data Kit

Data collection is a key component of social good efforts ranging from polio elimination to rainforest conservation and Open Data Kit (ODK) helps thousands of organizations collect data quickly, accurately, offline, and at scale.

Read the organization's project ideas for Season of Docs.

Contact: yanokwa at opendatakit.org@gmail.com
__________________________________
https://www.infoq.com/news/2019/05/google-ai-platform/

Google has recently launched AI Platform, an end-to-end platform for developers and data scientists to build, test, and deploy machine learning models
__________________________
100$ camera, 50%+ of "NewYorkers" detected
https://www.nytimes.com/interactive/2019/04/16/opinion/facial-recognition-new-york-city.html

Relacionado:
http://www.redusers.com/noticias/investigadores-belgas-descubren-metodo-enganar-camaras-ia/

_________________________________
https://www.infoq.com/news/2019/08/Baidu-OpenSources-ERNIE/

Baidu Open-Sources ERNIE 2.0, Beats BERT in Natural Language Processing Tasks
In a recent blog post, Baidu, the Chinese search engine and e-commerce giant, announced their latest open-source, natural language understanding framework called ERNIE 2.0. They also shared recent test results, including achieving state-of-the art (SOTA) results and outperforming existing frameworks, including Google’s BERT and XLNet in 16 NLP tasks in both Chinese and English.
_______________________________
<a href="https://ml-cheatsheet.readthedocs.io">https://ml-cheatsheet.readthedocs.io</a>
__________________
https://www.infoq.com/news/2019/08/adversarial-image-dataset/

University Research Teams Open-Source Natural Adversarial Image DataSet for Computer-Vision AI

Research teams from three universities recently released a dataset called ImageNet-A, containing natural adversarial images: real-world images that are misclassified by image-recognition AI. When used as a test-set on several state-of-the-art pre-trained models, the models achieve an accuracy rate of less than 3%.
___________________________
The Lack of A Priori Distinctions Between Learing Algorithms, D.H.Wolpert (1996);
No free lunch theorems for optimization, D.H. Wolpert y W.G.Macready (1997)
_________________
McCullock-Pitts  (MCP), A Logical Calculus of the Ideas Immanet in Nervous Activity, 
W.S. McCulloch  and W.Pitts, Bulletin of Mathematical Biophysics, 5(4): 115-133, 1943
________________
The Perceptron: A Perceiving and Recognizing Automaton, Frank Rosenblatt, Cornell Aeronautical Laboratory

An Adaptive "Adaline" Neuron Using Chemical "Memistors", Technical Report Number 1553-2, Bernard Widrow, Ted Hoff and others
_____________
Intro to Python Scientific Libaries
NumPy: https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf
Pandas: https://pandas.pydata.org/pandas-docs/stable/10min.html
Matplotlib: http://matplotlib/users/beginner.html

_____________

scikit-earn makes use amongst others, of LIBLINEAR, a highly optimized C/C++ lib from the National Taiwan University.

http://www.csie.ntu.edu.tw/cjlin/liblinear/

SVN makes use of LIBSVN
_____
http://www.graphviz.org

________________
An algorithm for finding best matches in logarithmic Expected Time, J.H.Friedman, J.L,  Bentley, and R.A. Finkel, ACM transactions on mathematical software (TOMS), 3(3): 209-226, 1977
_________
SciKit-learn metrics:
http://scikit-learn.org/stable/modules/generated/sklearn.neigbors.DistanceMetric.html
___________________
Example training data set:

https://archive.ics.uci.edu/ml/datasets/
___________________
L1/L2 regularization:
The Elements of statistical Learning, Trevor Hastie, Robert Tibshirani and Jerome Friedman, Springer Science+Business Media, 2009
___________________
Detailed evaluations of different secuencials algorithms  can be found on:
Comparative Study of Techniques for Large-Scale Feature Selection, F.Ferri, P. Pudil, M. Hatef and J. Kittler, pages 403-413, 1994
___________________
http://scikit-learn.org/stable/modules/feature_selection.html
http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/
_________________________
A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection, Kohavi, Ron, International Joint
  Conference on Artificial Intelligence (IJCAI), 14(12): 1137-43, 1995

https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html
https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html
https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html

Analysis of Variance of Cross-Validation Estimators of the Generalization Error, M.Markatou, H.Tian, S.Biswas, and G.M. Hripcsak, Journal of Machine Learning Research, 6: 1127-1168, 2005

Improvements on Cross-validation: The .632+ Bootstrap Method, B. Efron and R. Tibshirani, Journal of the American Statistical Association, 92 (438): 548-560, 1997

___________________
(Model evaluation and hyper-params)
Error Estimation When Using Cross-validation for Model Selection, BMC Bioinformatics, S. Varna and R. Simon, 7(1):91, 2006
________________________
(Model evaluation and hyper-params)
List of different values acepted for the qualification :
http://scikit-learn.org/stable/modules/model_evaluation.html
_____________________
(Model evaluation and hyper-params)
http://scikit-learn.org/stable/modules/generated/skleran.metrics.precision_recall_curve.html
_____________________
(Model evaluation and hyper-params)
Synthetic Minority Over-sampling Technique, Journal of Artificial Intelligence Reseach, 16: 321-357, 2002
_______________________
(Model evaluation and hyper-params)
https://github.com/scikit-learn-contrib/imbalanced-learn
________________________
Binomial coeficient: How many different ways we can choose a subset of k elements unordered from a set of N size.
_______________________
Stacking algorithm:
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/

________________
Chap 7
Combine different models:
- The Stregth of Weak Learnability , R. E. Schapire, Machine Learing, 5(2): 197-227, 1990
  
- AdaBoost: Proceedings of the Thirteenth International Conference (ICML 1996)
  
- Experiments with a New Boosting Algorithm, Y. Freund, R.E. Schapire and others, ICML, volume 96, 148-156, 1996

- http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BigChaos.pdf
- http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-starts.html
__________________

Chapter 8: Machine Learning for Sentiment Analysis

- Learning Word Vercotrs for Sentiment Analysis, A.L. Maas, R.E.Daly, P.T. Pham, D.Huang, A.Y.Ng, C.Potts
   Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:
     Human Language Technologies, pages 142-150, Portland, Oregon, USA, ACM, 2011

- http://ai.stanford.edu/~amaas/data/sentiment/ (84.1MB)

- Potter Algorithm:
  An Algorithm for suffix stripping, Martin F.Porter, Program: Electronic Library and Information Systems
   14(3): 130-137, 1980
 (Implemented by http://www.nltk.org like:
  from nltk.stem.porter import PorterStemmer
  See alternatives @ http://www.nltk.org/api/nltk.stem.html

- Influence of Word Normalization on Text Classification, Michal Toman, Roman Tesar and kael Jezek,
  Proceedings of InSciT, pages 354-358, 2006


- Naive Bayes Classifier, popular for antispam filtering.
  Easy to implement, efficients and work very well in relatively smalls data.
  Naive Bayes and Text Classification I, Introduction and Theory,
  R.Raschka, Computing Research Repository (CoRR), abs/1410.5329,2014,
  http://arxiv.org/pdf/1410.5329v3.pdf

- Hashing Vectorizer: Avoids having all data in main memory:
  https://sites.google.com/site/murmurhash/
 
- wrod2vec algorithm: Googl2 2013,
  Bag Of Words alternative:
  Efficient Estimation of Word Representations in Vector Space, T. Mikolov, K.Chen, G.Corrado and J.Dean
  arXiv:1301.3781, 2013
  Unsupervised algo. based on neuronal networks that tries to automatically learn the
  relation amongst words, puttins words with "similar" meanings into similar groups

  https://code.google.com/p/word2vect/

Chapter 8: *Topic Modeling*
- Latent Dirichlet Allocation (LDA)
  Very related to Bayessian inference.
  Latent Dirichlet Allocation, David M.Blei, Andrew Y.Ng, Michael I.Jordanl, 
  Journal of Machine Learning Research 3, pages: 993-1022, Jan. 2003.
  - It tires to find groups of words that appears frequently in new topics.
  Implemented in sckit-learn:
  from sklearn.decomposition import LatenDirchletAllocation
    
___________________

Chapter 10: Regression Analysis

- Introduction to Linear Regression Analysis, Montgomery, Douglas C. Montogmery, Elizabeth A. Peck, G. Geoffrey Vining, Wiley, 2012, pages: 318-319

Training Data:
https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt

- To represent the dispersion matrix we will use the pairplot function
from Seaborn library:
  http://standford.edu/~mwaskom/software/seaborn/

- A correlation matrix can be seen as a re-scaled version of the covariance matrix in Principal Component Analysis PCA.

  - It is a cuadratic matrix that contains the Pearson Correlation Coeficient.
    that measures the lineal dependency amongst pairs of characteristics.
    They are in the range -1 to 1. 1 for perfect correlation, 0 for no correlation

 - Ordinary Least Squares (OLS) method of adjust:  It estimates the parameters of
   the linear regresion line that minimizes the sum of vertical cuadratic-distances

   not to be confused with the Mean Square Error (MSE) used to measure the performance
   (prediction vs reality error)

 - we can also use linear ecuations:
   The Classical Linear Regression Model, Dr. Stephen Pollock
    http://www.le.ac.uk/users/dsgpl/COURSES/MESOMET/ECMETXT/06mesmet.pdf

 - Automatic Estimation of the Inlier 'Threshold in Robust Multiple Structures Fitting, R. Toldo, A.FUsiello's, Springer, 2009, Image Analysis and Processing-ICIAP 2009,
  pages 123-131
  

  - Overfitting methods (Regularization) popular in liner regression are:
    - Ridge Regression
    - LASSO (Least Absolute Shrinkage and Selection Operator)
    - Elastic Net.
______________________
https://github.com/rasbt/python-machine-learning-book-2nd-edition
_________________________
https://github.com/snipsco/snips-nlu
Snips NLU is a Natural Language Understanding python library that allows to parse sentences written in natural language, and extract structured information.

It’s the library that powers the NLU engine used in the Snips Console that you can use to create awesome and private-by-design voice assistants.
_____________________________
https://www.infoq.com/news/2019/09/facebook-roberta-nlp/
___________________________
https://www.infoq.com/news/2019/10/google-nlp-dataset/

Google Releases Two New NLP Dialog Datasets
____________________________
https://github.com/loredanacirstea/ai-projects
_________________________
Ace html editor:
https://stackoverflow.com/questions/15485153/enable-vim-mode-in-gist-ace-editor
ace vim mode:
https://stackoverflow.com/questions/15485153/enable-vim-mode-in-gist-ace-editor

https://ace.c9.io/#nav=production
_________________________
https://www.infoq.com/news/2019/11/alexa-genetic-deep-learning/
https://arxiv.org/abs/1908.09942
Amazon's Alexa Science researchers published a paper providing a theoretical basis for neural-network optimization. While showing that it is computationally intractable to find a perfect solution, the paper does provide a formulation, the Approximate Architecture Search Problem (a-ASP), that can be solved with genetic algorithms.

________________________
https://github.com/espnet/espnet

End-to-End Speech Processing Toolkit https://espnet.github.io/espnet/
ESPnet is an end-to-end speech processing toolkit, mainly focuses on end-to-end speech recognition and end-to-end text-to-speech. ESPnet uses chainer and pytorch as a main deep learning engine, and also follows Kaldi style data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.

__________________________
https://brohrer.github.io/blog.html !!!!
https://www.youtube.com/user/BrandonRohrer
End-to-End Machine Learning Library 

_______________________
http://pyro.ai/
Deep Universal Probabilistic Programming

https://www.datanalytics.com/2019/10/14/pyro/
Leyendo sobre si dizque PyTorch le siega la hierba debajo de los pies a TensorFlow, averigué la existencia de Pyro.

Pyro se autopresenta como Deep Universal Probabilistic Programming, pero aplicando métodos porfirianos (ya sabéis: género próximo y diferencia específica), es, o pretende ser, Stan en Python y a escala.

Aquí van mis dos primeras impresiones, basadas en una inspección superficial de los tutoriales.

En primer lugar, aunque Pyro permite usar (distintas versiones de) MCMC, parece que su especialidad es la inferencia variacional estocástica. Que parece funcionar de la siguiente manera. En el MCMC tradicional uno obtiene una muestra de la distribución (a posteriori, para los amigos) de los parámetros de interés. Eso es todo: vectores de puntos. En la inferencia variacional estocástica, uno preespecifica la forma paramétrica de la posteriori y el algoritmo calcula sus parámetros a partir de los valores simulados. Por ejemplo, uno va y dice: me da que la distribución del término independiente de mi regresión lineal va a ser normal. Entonces, Pyro responde: si es normal, la mejor media y desviación estándar que encuentro son tal y cual.

La segunda observación que me permito hacer es que la forma que adquiere la implementación de modelos en Pyro está muy alejada de la forma en que los plantearía un estadístico. Uno lee código en Stan o Jags y entiende lo que está ocurriendo: las servidumbres al lenguaje subyacente son mínimas y existe un DSL conciso que permite expresar los modelos de una manera natural. Pero no pasa así con Pyro.

De todos modos, es un gran aporte y espero que en no mucho tiempo podamos construir modelos de verdad (no, XGBoost no es de verdad) en condiciones y a escala.

________________________
https://www.infoq.com/news/2019/10/nlp-model-explanation/
AI Researchers' Open-Source Model Explanation Toolkit AllenNLP Interpret
______________________
http://people.idsia.ch/~juergen/who-invented-backpropagation.html
____________________
https://www.infoq.com/news/2019/09/waymo-machine-learning-dataset/
Waymo Shares Autonomous Vehicle Dataset for Machine Learning 
__________________
https://www.cerebras.net/technology/
The world's largest chip

46,225 mm2 chip
56x larger than the biggest GPU ever made
400,000 cores
78x more cores
18 GB on-chip SRAM
3000x more on-chip memory
100 Pb/s interconnect
33,000x more bandwidth 
_______________
MLflow: An Open Platform to Simplify the Machine Learning Lifecycle
______________________
http://blog.classora.com/2012/09/30/taxonomias-ontologias-y-folksonomias-que-son-y-para-que-sirven/
Taxonomías, ontologías y folksonomías... ¿qué son y para qué sirven?
________________________________
https://www.infoq.com/presentations/mlflow-databricks/
_________________________
https://www.linuxlinks.com/excellent-r-natural-language-processing-tools/
 7 Excellent R Natural Language Processing Tools 
