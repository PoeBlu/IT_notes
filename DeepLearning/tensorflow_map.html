<html>
<head>
   <meta charset="UTF-8">
   <title>Tensorflow Map</title>
<!-- mapview_v1 {{{ -->
<script>
var zoomDivDOM
function doCloseZoom() {
  zoomDivDOM.innerHTML = ''; 
  zoomDivDOM.style.display="none";
}
var zoomDivFW = true; // FW Full Width
var zoomDivFH = true; // FW Full Height 
var zoomDivTop = true; 
var zoomDivLft = true; 

var zoom=0.1
var idxXXXsmallRule=-1;
var idxXXsmallRule =-1;
var idxXsmallRule  =-1;
function onZoomOut(){
  zoom=zoom - 0.05
  document.styleSheets[0]['cssRules'][idxXXXsmallRule].style['font-size']=zoom+'rem';
}
function onZoomIn(){
  zoom=zoom + 0.05
  document.styleSheets[0]['cssRules'][idxXXXsmallRule].style['font-size']=zoom+'rem';
}
function doOpenZoom(e)      { 
  zoomDivDOM.innerHTML = 
     "<span style='font-size:1.0rem; color:blue;'>('Esc' to close)<br/></span>" 
   + this.outerHTML; 
  zoomDivDOM.style.display="block";
  e.stopPropagation();
}

function removeToLeftMarginInPre() {
  // TODO:(0) Not working
  // nodeList = document.querySelectorAll('pre')
  // for (idx in nodeList) { 
  //   var node = nodeList[idx]
  //   var html = node.innerHTML
  //   var pattern = html.match(/^\s*[|]/)
  //   var regEx = new RegExp(pattern, "")
  //   console.log(html)
  //   node.innerHTML = html.replace(regEx,''))
  //    
  // }
}


function onPageLoaded() {
  zoomDivDOM = document.getElementById('zoomDiv')
  document.addEventListener('keyup',function(e) { if (e.code !== "Escape") return; doCloseZoom(); })
  // Change default a.target to blank. Ussually this is bad practice 
  // but this is the exception to the rule
  var nodeList = document.querySelectorAll('a')
  for (idx in nodeList) { 
      if (!nodeList[idx].href) { continue; }
      if (nodeList[idx].href && !nodeList[idx].href.startsWith("http")) continue;
      nodeList[idx].target='_blank'; 
  }
  nodeList = document.querySelectorAll('td')
  for (idx in nodeList) { 
     if (!!! nodeList[idx].addEventListener) continue;
     nodeList[idx].addEventListener('dblclick',doOpenZoom, false)
  }
  nodeList = document.querySelectorAll('*[zoom]')
  for (idx in nodeList) { 
     if (!!! nodeList[idx].addEventListener) continue;
     nodeList[idx].addEventListener('dblclick',doOpenZoom, false)
  }

  removeToLeftMarginInPre();

  for (idx=0; idx<document.styleSheets[0]['cssRules'].length; idx++){
      if( document.styleSheets[0]['cssRules'][idx].selectorText == "[xxxsmall]") {
          idxXXXsmallRule=idx;
      }
      if( document.styleSheets[0]['cssRules'][idx].selectorText == "[xxsmall]") {
          idxXXsmallRule=idx;
      }
      if( document.styleSheets[0]['cssRules'][idx].selectorText == "[xsmall]"  ) {
          idxXsmallRule=idx;
      }
  }
  // Simulate initial dblclick to show help
  var event = new MouseEvent('dblclick', { 'view': window, 'bubbles': true, 'cancelable': true });
  document.getElementById('initialMessage').dispatchEvent(event);
}
</script>
<style { >
*[blue]         { color:blue !important;  }
*[orange]         { color:orange !important; }
*[green]         { color:green !important;  }
*[brown]         { color:brown !important;  }
b { color: #0A9}
*[mono]         { font-family: monospace; white-space: pre; }
pre { background-color:#EEEEEE; outline:1px dotted grey; margin: 0; }
*[cite]         { font-style: italic; }
*[TODO]         { color:red; font-weight: bold; }
*[TODO]:before  { content: "TODO:"; }
*[xxxsmall]{ font-size:0.1rem; }
img[xxxsmall]{ max-width:10rem; }
*[xxsmall] { font-size:0.3rem; }
*[xsmall]  { font-size:0.7rem; }
*[small]   { font-size:0.9rem; }
*[xxbig]  { font-size:1.7em; font-weight: bold; color:#007733;}
*[xbig]  { font-size:1.5em; }
*[hidden]  { display:none; }
ul,ol { margin-left: 1.0em; padding-left: 0rem; }
#zoomDiv [xxxsmall] , #zoomDiv * [xxxsmall], #zoomDiv * * [xxxsmall], #zoomDiv * * * [xxxsmall]{ font-size:1em; } 
#zoomDiv img[xxxsmall] , #zoomDiv * img[xxxsmall], #zoomDiv * * img[xxxsmall], #zoomDiv * * * img[xxxsmall]{ max-width:100%; } 

/* REF: https://stackoverflow.com/questions/4910077/select-all-child-elements-recursively-in-css */
#zoomDiv * [small], #zoomDiv * [xsmall], #zoomDiv * [xxsmall] { font-size:1em; }
#zoomDiv *[small], #zoomDiv *[xsmall], #zoomDiv *[xxsmall] { font-size:1em; }
#zoomDiv * td { font-size:1em; }

body      { font-family:sans-serif; font-size:16px; padding: 0; margin: 0; }
#zoomDiv  { 
   display:none;
   position:fixed; top:0.1%; left:0.1%; width:auto; height:auto;
   max-height: 98%; max-width: 98%; overflow: auto;
   background-color:#FFFFFF; color:#000; border-radius: 0.5rem; border: 4px solid black; font-size: 2rem;
   box-shadow: 5px 5px 30px black;
   padding: 0.5rem;
}

a            { text-decoration:none; font-family:monospace; padding:0.0;}
a[href^="#"]:before /* mark internal anchor */ {  content: ">"; }
a[href^="#"]:after  /* mark internal anchor */ {  content: "<"; }
a:visited { color:blue; }
td { 
   font-size: 0.8rem;
   vertical-align: top;
   outline: 1px solid grey; 
}
td,th               {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col0] ,th[col1]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col2] ,th[col2]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col3] ,th[col3]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col4] ,th[col4]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col5] ,th[col5]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col6] ,th[col6]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col7] ,th[col7]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col8] ,th[col8]  {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col9] ,th[col9]  {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col10],th[col10] {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
td[col11],th[col11] {background-color:#FFFFFF; min-width:8.25%; max-width:8.25%; }
td[col12],th[col12] {background-color:#FAFAFA; min-width:8.25%; max-width:8.25%; }
tr[header_delimit] > *{background-color:#000000; color:#FFFFFF; font-size:2em; color: white; }
tr[header_delimit] > td > a{color:inherit; text-decoration: underline; }
div[subtable1] { max-width: 95%; overflow: auto; padding:0; margin: 0;}

table { width:100% border:0; margin: 0;}
</style }>
</head>
<body onLoad='onPageLoaded()'>
<b id='initialMessage' orange>Hint double-click on elements to zoom!!</b>
<div id='zoomDiv'></div>
<div style="position:fixed; right:0.3%; bottom:0; width:auto;">
<b style="font-size:1.5rem" orange><a onclick="onZoomOut()">[-A]</a></b>
<b style="font-size:1.5rem"       >                                 </b>
<b style="font-size:2.0rem" orange><a onclick="onZoomIn ()">[A+]</a></b>
</div>
<!-- mapview_v1 }}} -->

<table>
<tr header_delimit {>
  <td topic >topic</td>
  <td summa >summa</td>
  <td col1  ></td>
  <td col2  ></td>
</tr>
<tr {>
  <td topic ><a href='https://www.tensorflow.org/'>Tensor Flow</a></td>

  <td summa >
    <ul>
      <li>
You might think of TensorFlow Core programs as consisting of two discrete sections:<br/>
    - Building the computational graph<br/>
    - Running the computational graph
      </li>
      <li>TensorBoard: display pictures of the Computational graph </li>
    </ul>
  </td>
  <td col1  >
    <pre>
import tensorflow as tf
    </pre>
  </td>
  <td col2  ></td>
</tr }>
<tr header_delimit {>
  <td colspan=4 >Building blocks</td>
</tr>

<tr {>
  <td topic >tensor</td>
  <td summa >
    <ul>
      <li>
    A tensor consists of a set of primitive values shaped into an array of any number of dimensions. <br/>
      </li>
      <li>tensor rank = number of dimensions</li>
      <li></li>
    </ul>
  </td>
  <td col1  ></td>
  <td col2  ></td>
</tr }>


<tr {>
  <td topic >Session</td>
  <td summa >
    <ul>
      <li></li>
    </ul>
  </td>
  <td col1  >
    <ul>
      <li>
        <pre { >
sess = tf.Session()
# init is a handle to TF sub-graph initializing
# all the global variables
init = tf.global_variables_initializer()
sess.run(init)
        </pre }>
      </li>

  </td>
  <td col2  ></td>
</tr }>

<tr {>
  <td topic >(Graph Tensor) Node</td>
  <td summa >
    <ul>
      <li>Each node takes zero or more tensors as inputs and produces a tensor as an output.</li>
      <li>constant node: takes no inputs, outputs a value it stores internally. </li>
      <li>Operations are also nodes</li>
    </ul>
  </td>
  <td col1  >
    <ul>
      <li>create two floating point constants node1 and node2:
        <pre { >
node1 = tf.constant(3.0, dtype=tf.float32)
node2 = tf.constant(4.0) # tf.float32 implicit
sess.run([node1, node2])
> [3.0, 4.0]
node3 = tf.add(node1, node2)
sess.run(node3)
> [4.0]
        </pre }>
      </li>
      <li>Variables (trainable model)
        <pre { >
W = tf.Variable([ .3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
#                ^initial value 
x = tf.placeholder(tf.float32)
linear_model = W * x + b
session.run(linear_model, {x:[1,2,3,4])
> [0. 0.30000001 0.60000002 0.90000004]
# y: input data
y = tf.placeholder(tf.float32)
<p important>
# A loss function measures how far apart 
# the current model is from provided data (y)
squared_deltas = tf.square(linear_model - y)
loss = tf.reduce_sum(squared_deltas)
sess.run(loss, {
  y: [0, -1, -2, -3],
  x: [1, 2, 3, 4]
})
> 23.66
</p>

        </pre }>
      </li>
   </ul>

  </td>
  <td col2  >
   <ul>
      <li>Manual fix loss function
        <pre { >
fixW = tf.assign(W, [-1.])
fixb = tf.assign(b, [1.])
sess.run([fixW, fixb])
sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})
> 0.0
        </pre }>
      </li>
   </ul>
  </td>
</tr }>

<tr {>
  <td topic >Computational Graph (CG)</td>
  <td summa >
    <ul>
      <li> A CG is a series of TensorFlow operations arranged into a graph of nodes.
      </li>
      <li>placeholders: used to parameterize external inputs (promise of value provided later)
        <pre {>
a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b  # + provides a shortcut for tf.add(a, b)
input={a: 3, b: 4}
sess.run(adder_node, feed_dict=input)
> 7
input={a: [1, 3], b: [2, 4]}
sess.run(adder_node, feed_dict=input)
[3., 7.]

        </pre }>
 
</li>
      <li>
        To make the model trainable, we need to be able to
        modify the graph to get new outputs with the same input.
        Variables allow us to add trainable parameters to a
        graph. They are constructed with a type and initial value:
      </li>
      <li></li>
      <li></li>
    </ul>
  </td>
  <td col1  >
graph=[node1, node2]
sess.run(graph)
  </td>
  <td col2  ></td>
</tr }>

<tr {>
  <td topic >Training (tf.train)</td>

  <td summa >
    <ul>
      <li>
      </li>
    </ul>
  </td>
  <td col1  >
    <pre>
    </pre>
  </td>
  <td col2  ></td>
</tr }>

</table>
</body>
<!--
REF: http://www.alanflavell.org.uk/unicode/unidata25.html
─  ┐  ┠   ┰    ╀   ═   ╠   ╰     ┌─────┬─────┐
                                 │     │     │
━  ┑  ┡   ┱    ╁   ║   ╡   ╱     │     │     │
                                 ├─────┼─────┤
│  ┒  ┢   ┲    ╂   ╒   ╢   ╲     │     │     │
                                 │     │     │
┃  ┓  ┣   ┳    ╃   ╓   ╣   ╳     └─────┴─────┘
                                 ← ↑
┄  └  ┤   ┴    ╄   ╔   ╤   ╴     → ↓

┅  ┕  ┥   ┵    ╅   ╕   ╥   ╵     ┌─────────┐
                                 │         │
┆  ┖  ┦   ┶    ╆   ╖   ╦   ╶     │         │
                                 │         │
┇  ┗  ┧   ┷    ╇   ╗   ╧   ╷     │         │
                                 └─────────┘
┈  ┘  ┨   ┸    ╈   ╘   ╨   ╸ 

┉  ┙  ┩   ┹    ╉   ╙   ╩   ╹ 

┊  ┚  ┪   ┺    ╊   ╚   ╪   ╺ 

┋  ┛  ┫   ┻    ╋   ╛   ╫   ╻ 

┌  ├  ┬   ┼    ╌   ╜   ╬   ╼ 

┍  ┝  ┭   ┽    ╍   ╝   ╭   ╽ 

┎  ┞  ┮   ┾    ╎   ╞   ╮   ╾ 

┏  ┟  ┯   ┿    ╏   ╟   ╯   ╿ 


-->
<!--
ma: https://www.tensorflow.org/get_started/get_started
-->

<!--
keras.io:
high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. 
It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.

__________________
aidu, the Chinese Internet giant, has released ApolloScape, a massive dataset for autonomous vehicle simulation and machine learning.

ApolloScape is an order of magnitude bigger and more complex than existing similar datasets such as Kitti and CityScapes. ApolloScape offers 10 times more high-resolution images with pixel-by-pixel annotations, and includes 26 different recognizable objects such as cars, bicycles, pedestrians and buildings. The dataset offers several levels of scene complexity with increasing number of pedestrians and vehicles, up to 100 vehicles in a given scene, as well as a wider set of challenging environments such as heavy weather or extreme lighting conditions. The ApolloScape dataset is a work in progress, and this release corresponds to the first subset, which contains 144k image frames.

The ApolloScape dataset is part of version 2 of Apollo, Baidu's open autonomous driving platform. The Apollo source code, open sourced under an Apache-2.0 license, includes a 2D/3D simulation driving vehicle environment as well as hardware instructions to set up a vehicle for further data collection. Clear instructions can be found in the Apollo GitHub project to help install the simulation environment within a Docker environment.

This dataset will be used to boost research on automated-learning tasks such as finding the roads (Drivable Area Segmentation), detecting the objects (Road Object Detection), allowing model generalization for different locations or weather conditions (Domain Adaptation of Semantic Segmentation) and tracking moving objects (Instance-level Video Movable Object Segmentation).

These research tasks make up the Workshop on Autonomous Driving (WAD) Challenge sponsored by Baidu and taking place next June during CVPR 2018, the IEEE International Conference on Computer Vision and Pattern Recognition. The WAD challenge regroups researchers and engineers across academia and industries to discuss computer vision applications in autonomous driving.

According to ArsTechnica, Waymo, the self-driving unit of Google parent company Alphabet, is currently leading the global innovation in autonomous vehicles along with GM, while Baidu is for the time being viewed more as a contender in the automated driving sector. Opening up the ApolloScape dataset could be interpreted as a move by Baidu to weaken Google's data advantage and increase its own relative position in the industry.

To that effect, Baidu further announced it has joined the Berkeley DeepDrive (BDD) Industry Consortium, a top-tier research alliance which includes Ford, NVIDIA, Qualcomm, and General Motors. BDD focuses on innovations in deep reinforcement learning, cross-modal transfer learning applied to autonomous driving.

Baidu has also partnered with Udacity, an online data-science education website, to launch on online course titled Intro to Apollo which is part of Udacity’s nano degree on self-driving cars. The course start date has not yet been set.

KPMG’s 2018 Index on Autonomous Vehicles Readiness ranks China at number 16 in terms of the 20 countries preparedness for an autonomous vehicle future. Baidu is one of three major Chinese autonomous driving companies along with JingChi.ai and Pony.ai.
-->
</html>
 







