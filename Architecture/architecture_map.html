<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>architecture map (alpha)</title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>

<body>

<table>
<tr>
  <th colspan=10>DB Engines (REF: <a href="https://db-engines.com/">db-engines.com</a>, <a href="https://db-engines.com/en/ranking">ussage Ranking</a>)<br/>
  <a href="https://dzone.com/articles/rant-there-is-no-nosql-data-storage-engine">REF: "There is no NoSQL data storage</a>
  </th>
</tr>
<tr>
<td>
  RDBMS
  <ul xxxsmall zoom>
  <li>support the relational (=table-oriented) data model. The schema of a table
      (=relation schema) is defined by the table name and a fixed number of 
      attributes with fixed data types. A record (=entity) corresponds to a row
      in the table and consists of the values of each attribute. A relation 
      thus consists of a set of uniform records.</li>
  <li>The table schemas are generated by normalization in the process of data modeling.</li>
  <li>Certain basic operations are defined on the relations:
    <ul>
    <li> classical set operations (union, intersection and difference)                                                        </li>
    <li> Selection (selection of a subset of records according to certain filter criteria for the attribute values)           </li>
    <li> Projection (selecting a subset of attributes / columns of the table)                                                 </li>
    <li> Join: special conjunction of multiple tables as a combination of the Cartesian product with selection and projection.</li>
    </ul></li>
  <li>These basic operations, as well as operations for creation, modification 
    and deletion of table schemas, operations for controlling transactions and 
    user management are performed by means of database languages, 
    with SQL being a well established standard for such languages.</li>
  <li>The first relational database management systems appeared on the market at the beginning of the 1980s and since have been the most commonly used DBMS type.</li>
  </ul>
  Main  Examples
<pre xxxsmall zoom>
Oracle
MySQL
TiDB   (MySQL compatible, RAFT-distributed, Rust/go written) featuring:
       - "infinite horizontal scalability", strong consistency, HA
SQL Server
PostgreSQL
DB2
Hive          - <a href="https://hive.apache.org/">home</a>
              - Data Warehouse designed for Hadoop
              - <a href="https://db-engines.com/en/system/Hive">db-engines.com description</a>
              - Implemented in Java
              - pache Hive supports analysis of large datasets stored in Hadoop's HDFS and
                compatible file systems such as Amazon S2 filesystem.
              - SQL-like DML and DDL statements (WARN: No Foreign keys, NO ACID)
                Traditional SQL queries must be implemented in the MapReduce Java API to  
                execute SQL applications and queries over distributed data. Hive provides
                the necessary SQL abstraction to integrate SQL-like queries (HiveQL) into
                the underlying Java without the need to implement queries in the low-level
                Java API. Since most data warehousing applications work with SQL-based 
                querying languages
              - Hive aids portability of SQL-based applications to Hadoop
              - JDBC, ODBC, Thrift
              - Eventual Consistency!!

</pre>
</td>
<td>
  Key-value Stores
  <ul xxxsmall zoom>
  <li>probably the simplest form of database management systems. They can only 
      store pairs of keys and values, as well as retrieve values when a key is known.</li>
  <li>These simple systems are normally not adequate for complex applications. 
      On the other hand, it is exactly this simplicity, that makes such systems
      attractive in certain circumstances. For example resource-efficient key-value
      stores are often applied in embedded systems or as high performance 
      in-process databases.</li>
  <li>Advanced Forms: An extended form of key-value stores is able to sort the 
      keys, and thus enables range queries as well as an ordered processing of keys.<br/>
      Many systems provide further extensions so that we see a fairly seamless 
      transition to document stores and wide column stores.</li>
  </ul>
  Examples:
<pre xxxsmall zoom>
Redis
Amazon DynamoDB
Memcached
Microsoft Azure Cosmos DB
Hazelcast
TiKV  (Rust) Incubation Kubernetes project, used also for TiDB
</pre>
</td>

<td>
   Time Series DBMS
  <ul xxxsmall zoom>
  <li>If you want to know, for example, the impact a new change has on the
     number of hits on your API, or how a specific software fix affected
     your database’s latency, comparing the present value to a previous one 
     done BEFORE the change was introduced will be useful. Such is the value
     of time series data.</li>
  (DDBB) tools built around time series data need to do the following under a very high transaction volume:
  <li>Time Series DBMS are designed to efficiently collect, store and query 
    various time series with high transaction volumes. Although time series 
    data can be managed with other categories of DBMS (from key-value stores 
    to relational systems), the specific challenges often require specialized 
    systems.</li>
  <li>E.g. a query like 'SELECT SENSOR1_CPU_FREQUENCY / SENSOR2_HEAT' joins two
      time series based on the overlapping areas of time for each and outputs a
      single composite time series.</li>
  <li>For example, time series data may be produced by sensors, smart meters or
      RFIDs in the so-called Internet of Things, or may depict the stock tickers
      of a high frequency stock trading system.</li>
  </ul>
  Examples:
<pre xxxsmall zoom>
Timescale.com - PostgreSQL optimized for Time Series.
                """ Optimized query engine: We modified the PostgreSQL insert path, 
                  execution engine, and query planner to intelligently process 
                  queries across chunks. We continue to leverage PostgreSQL's 
                  battle-tested storage layer for the reliability you need to
                  support mission critical workloads.  """
_
InfluxDB
Kdb+
Graphite      - <a href="https://logz.io/blog/prometheus-vs-graphite/">Prometheus vs. Graphite: Which Should You Choose for Time Series or Monitoring?</a>
              - In a way, Graphite is simpler than Prometheus, with fewer features and a simple raison d’etre.
                According to its own documentation, it does precisely two things:
                - Store numeric time series data
                - Render graphs of this data
              - Although Graphite will not collect data for you, there is a component—a Twisted daemon called Carbon—
                which passively listens for time series data. Data is stored in a simple library called Whisper.
                That means that data collection to Graphite is passive, meaning that applications sending it data 
                need to be configured to send data to Graphite's carbon component.
              - graphs can be rendered on-demand via a simple Django web app.
RRDtool
Prometheus    - <a href="https://prometheus.io/">home</a> 
              - GoLang based. All binaries are statically linked and easy to deploy.
              - Many client libraries.
              - Part of the CNCF. (Kubernetes friendly)
              - monitoring metrics analyzer and alerting
              - Highly dimensional data model. Time series are identified by a metric
                name  and a set of key-value pairs.
              - Part of (Fedora/RedHat) CoreOS.
              - stores all data as time series: streams of timestamped values belonging
                to the same metric and the same set of labeled dimensions.
              - Multiple mode for visualizing data:
                - Built-in expression browser, Grafana integration, console template lang
              - Query language: PromQL: allows to select and aggregate time
                series data in real time. The result can either be shown as a graph,
                tabular data or consumed by external systems via HTTP API.
              - Precise alerts based on PromQL.
              - (optionally) integrates with remote storage systems.
              - alerts can be defined using expression language
                to send notifications about firing alerts to an external service
              - while Graphite is a simpler "data logging and graphing tool for time series data."
                Prometheus adds features over Graphite including a flexible query language, a push
                gateway (for collecting metrics from ephemeral or batch jobs), a range of exporters, ...
              - Support scaling through sharding and federation
              - Easy admin: Each server is independent, relying only on local storage.


Uber M3       <a href="https://www.infoq.com/news/2018/08/uber-metrics-m3">REF:</a>
              - Large Scale Metrics Platform 
              - built to replace its Graphite based system, backed by a sharded Carbon cluster,
                with Nagios for alerting and Grafana for dashboarding.  Issues with this included
                poor resiliency and clustering, high operational cost to expand the Carbon cluster,
                and a lack of replication which made each node a single point of failure. 
              - M3 was born out of these shortcomings. 
              - provides cluster management, aggregation, collection, storage management, 
                a distributed time series database (TSDB) and a query engine with its own query language M3QL.
              - In addition to scalability, global, responsive querying across datacenters, the goals for 
                the new system were the ability to tag metrics, and maintain backwards compatibility with services
                that emitted metrics in the StatsD and Graphite format.  
              - Due to the widespread use of Prometheus in multiple teams at Uber, M3 was built to integrate
                with Prometheus as a remote storage backend: The Prometheus integration is via a sidecar component 
                that writes to local regional M3DB instances and fans out queries "to inter-regional coordinators 
                which coordinate reads from their local regional M3DB (the storage engine) instances":
                This model is similar to the the way that Thanos, an extension to Prometheus that provides 
                cross-cluster federation, unlimited storage and global querying across clusters, works.
              - M3's query engine provides a single global view of all metrics without cross region replication.
                Metrics are written to local regional M3DB instances and replication is local to a region.
                Queries go to both the regional local instances as well as to coordinators in remote regions where
                metrics are stored. The results are aggregated locally, and future work is planned wherein any
                query aggregation would happen at the remote coordinators.
              - Own query language - M3QL - is used internally at Uber due to features that are not available in PromQL.
              - The team is working on adding support for running M3 on Kubernetes.
              - Written in Go.
</pre>

  Related
<pre xxxsmall zoom>
<a href="https://www.infoq.com/news/2018/09/pinterest-goku-timeseries-db>Pinterest Switches from OpenTSDB to Their Own Time Series Database</a>

<a href="https://facebook.github.io/prophet/">Prophet</a>, a time-series forecasting library (wrapper around Stan), is a particularly approachable place to use Bayesian Inference for forecasting use cases general purpose.
      Prophet is a procedure for forecasting time series data based on an 
additive model where non-linear trends are fit with yearly, weekly, and daily 
seasonality, plus holiday effects. It works best with time series that have 
strong seasonal effects and several seasons of historical data. Prophet is 
robust to missing data and shifts in the trend, and typically handles outliers well.
</pre>
</td>

<td>
  Search Engines
  <ul xxxsmall zoom>
  <li>"NoSQL" database management systems dedicated to the search for data content.</li>
  <li>In addition to general optimization for this type of application, the specialization consists in typically offering the following features:
    <ul>
    <li>Support for complex search expressions           </li>
    <li>Full text search                                 </li>
    <li>Stemming (reducing inflected words to their stem)</li>
    <li>Ranking and grouping of search results           </li>
    <li>Geospatial search                                </li>
    <li>Distributed search for high scalability          </li>
    </ul>
  </li>
  </ul>
  Examples
<pre xxxsmall zoom>
Elasticsearch
Splunk
Solr
MarkLogic
Sphinx
<a href="https://projects.eclipse.org/projects/modeling.hawk">Eclipse Hawk</a>
               heterogeneous model indexing framework: it indexes collections of models 
              transparently and incrementally into a NoSQL database, which can be queried 
              in a more efficient and convenient manner. You can mirror EMF, UML or Modelio 
              models (among others) into a Neo4j or OrientDB graph, which you can query 
              with their native languages, or (preferably) through the languages provided 
              by Hawk. Hawk will watch over those models and update the graph whenever they 
              change, in an incremental manner.
</pre>
</td>
<td>
  Graph DBMS
  <ul xxxsmall zoom>
  <li>Graph DBMS, also called graph-oriented DBMS or graph database, represent 
    data in graph structures as nodes and edges, which are relationships between
    nodes. They allow easy processing of data in that form, and simple calculation
    of specific properties of the graph, such as the number of steps needed to 
    get from one node to another node.</li>
  <li>Graph DBMSs usually don't provide indexes on all nodes, direct access to
    nodes based on attribute values is not possible in these cases.</li>
  </ul>
  Examples:
<pre xxxsmall zoom>
    Neo4j
    Microsoft Azure Cosmos DB
    Datastax Enterprise
    OrientDB
    ArangoDB
</pre>
  <hr xxxsmall />
  <a href="https://db-engines.com/en/article/RDF+Stores">RDF stores</a>
  <ul xxxsmall zoom>
  <li>The Resource Description Framework (RDF) is a methodology for the 
    description of information, originally developed for describing metadata 
    of IT resources. Today it is used much more generally, often in connection 
    with the sematic web, but also in other applications.</li>
  <li>The RDF model represents information as triples in the form of subject-predicate-object.</li>
  <li>Database management systems, which are able to store and process such 
    triples, are called RDF stores or triple stores.</li>
  <li>RDF stores can be seen as a subclass of graph DBMS, by interpreting the 
    predicate as a connection between subject and object in the above notation. 
    However, RDF stores offer specific methods that go beyond those of the 
    general graph DBMS. For example, SPARQL, an SQL-like query language for RDF 
    data, is supported by most RDF stores.</li>
  </ul>

  Examples
<pre xxxsmall zoom>
MarkLogic
Jena
Virtuoso
Amazon Neptune
GraphDB
</pre>

</td>

<td>
  Wide Column Stores<br/>
  (<a href="http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">REF 1:BigTable</a>)
  <ul xxxsmall zoom>
  <li>Wide column stores, also called extensible record stores, store data in 
    records with an ability to hold very large numbers of dynamic columns. Since
    the column names as well as the record keys are not fixed, and since a 
    record can have billions of columns, wide column stores can be seen as 
    two-dimensional key-value stores.</li>
  <li>Wide column stores share the chracteristic of being schema-free with 
    document stores, however the implementation is very different.</li>
  <li>Wide column stores must not be confused with the column oriented storage 
    in some relational systems. This is an internal concept for improving the 
    performance of an RDBMS for OLAP workloads and stores the data of a table 
    not record after record but column by column.</li>
  </ul>
  Examples
<pre xxxsmall zoom>
Cassandra     - SQL-like SELECT, DML and DDL statements (CQL)
              - Designed to handle large amounts of data across many commodity servers, 
                providing high availability with no single point of failure. 
              - robust support for clusters spanning multiple datacenters,
                with asynchronous masterless replication allowing low latency
                operations for all clients.

               Related: <a href="https://www.infoq.com/news/2018/10/spotify-cstar">REF</a>
               Spotify Open Sources cstar: its Cassandra Orchestration Tool
               
               Cstar emerged from the necessity of running shell commands in 
               Cassandra nodes. These shell commands are usually related to 
               performance, security, consistency, upgrade, etc.
               
               According to Spotify, during 2017 the Spotify Cassandra fleet 
               reached 3000 nodes; from there, the necessity of having a safe and 
               efficient solution for running shell commands became increasingly 
               more urgent. An example of a task nightmare was a scheduled upgrade 
               of their entire Cassandra fleet, which required the following steps:
               
               - Clear all snapshots (to have enough disk space to finish the upgrade)
               - Take a new snapshot (to allow a rollback)
               - Disable automated puppet runs
               - Stop the Cassandra process
               - Run puppet from a custom branch of our git repo in order to upgrade the package
               - Start the Cassandra process again
               - Update system.schema_columnfamilies to the JSON format
               - Run `nodetool upgradesstables`, which depending on the amount of data 
                    on the node, could take hours to complete
               - Remove the rollback snapshot
               
               Furthermore, there are a series of other related problems when 
               dealing with Cassandra fleet, such as network failures, ssh 
               connection interruptions, CPU-intensive operations, Cassandra 
               process/nodes restarting without impacting performance and 
               availability, or partially finished executions handling (tasks 
               succeed only in some nodes).
               
               In the early Spotify days, the most common way of running commands 
               on Cassandra nodes was to be typing the command in multiple terminals.
               
               Cstar aims to address these problems

Scylla        - Designed to be compatible with Cassandra while achieving significantly 
                higher throughputs and lower latencies. It supports the same protocols as
                Cassandra (CQL and Thrift) and the same file formats (SSTable), but is
                a completely rewritten implementation, using the C++14 language replacing
                Cassandra's Java, and the Seastar asynchronous programming library replacing
                threads, shared memory, mapped files, and other classic Linux programming
                techniques.
              - Scylla uses a sharded design on each node, meaning that each CPU core handles
                a different subset of data. Cores do not share data, but rather communicate 
                explicitly when they need to. The Scylla authors claim that this design allows
                Scylla to achieve much better performance on modern NUMA SMP machines, and to
                scale very well with the number of cores. They have measured as much as 2 million
                requests per second on a single machine, and also claim that a Scylla cluster
                can serve as many requests as a Cassandra cluster 10 times its size - 
                and do so with lower latencies.
HBase
CosmosDB
</pre>
</td>

<td>
  Service Registration and Discovery: 
  <a href="https://technologyconversations.com/2015/09/08/service-discovery-zookeeper-vs-etcd-vs-consul/">REF</a>

  <ul xxxsmall zoom>
  <li>Speciallized key/value DDBB for service registration and discovery</li>
  <li>In order to be able to locate our services we need at least the following
    two processes to be available for us.
    <ul>
    <li>Service registration process that will store, as a minimum, the host and
      the port service is running on.</li>
    <li>Service discovery process that will allow others to be able to discover
      the information we stored during the registration process.</li>
    </ul>
  </li>
  <li>other aspects to consider:
  <ul>
  <li>Should we unregister the service if it stops working and deploy/register a new instance? </li>
  <li>What happens when there are multiple copies of the same service? </li>
  </ul></li>
  <li> Most of them feature some kind of highly available distributed key/value storage.</li>
  <li>The main objective of service discovery tools is to help services find and talk
    to one another. In order to perform their duty they need to know where each service is.</li>
  <li>Any new instance of a service (or an application) must be able to identify
its current environment and store that information (stored in a key/value DDBB normally)</li>
  <li>Discovery tools tend to provide some kind of API that can be used by a 
    service to register itself as well as by others to find the information about that service.</li>
  </ul>
  Examples:
<pre xxxsmall zoom>
See also: <a href="https://coreos.com/etcd/docs/latest/learning/why.html">etcd|zookeeper|consul|"NewSQL" Comparision Chart</a>
ZooKeeper (one of the oldest projects of this type), It originated out of the 
          Hadoop world, where it was built to help in the maintenance of the
          various components in a Hadoop cluster. 
          The format of the data it stores is similar to the organization of the file system.
          Can be run on cluster mode. Each cluster elects a leader and clients can
          connect to any of the servers to retrieve data.
          Disadvantages:
          - complex: Maintaining it requires considerably more knowledge than we should 
                     expect from an application of this type
          - Java plus a considerable number of dependencies is too much bloated for this type of task
          Today, Zookeeper it shows its age and we are better off with alternatives.
          - Used by kafka for config. (there is
            <a href="https://issues.apache.org/jira/browse/KAFKA-6598">WiP</a> to 
            replace dependency)

etcd     distributed key/value store accessible through HTTP. 
         - hierarchical configuration system that can be used to build service discovery. 
         - Very easy to deploy, setup and use, provides reliable data persistence,
           it’s secure and with a very good documentation.
         - <a href="https://coreos.com/blog/introducing-zetcd">zetcd</a> sits in front of
           etcd and can handle ZooKeeper requests using etcd for back end storage.
           This allows you to use ZooKeeper based apps (such as Kafka) with etcd.
         Disadvantages:
         - needs to be combined with few third-party tools before it can serve 
           service discovery objectives:
           - etcd-registrator to keep an updated list of docker containers
           - etcd-registrator-confd to keep updated config files
           - ...
         - Used by Kubernetes for config

Consul   strongly consistent datastore that uses gossip to form dynamic clusters.
         - It was designed with services architecture and discovery in mind.
         - It features hierarchical key/value store and adds the  notion of a
           service together with data that belongs to it. "watches" can be registered
           that can be used for a variety of tasks from sending notifications about
           data changes to running health checks and custom commands depending on their output.
         - Unlike Zookeeper and etcd, Consul implements service discovery system 
           embedded so there is no need to build your own or use a third-party one.
           This discovery includes, among other things, health checks of nodes and
           services running on top of them.
         - ZooKeeper and etcd provide only a primitive K/V store and require that
           application developers build their own system to provide service discovery.
           Consul, on the other hand, provides a built in framework for service discovery.
           Clients only need to register services and perform discovery using the DNS 
           or HTTP interface. The other two tools require either a hand-made solution
           or the usage of third-party tools.
         - offers out of the box native support for multiple datacenters and the
           gossip system that works not only among nodes in the same cluster but 
           across datacenters as well.
         - provides easy to extend health checks through HTTP requests, 
           TTLs (time-to-live) and custom commands.
         - consul-template is a very convenient way to create configuration files
         Consul Health checks, Web UI and datacenters:
         - Consul has a simple, elegant and, yet powerful way to perform health
           checks and help us to define what actions should be performed when 
           health thresholds are reached.
         - the Web UI display all services and nodes, monitor health checks
           and their statuses, read and set key/value data as well as switch
           from one datacenter to another.
doozerd  (TODO)
</pre>
</td>
<td>
Document Stores
  <ul xxxsmall zoom>
  <li>also called document-oriented database systems, are characterized by their schema-free organization of data.</li>
  <li>Records do not need to have a uniform structure, i.e. different records may have different columns.</li>
  <li>The types of the values of individual columns can be different for each record.</li>
  <li>Columns can have more than one value (arrays).                                                     </li>
  <li>Records can have a nested structure.                                                               </li>
  <li>Document stores often use internal notations, which can be processed directly in applications, mostly JSON.
       JSON documents of course can also be stored as pure text in key-value stores or relational database systems.
       That would, however, require client-side processing of the structures, which has the disadvantage
        that the features offered by document stores (such as secondary indexes) are not available.</li>
  </ul>
  Examples:
<pre xxxsmall zoom>
MongoDB (See <a href="https://www.infoq.com/articles/Starting-With-MongoDB">14 Things I Wish I’d Known When Starting with MongoDB</a>)
Amazon DynamoDB
Couchbase
Cosmos DB
CouchDB
</pre>
</td>
</tr>
</table>
<br/>
<hr/>

<table>
<tr>
  <th xsmall colspan=4>Data(log) collector</th>
  <th xsmall colsep />
  <th xsmall colspan=4>Distributed (<a href="https://martinfowler.com/eaaDev/EventSourcing.html">Event</a>) Stream Processors<br/>
    (See also <a TODO href="https://iwringer.wordpress.com/2015/08/03/patterns-for-streaming-realtime-analytics/">Ussage Patterns</a>)</th>
  <th xsmall colsep />
  <th xsmall colspan=1>Data Route/Process</th>
  <th xsmall colsep />
  <th xsmall colspan=1>Search/Indexers</th>
  <th xsmall colsep />
  <th xsmall colspan=2>Visualization</th>
</tr>
<tr>
<!--
<td>
<pre xsmall zoom bgorange>
Tags:
[performance]
[redundancy]
[log]        Loggin
[monitoring]
[analytics]
[testing]
[CI]         Continuous Integration
[IaC]        Infrastructure as code
</pre>
</td>
-->


<td>
  [log]<a href="https://www.fluentd.org/">FluentD</a><br/>
  (Improved "logstat")
  <ul xxxsmall zoom>
  <li>In the open source world, the two most-popular data collectors are Logstash 
    and Fluentd. Logstash is most known for being part of the ELK Stack while
    Fluentd has become increasingly used by communities of users of software such as Docker, GCP, and Elasticsearch.
  </li>
  </ul>
  <a href="https://logz.io/blog/fluentd-logstash/">FluentD vs Logstash compared</a>
<pre xxxsmall zoom { >
Open Source data collector for unified logging layer.

Fluentd allows you to unify data collection and consumption for
a better use and understanding of data.

Syslog                      Elasticsearch
Apache/Nginx logs    → → →  MongoDB
Mobile/Web app logs  → → →  Hadoop
Sensors/IoT                 AWS, GCP, ...
</td>
<td TODO>
  Logstash (E*L*K)
</td>
<td>
  OS Collector<br/>
  <ul xxxsmall zoom>
  <li><a TODO xsmall href="https://osquery.readthedocs.io/en/stable/">- OSquery</a>
<pre xxxsmall zoom>
   low-level instrumentation framework for Windows, OSX, Linux, FreeBSD with system analytics
   and monitoring both performant and intuitive.
   
   osquery exposes an operating system as a high-performance SQL relational database.
   With osquery, SQL tables represent abstract concepts such as running processes, 
   loaded kernel modules, open network connections, browser plugins, hardware events
   Features:
   - File Integrity Monitoring (FIM):
   - dns
 <a href="https://medium.com/palantir/osquery-across-the-enterprise-3c3c9d13ec55">Ref</a>
</pre>
  </li>
  <li><a xsmall href="https://github.com/prometheus/node_exporter">- Prometheus Node Exporter</a></li>
  <li><span xsmall>- collectd</span></li>
  <li><span xsmall>- Dynatrace OneAgent</span></li>
  <li><span xsmall>- Datadog agent</span></li>
  <li><span xsmall>- New Relic agent</span></li>
  <li><span xsmall>- Ganglia gmond</span></li>
  <li><span xsmall>- ...</span></li>
  </ul>
</td>
<td>
  <a href="https://opensource.com/article/18/9/quiet-log-noise-python-and-machine-learning">Logreduce <b bgorange>IA-log-filter</b></a><span TODO></span><br/>
  <a href=https://pypi.org/project/logreduce/">logreduce@pypi</a>
<pre xxxsmall zoom TODO>
  Quiet log noise with Python and machine learning
</pre>


</td>
<td colsep> </td>
<td>
  <span xsmall TODO>Stream Archs.</span>
<pre xxxsmall zoom>
<a href="https://en.wikipedia.org/wiki/Stream_processing">Stream_processing@Wikipedia</a>
<a href="https://www.infoq.com/streaming?utm_source=infoqEmail&utm_medium=editorial&utm_campaign=SpecialNL&utm_content=05182018">???</a>
<a href="https://www.infoq.com/presentations/squbs?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming Reactive Systems & Data Pites w. Squbs</a>
<a href="https://www.infoq.com/presentations/sql-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming SQL Foundations: Why I Love Streams+Tables </a>

<a href="https://www.infoq.com/presentations/flink-stateful-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Next Steps in Stateful Streaming with Apache Flink</a>
<a href="https://www.infoq.com/presentations/kafka-streams-spring-cloud?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Kafka Streams - from the Ground Up to the Cloud </a>
<a href="https://www.infoq.com/presentations/facebook-stream-processing?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Data Decisions with Real-Time Stream Processing</a>

<a href="https://www.infoq.com/presentations/beam-model-stream-table=theory?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Foundations of streamng SQL</a>
<a href="https://www.infoq.com/presentations/distributed-stream-processing-flink?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">The Power of Distributed Snapshots in Apache Flink</a>
<a href="https://www.infoq.com/presentations/sql-streams-panel?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Panel: SQL over Streams, Ask the Experts</a>
<a href="https://www.infoq.com/presentations/hbc-digital-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Survival of the Fittest - Streaming Architectures</a>
<a href="https://www.infoq.com/presentations/netflix-personalization-datasets-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming for Personalization Datasets at Netflix</a>

< href="https://www.safaribooksonline.com/library/view/an-introduction-to/9781491934951/">An Introduction to Time Series with Team Apache </a>
    Apache Cassandra evangelist Patrick McFadin shows how to solve time-series data
    problems with technologies from Team Apache: Kafka, Spark and Cassandra.
    
      - Kafka: handle real-time data feeds with this "message broker"
      - Spark: parallel processing framework that can quickly and efficiently 
               analyze massive amounts of data
      - Spark 
        Streaming: perform effective stream analysis by ingesting data in micro-batches
      - Cassandra: distributed database where scaling and uptime are critical
      - Cassandra Query Language (CQL): navigate create/update your data and data-models
      - Spark+Cassandra: perform expressive analytics over large volumes of data

</pre>
</td>
<td>
  <a xsmall href="http://kafka.apache.org/">Kafka</a>
  <a xsmall href="./kafka_map.html">(map)</a> <br/>
  <ul xxxsmall zoom>
  <li>It's NOT a real stream processor. It acts as a broker/message-bus to stores stream data for comsuption.
     "Kafka stream" can be use to add data-stream-processor capabilities</li>
  <li>log and events collection , (persistent fault-tolerant) streaming real-time processing platform, ...<br/>
  Used for two broad classes of applications:
    real-time streaming data pipelines that reliably get data between systems or applications<br/>
    real-time streaming applications that transform or react to the streams of data</li>
  <li>Each broker in the Kafka cluster has an identity which can be used to find other
brokers in the cluster. The brokers also need some type of a database to 
store partition logs. It's important to configure a Persistent Volume (PV) for 
Kafka, otherwise you will lose the logs.
  </li>
  </ul>
  <a href="http://kafka.apache.org/uses">(Popular) Use cases</a>
  <ul xxxsmall zoom>
  <li><def>Messaging</def> works well as a replacement for a more traditional 
    message broker.  Message brokers are used for a variety of reasons 
   (decoupling processing from data producers, buffering unprocessed messages, 
   etc). In comparison Kafka has better throughput, built-in partitioning, 
   replication, and fault-tolerance which makes it a good solution for large 
   scale message processing applications.
  </li>
  <li><def>Website Activity Tracking</def> was the original use case for Kafka
    to be able to rebuild a user activity tracking pipeline as a set of
    real-time publish-subscribe feeds. Page views, searches, .... is published
    to central topics with one topic per activity type. These feeds are 
    available for subscription for a range of use cases including real-time 
    processing, real-time monitoring, and loading into Hadoop or offline data 
    warehousing systems for offline processing and reporting.
  </li>
  <li><def>Metrics</def> operational monitoring data. This involves aggregating
    statistics from distributed applications to produce centralized feeds of 
    operational data.
  </li>
  <li><def>Log Aggregation</def> replacement for a log aggregation solution. 
    Log aggregation typically collects physical log files off servers and puts 
    them in a central place (a file server or HDFS perhaps) for processing. 
    Kafka abstracts away the details of files and gives a cleaner abstraction 
    of log or event data as a stream of messages. This allows for lower-latency
    processing and easier support for multiple data sources and distributed 
    data consumption. In comparison to log-centric systems like Scribe or Flume,
     Kafka offers equally good performance, stronger durability guarantees due 
     to replication, and much lower end-to-end latency.
  </li>
  <li><def>Stream Processing</def>: Kafka process data in processing pipelines 
   consisting of multiple stages, where raw input data is consumed from Kafka 
   topics and then aggregated, enriched, or otherwise transformed into new 
   topics for further consumption or follow-up processing. For example, a 
   processing pipeline for recommending news articles might crawl article 
   content from RSS feeds and publish it to an "articles" topic; further 
   processing might normalize or deduplicate this content and published the 
   cleansed article content to a new topic; a final processing stage might 
   attempt to recommend this content to users. Such processing pipelines 
   create graphs of real-time data flows based on the individual topics. 
   Starting in 0.10.0.0, a light-weight but powerful stream processing library 
   called Kafka Streams is available in Apache Kafka to perform such data 
   processing as described above. Apart from Kafka Streams, alternative open 
   source stream processing tools include Apache Storm and Apache Samza.
  </li>
  <li><def>Event Sourcing</def> style of application design where state 
    changes are logged as a time-ordered sequence of records.
    Kafka's support for very large stored log data makes it an excellent 
    backend for an application built in this style.
  </li>
  <li><def>Commit Log</def>: Used as kind of external commit-log for a
    distributed system. The log helps replicate data between nodes and acts as 
    a re-syncing mechanism for failed nodes to restore their data. The log 
    compaction feature in Kafka helps support this usage. In this usage Kafka 
    is similar to Apache BookKeeper project. </li>
  </ul>
</td>
<td>
  <a xsmall href="http://spark.apache.org/">Spark</a>
<pre xxxsmall zoom>
</pre>
  <a xxsmall href="https://www.youtube.com/watch?v=CfhYFqNyjGc">Zeppelin "Spark Notebook"<a>(video)
</td>
<td>Flink
<pre xxxsmall zoom>
<a href="https://www.confluent.io/blog/apache-flink-apache-kafka-streams-comparison-guideline-users/">kafka-streams vs flink</a>

<a href="https://stackoverflow.com/questions/30699119/what-is-are-the-main-differences-between-flink-and-storm#">REF: Flink vs Spark Storm</a>
 """Streaming Windows: Stream windowing and window aggregations are a crucial 
  building block for analyzing of data streams. Flink comes with a quite 
  powerful windowing system that supports many types of windows."""

 Check also: <a href="https://data-artisans.com/blog/serializable-acid-transactions-on-streaming-data">Streaming Ledger</a>. Stream ACID TXs on top of Flink
</pre>
</td>
<td colsep></td>
<td>
  <a href="https://nifi.apache.org">nifi</a>, Web-GUI data route+transform
<pre xxxsmall zoom>
scalable directed graphs of scalable directed graphs of data routing, transformation, and system mediation logic.
    Web-based user interface
        Seamless experience between design, control, feedback, and monitoring
    Highly configurable
        Loss tolerant vs guaranteed delivery
        Low latency vs high throughput
        Dynamic prioritization
        Flow can be modified at runtime
        Back pressure
    Data Provenance
        Track dataflow from beginning to end
    Designed for extension
        Build your own processors and more
        Enables rapid development and effective testing
    Secure
        SSL, SSH, HTTPS, encrypted content, etc...
        Multi-tenant authorization and internal authorization/policy management
</pre>
  <a xsmall href="https://blogs.apache.org/nifi/entry/stream_processing_nifi_and_spark">NiFi+Spark</a>
</td>
<td colsep></td>
<td>
  <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a><br/>
  distributed, RESTful (all-document-type) search and analytics engine
  <ul xxxsmall zoom>
  <li>Implemented on top of Lucene</li>
  <li>Elasticsearch is developed alongside a data-collection and log-parsing engine
     called Logstash, and an analytics and visualisation platform called Kibana.
     The three products are designed for use as an integrated solution, referred
     to as the "Elastic Stack" (formerly the "ELK stack").</li>
  <li>At the heart of the Elastic Stack,  data is stored centrally</li>
  <li>""discover the expected and uncover the unexpected""</li>
  </ul>
</td>
<td colsep></td>
<td>  
  <a href="https://www.elastic.co/products/kibana">Kibana</a><br/>
  <span cite>A Picture's Worth a Thousand Log Lines</span>
  <ul xxxsmall zoom>
  <li>""visualize (Elasticsearch) data and navigate the Elastic Stack,
  learning  understanding the impact rain might have on your 
  quarterly numbers""</li>
  </ul>
</td>

<td>
  <a href="https://grafana.com/">Grafana</a> time series analytics
  <ul xxxsmall zoom>
  <li>Integrates with Prometheus queries</li>
  <li TODO><a xsmall href="https://logz.io/blog/grafana-vs-kibana/">Grafana vs Kibana</a></li>
  </ul>
</td>
</tr>
</table>
<br/>
<hr/>
<br/>
<table>
<tr>
  <th colspan=3 header_delimit xsmall >distributed cache</th>
  <td colsep ></td>
  <th colspan=1 header_delimit xsmall >Local InMemory Cache</th>
</tr>
<tr>
<td>
  <a href="https://www.memcached.org/">Memcached</a><br/>
  distributed memory object caching system
.
  <ul xxxsmall>
  <li>Memcached servers are unaware of each other. There is no crosstalk, no 
     syncronization, no broadcasting, no replication. Adding servers increases 
     the available memory. Cache invalidation is simplified, as clients delete 
     or overwrite data on the server which owns it directly</li> 
  <li>initially intended to speed up dynamic web applications alleviating database load</li> 
  </ul> 
 
  <a href="https://github.com/magro/memcached-session-manager">
    Memcached-session-manager</a>
  tomcat HA/scalable/fault-tolerant session manager
  <ul xxxsmall>
  <li>supports sticky and non-sticky configurations</li>
  <li>Failover is supported via migration of sessions</li>
  </ul>
</td>
<td><a href="https://redis.io/">Redis</a>
  in-memory data structure store, used as a database, cache and message broker
  <ul xxxsmall zoom >
  <li>supports data structures such as strings, hashes, lists, sets, sorted sets
    with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries</li>
  <li>Redis has built-in replication, Lua scripting, LRU eviction, transactions
    and different levels of on-disk persistence, and provides high availability
    via Redis Sentinel and automatic partitioning with Redis Cluster</li>
  </ul>
  <hr/>
  <a href="https://en.wikipedia.org/wiki/Hazelcast">Hazelcast</a>, in-memory data grid based on Java
</td>
</td>
<td>
  <a href="http://www.ehcache.org/">Ehcache</a>
  <ul xxxsmall zoom >
  <li>Can be used as tcp service (distributed cache) or process-embedded<br/>
    <span TODO>Same API for local and distributed objects?</span></li>
  <li>open source, standards-based cache that boosts performance, offloads I/O</li>
  <li>Integrates with other popular libraries and frameworks</li>
  <li>It scales from in-process caching, all the way to mixed in-process/out-of-process
  deployments with terabyte-sized caches</li>
  </ul>
<pre xxxsmall zoom { >
Coding to Ehcache 3 API:
CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder()
    .withCache("preConfigured",
         CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class,
             ResourcePoolsBuilder.heap(100))
         .build())
    .build(true);

Cache&lt;Long, String&gt; preConfigured
    = cacheManager.getCache("preConfigured", Long.class, String.class);

Cache&lt;Long, String&gt; myCache = cacheManager.createCache("myCache",
    CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class,
                                  ResourcePoolsBuilder.heap(100)).build());

myCache.put(1L, "da one!");
String value = myCache.get(1L);

cacheManager.close();
</pre>
(simpler/lighter solution but not so escalable could be to use Google Guava Cache)
  <br/>
  <a href="http://jbosscache.jboss.org/">JBoss Cache</a>
</td>
<td colsep>
<td><a href="https://github.com/google/guava/wiki/CachesExplained">Guava Cache</a>
  <b>non-distributed</b> easy-to-use Java library for data caching
  <ul xxxsmall zoom >
  <li>A Cache is similar to ConcurrentMap, but not quite the same. The most 
    fundamental difference is that a ConcurrentMap persists all elements that 
    are added to it until they are explicitly removed. A Cache on the other 
    hand is generally configured to evict entries automatically, in order to 
    constrain its memory footprint. In some cases a LoadingCache can be useful
    even if it doesn't evict entries, due to its automatic cache loading.
  </li>
  </ul>
</td>
</tr>
</table>
<br/>
<hr/>
<br/>
<table>
<tr>
  <th colspan=4>Messaging</th>
  <th colsep></th>
  <th xsmall colspan=4>Distributed Storage. Related:<a href="http://www.time-travellers.org/shane/papers/NFS_considered_harmful.html">NFS considered harmful</a></th>
</tr>
<tr>
<td>
  Summary
  <ul xxxsmall zoom>
  <li>Messaging traditionally has two models: queuing and publish-subscribe. In a queue,
     a pool of consumers may read from a server and each record goes to one of them;
     in publish-subscribe the record is broadcast to all consumers. Each of these two
     models has a strength and a weakness. The strength of queuing is that it allows 
     you to divide up the processing of data over multiple consumer instances, which
     lets you scale your processing. Unfortunately, queues aren't multi-subscriber—once
     one process reads the data it's gone. Publish-subscribe allows you broadcast data
     to multiple processes, but has no way of scaling processing since every message
     goes to every subscriber
  </li>
  </ul>


</td>
<td>
  <b>Message Queues</b>
  Defined by
  <ul xxxsmall zoom>
  <li>message oriented architecture</li>
  <li>Persistence (or durability until comsuption)</li>
  <li>queuing</li>
  <li>Routing: point-to-point / publish-and-subscribe</li>
  <li>No processing/transformation of message/data</li>
  </ul>
  Implementations
  <ul xxxsmall zoom>
  <li>
    <a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol">AMQP</a>
    Open standard application layer protocol for message-oriented middleware. <br/>
    Often compared to JMS (Java Message Service): <br/>
    JMS defines the API interfaces, while AMQP defines the network protocol.<br/>
     JMS has no requirement for how messages are formed and transmitted and thus 
    every JMS broker can implement the messages in a different (incompatible) format<br/>
     AMQP publishes its specifications in a downloadable XML format. 
    This availability makes it easy for library maintainers to generate APIs 
    driven by the specs while also automating construction of algorithms to 
    marshal and demarshal messages.<br/>
     These advantages and the openness of the spec have inspired the creation of
     multiple brokers that support AMQP, including:<br/>
    RabbitMQ, ActiveMQ, Qpid, Solace<br/>
    <a href="https://www.amqp.org/about/examples">AMQP implementations</a>:
<pre>
<a href="http://qpid.apache.org/">Apache Qpid</a>
<a href="http://www.inetco.com/resource-library/technology-amqp/">INETCO's AMQP protocol analyzer</a>
<a href="http://joram.ow2.org/">JORAM</a>: open reliable asynchronous messaging, 100% pure Java implementation of JMS
<a href="http://kaazing.net/index.html">Kaazing's AMQP Web Client</a>
<a href="http://www.windowsazure.com/en-us/develop/net/how-to-guides/service-bus-amqp-overview/">Microsoft's Windows Azure Service Bus</a>
<a href="http://www.redhat.com/en/technologies/jboss-middleware/amq">JBoss&nbsp;A-MQ&nbsp;</a>, built from <a href="http://qpid.apache.org/">Qpid</a>
<a href="http://stormmq.com/">StormMQ</a> a cloud hosted messaging service based on AMQP
VMware Inc <a href="http://www.rabbitmq.com/">RabbitMQ</a>; also supported by SpringSource
<a href="https://developer.ibm.com/messaging/mq-light/">IBM MQlight</a>
...
</pre>
  </li>
  <li>Java JMS</li>
  <li>...</li>
  </ul>
</td>
<td>
  <b>Message Brokers</b>
  <ul xxxsmall zoom>
  <li>Routing</li>
  <li>(De-)Multiplexing of messages from/into multiple messages to different recipients</li>
  <li>Durability</li>
  <li>Transformation (translation of message between formats)</li>
  <li>"things usually get blurry - many solutions are both (message queue and message
    broker) - for example RabbitMQ or QDB.  Samples for message queues are 
    Gearman, IronMQ, JMS, SQS or MSMQ."<br/>
    Message broker examples are, Qpid, Open AMQ or ActiveMQ.</li>
  <li>Kafka can also be used as message broker but is not its main intention</li>
  </ul>
</td>
<td>
  <b>Enterprise Service Bus (ESB)</b>
  Can be defined by next feautes:
  <ul xxxsmall zoom>
  <li>Monitoring of services/messages passed between them</li>
  <li>wire Protocol bridge between HTTP, AMQP, SOAP, gRPC, CVS in Filesystem,...</li>
  <li>Scheduling, mapping, QoS management, error handling, ..</li>
  <li>Data transformation</li>
  <li>Data pipelines</li>
  <li>Mule, JBoss Fuse (Camel + "etc..."), BizTalk, Apache ServiceMix, ...</li>
  <li>
<pre>
REF: https://en.wikipedia.org/wiki/Enterprise_service_bus#/media/File:ESB_Component_Hive.png
    ^   Special App. Services
    |
E   |   Process Automation                 BPEL, Workflow
n   |
t   |   Application Adapters               RFC, BABI, IDoc, XML-RPC, ...
e m |
r e |   Application Data Consolidation     MDM, OSCo, ...
p s |
r s |   Application Data Mapping           EDI, B2B
i a |   _______________________________
s g |   Business Application Monitoring
e e |   _______________________________
    |   Traffic Monitoring Cockpit
S c |
e h |   Special Message Services           Ex. Test Tools
r a |
v n |   Web Services                       WSDL, REST, CGI
i n |
c e |   Protocol Conversion                XML, XSL, DCOM, CORBA
e l |
    |   Message Consolidation              N.N (data locks, multi-submit,...)
B   |
u   |   Message Routing                    XI, WBI, BIZTALK, Seeburger
s   |
    |   Message Service                    MQ Series, MSMQ, ...
</pre>

  </li>
  </ul>
</td>
<td colsep></td>
<td>
   <a href="http://zgp.org/linux-tists/20040101205016.E5998@shaitan.lightconsulting.com.html">Interesting mail</a> "complaining" about the different cluster-filesystem solutions: 
</td>
<td>
  <a href="http://ceph.com/ceph-storage/">Ceph</a>
<pre xxxsmall zoom>
Ceph’s RADOS provides you with extraordinary data storage  scalability—
thousands of client hosts or KVMs accessing petabytes to 
exabytes of data. Each one of your applications can use the object, block or 
file system interfaces to the same RADOS cluster simultaneously, which means 
your Ceph storage system serves as a  flexible foundation for all of your 
data storage needs. You can use Ceph for free, and deploy it on economical 
commodity hardware. Ceph is a  better way to store data.

By decoupling the namespace from the underlying hardware, object-based 
storage systems enable you to build much larger storage clusters. You 
can scale out object-based storage systems using economical commodity hardware
, and you can replace hardware easily when it malfunctions or fails.

Ceph’s CRUSH algorithm liberates storage clusters from the scalability and 
performance limitations imposed by centralized data table mapping. It 
replicates and re-balance data within the cluster dynamically—elminating this 
tedious task for administrators, while delivering high-performance and 
infinite scalability.

See more at: http://ceph.com/ceph-storage/#sthash.KNp2tGf5.dpuf
</pre>
</td>
<td TODO>
  GlusterFS
</td>
<td>
  <a href="http://tachyon-project.org/index.html">Tachyon</a>
<pre xxxsmall zoom>
memory-centric distributed file system enabling reliable file sharing at memory-speed
across cluster frameworks, such as Spark and MapReduce. It achieves high performance by leveraging
lineage information and using memory aggressively. Tachyon caches working set files in memory,
thereby avoiding going to disk to load datasets that are frequently read. This enables different
jobs/queries and frameworks to access cached files at memory speed.

Tachyon is Hadoop compatible. Existing Spark and MapReduce programs can run on top of it without
any code change. The project is open source (Apache License 2.0) and is deployed at multiple companies.
It has more than 40 contributors from over 15 institutions, including Yahoo, Intel, and Redhat.

The project is the storage layer of the Berkeley Data Analytics Stack (BDAS) and also part of the
Fedora distribution.
</pre>
</td>
<td>
  <a href="http://xmodulo.com/2014/09/create-cloud-based-encrypted-file-system-linux.html">S3QL</a>
<pre xxxsmall zoom>
S3QL is one of the most popular open-source cloud-based file systems.  It is a FUSE-based file
system backed by several commercial or open-source cloud storages, such as Amazon S2, 
Google Cloud Storage, Rackspace CloudFiles, or OpenStack.  As a full featured file system, S3QL boasts 
of a number of powerful capabilities, such as unlimited capacity, up to 2TB file sizes, 
compression, UNIX attributes, encryption, snapshots with copy-on-write, immutable trees,
de-duplication, hardlink/symlink support, etc.  Any bytes written to an S3QL file system are 
compressed/encrypted locally before being transmitted to cloud backend. 
When you attempt to read contents stored in an S3QL file system, the 
corresponding objects are downloaded from cloud (if not in the local 
cache), and decrypted/uncompressed on the fly.
</pre>
</td>


</tr>
</table>

<br/>
<hr/>
<br/>

<table>
<tr>
<th colspan=10 header_delimit xsmall >Example Architectures</th>
</tr>
<tr>
<td>
observability: login + monitoring + tracing

  Ex: (REF: <a href="https://www.rsaconference.com/writable/presentations/file_upload/csv-r14-fim-and-system-call-auditing-at-scale-in-a-large-container-deployment.pdf">File Integrity Monitoring at scale: (RSA Conf)</a>)<br/>
  Auditing log to gain insights at scale:
<pre xxxsmall zoom>
                         +→ Pagerduty
            +-→ Grafana -+→ Email
   Elastic  |            +→ Slack
   Search  -+-→ Kibana
            |
            +-→ Pre-processing  -> TensorFlow

Alt1:
  User   │ go-audit-                          User space
  land   │ container                             app
  ───────├─────  Netlink ───── Syscall iface ───────────
  Kernel │        socket           ^
         │          ^              |
                    └─  Kauditd ───┘
</pre>
</td>
</tr>
</table>


<table>
<tr>
  <th header_delimit colspan=10  xsmall >Continuous Integration</td>
</tr>
<tr>
<td>[CI]<a href="https://jenkins.io/doc/">Jenkins</a>
   <ul xxxsmall zoom>
   <li><a href="https://jenkins.io/solutions/pipeline/">Pipeline as Code</a></li>
   </ul>
</td>
<td>
  [CI]<a href="https://github.com/spinnaker/kayenta">Kayenta</a> Canary Testing
  <ul>
  <li>Kayenta is a platform for Automated Canary Analysis (ACA) </li>
  </ul>
</td>

</tr>
</table>

<br/>
</body>
</html>

<!--
TODO_start:
_________________________
DevOps Architecture:
  https://logz.io/blog/devops/
  Full list of CI tools
  https://xebialabs.com/technology/nevercode/
_________________________
CI/CD Tools:
  CI/CD - Jenkins, Maven, Nolio, Sonar, Jdepend, Selenium/fortify, TDD/BDD usage, Cucumber
  https://www.mediawiki.org/wiki/Continuous_integration

  https://www.mediawiki.org/wiki/Continuous_integration/Entry_points

  https://zuul-ci.org/

  https://www.mediawiki.org/wiki/Continuous_integration/Zuul
  """Zuul is a python daemon which acts as a gateway between Gerrit and Jenkins. It listens to Gerrit stream-events feed and trigger jobs function registered by Jenkins using the Jenkins Gearman plugin. The jobs triggering specification is written in YAML and hosted in the git repository integration/config.git as /zuul/layout.yaml . """


  CircleCI
__________________________
https://opensource.com/article/18/9/open-source-log-aggregation-tools?utm_medium=Email&utm_campaign=weekly&sc_cid=701f2000000RRBZAA4
____________________________

REF: https://www.infoq.com/news/2018/09/logdevice-distributed-logstorage
Facebook Open Sources LogDevice - a Distributed Data Store for Log Storage

LogDevice has been compared with other log storage systems like Apache BookKeeper and Apache Kafka. The primary difference with Kafka <a href="https://news.ycombinator.com/item?id=17975328">seems to be the decoupling of computation and storage</a> that LogDevice does to be able to handle Facebook's scale. LogDevice is written in C++ and hosted on GitHub. 
The underlying storage is based on RocksDB, a key value store also open sourced by Facebook


_____________________
http://lucene.apache.org/solr/
Solr is the popular, blazing-fast, open source enterprise search platform built on Apache Lucene

________________
https://www.infoq.com/news/2018/10/Redis-5-Released
___________________________
http://camel.apache.org/manual/camel-manual-2.22.2.html#chapter-cook-book:
"""For example if you want to implement some kind of message passing, remoting, reliable load balancing or asynchronous processing in your application we recommend you use Camel annotations to bind your services and business logic to Camel Components which means you can then easily switch between things like

 *  in JVM messaging with SEDA
 *  using JMS via ActiveMQ or other JMS providers for reliable load balancing, grid or publish and subscribe
 *  for low volume, but easier administration since you're probably already using a database you could use
        Hibernate or JPA to use an entity bean / table as a queue
        iBatis to work with SQL
        JDBC for raw SQL access
 *  use JavaSpace
"""
___________________________
Business Activity Monitoring

The Camel BAM module provides a Business Activity Monitoring (BAM) framework for testing business processes across multiple message exchanges on different Endpoint instances.

Consider, for example, a simple system in which you submit Purchase Orders into system A and then receive Invoices from system B. You might want to test that, for a given Purchase Order, you receive a matching Invoice from system B within a specific time period.

______________________
Extract-Transform-Load Example
http://camel.apache.org/etl-example.html
_____________________
Mock Component

Testing Summary Include

The Mock component provides a powerful declarative testing mechanism, which is similar to jMock in that it allows declarative expectations to be created on any Mock endpoint before a test begins. Then the test is run, which typically fires messages to one or more endpoints, and finally the expectations can be asserted in a test case to ensure the system worked as expected.

This allows you to test various things like:

    The correct number of messages are received on each endpoint,
    The correct payloads are received, in the right order,
    Messages arrive on an endpoint in order, using some Expression to create an order testing function,
    Messages arrive match some kind of Predicate such as that specific headers have certain values, or that parts of the messages match some predicate, such as by evaluating an XPath or XQuery Expression.
_____________________
 What you need for microservices:
- Visibility and reporting
Resilence and fault tolerance
- Routing and traffic control
- Identity and secuiryt
- Policy enforcement.
_____________________
https://github.com/dexidp/dex

Dex is an identity service that uses OpenID Connect to drive authentication for other apps.

Dex acts as a portal to other identity providers through "connectors." This lets dex defer authentication to LDAP servers, SAML providers, or established identity providers like GitHub, Google, and Active Directory. Clients write their authentication logic once to talk to dex, then dex handles the protocols for a given backend.

______________________
https://prometheus.io/
________________
https://evolveum.com/midpoint/
  Why is midPoint the Best Identity Management and Identity Governance platform?
_____________________
More technologies
Nexus:
 - Component repository DDBB for Maven/Gradle, npm, NuGet, RubyGems, Docker, PyPI.
-->

