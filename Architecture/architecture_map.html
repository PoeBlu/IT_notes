<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>architecture map (alpha) <!-- ignore --></title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>

<body>

<table>
<tr>
<td>
<pre zoom>
<span xsmall>DB Engines Types</span>
<span xsmall>(key/value, RDBMS, TimeSeries,...)</span>
REF:
- <a href="https://db-engines.com/">db-engines.com</a>
- <a href="https://db-engines.com/en/ranking">ussage Ranking</a>
- <a href="https://dzone.com/articles/rant-there-is-no-nosql-data-storage-engine">REF: "There is no NoSQL data storage</a>
*RDBMS*                                         | *KEY-VALUE STORES*                             | *Time Series DBMS*
*Features*                                      | -*simplest*form of DBMS.                       | - Managing time series data
- support E-R data model.                       | - store pairs of keys and values               | - very high TX load:
- table schema defined by the                   | -*high performance*                            |   - designed to efficiently collect,
  table name and fixed number                   | - not adequate for complex apps                |     store and query various time
  of attributes and data types.                 | - extended forms allows to sort the            |     series.
- A record (=entity) corresponds                |   keys, enabling range queries as well         | - Ex use-case:
  to a row in the table.                        |   as an ordered processing of keys.            |   SELECT SENSOR1_CPU_FREQUENCY / SENSOR2_HEAT'
- basic operations are defined on               | - Can evolve to document stores and            |   joins two time series based on the
  the tables/relations:                         |   wide column stores.                          |   overlapping areas of time providing
  - CRUD: Create/Read/Update/Delete             |                                                |   new time-serie
  - set ops: union|intersect|difference         | *Examples*                                     |
  - subset selection defined by filters         | - Redis                                        | *Examples*
  - Projection of subset of table columns       | - Amazon DynamoDB                              | - Timescale.com
  - JOIN: combination of:                       | - Memcached                                    |   - PostgreSQL optimized for Time Series.
    Cartesian_product+selection+projection      | - Microsoft Azure Cosmos DB                    |     by modifying the insert path,
  - TX ACID control                             | - Hazelcast                                    |     execution engine, and query planner
  - user management                             | - LabelDB ("Ethereum State")                   |     to "intelligently" process queries
- Ops defined in  standard SQL                  | - TiKV                                         |     across chunks.
*History*                                       |   - dev lang:*Rust*                            | - InfluxDB
- beginning of 1980s                            |   - Incubation Kubernetes project              | - Kdb+
- Most widely used DBMS                         |   - used also for TiDB                         | - Graphite. Simple system that will just:
                                                                                                 |   - Store numeric time series data
*Main  Examples*                                                                                 |   - Render graphs of this data
- Oracle                                                                                         |   It will*NOT*:
- MySQL                                                                                          |   - collect data (Carbon needed)
- TiDB                                                                                           |   - render graphs (external apps exists)
  - MySQL compatible                                                                             | - RRDtool
  - RAFT-distributed                            | *Search Engines*                               | - Prometheus
  - Rust/go written                             | - "NoSQL" DBMS for search of content           |   - https://prometheus.io/
  - Features:                                   | - Optimized for:                               |   - CNCF project,*kubernetes friendly*
    - "infinite" horizontal scalability         |   - complex search expressions                 |   - GoLang based:
    - strong consistency                        |   - Full text search                           |     - binaries statically linked
    - HA                                        |   - reducing words to stem                     |     - easy to deploy.
- SQL Server                                    |   - Ranking and grouping of results            |   - Many client libraries.
- PostgreSQL                                    |   - Geospatial search                          |   - monitoring metrics analyzer
- DB2                                           |   - Distributed search for high                |     and alerting
- Hive (https://db-engines.com/en/system/Hive)  |     scalability                                |   - Highly dimensional data model.
  - Home: https://hive.apache.org/              | *Examples*                                     |     Time series are identified by a
  - r*WARN*: No Foreign keys, NO ACID           | - Elasticsearch                                |     metric name and a set of
  -*Eventual Consistency*                       | - Splunk                                       |     key-value pairs.
  - Data Warehouse designed for Hadoop          | - Solr                                         |   - stores all data as time series:
  - Implemented in Java                         | - MarkLogic                                    |     streams of timestamped values
  - supports analysis of large datasets         | - Sphinx                                       |     belonging to same metric and
    stored in Hadoop's HDFS and                 | - Eclipse Hawk:                                |     same set of labeled dimensions.
    compatible file systems such as             |   projects.eclipse.org/projects/modeling.hawk  |   - Multi-mode data visualization.
    Amazon S2 filesystem.                       |   heterogeneous model indexing framework:      |   - Grafana integration
  - SQL-like DML and DDL statements             |   - indexes collections of models              |   - Built-in expression browser.
    Traditional SQL queries implemented in      |     transparently and incrementally into       |   - PromQL Query language allowing
    MapReduce Java API to  execute SQL apps:    |     NoSQL DDBB, which can be queried           |     to select+aggregate time-series
    - necessary SQL abstraction provided to     |     efficiently.                               |     data in real time.
      integrate SQL-like queries (HiveQL) into  |   - can mirror EMF, UML or Modelio             |     - result can either be shown as
      the underlying Java without the need      |     models (among others) into a Neo4j or      |       graph, tabular data or consumed
      for low-level queries.                    |     OrientDB graph, that can be queried        |       by external HTTP API.
  - Hive aids portability of SQL-based apps     |     with native languages, or Hawk ones.       |   - Precise alerts based on PromQL.
    to Hadoop                                   |     Hawk will watch models and update          |   - scaling:
  - JDBC, ODBC, Thrift                          |     the graph incrementally on change.         |     - sharding
                                                                                                 |     - federation
                                                                                                 |   - "Singleton" servers relying only
                                                                                                 |     on local storage.
                                                                                                 |     (optionally remote storage).
                                                                                                 |
   | *RDF stores*                               | *Graph DBMS*                                   | - Uber M3
   | db-engines.com/en/article/RDF+Stores       | - represent data in graph structures           |   www.infoq.com/news/2018/08/uber-metrics-m3
   | - Resource Description Framework stores    |   of nodes and edges (relations).              |   - Large Scale Metrics Platform
   |   *describes information in triplets:*     | - easy processing, simple calculation          | """ built to replace Graphite+Carbon cluster,
   |  *(subject,predicate,object)*              |   of specific graph properties:                |     and Nagios for alerting and Grafana for
   | - Originally used for describing           |   - number of steps needed to                  |     dashboarding due to issues like
   |   IT-resources-metadata.                   |     get from one node to another node          |     poor resiliency/clustering, operational
   | - Today often used in semantic web.        | - (usually) DON'T provide indexes on           |     cost to expand the Carbon cluster,
   | - RDS is a subclass of graph DBMS:         |   all nodes. Direct access to                  |     and a lack of replication""".
   |   (subject,predicate,object)               |   nodes based on attribute values              |   *Features*
   |    ^          ^      ^                     |   is not possible                              |   - cluster management, aggregation,
   |    node      edge   node                   | *Examples*                                     |     collection, storage management,
   |   but it offer specific methods            | - Neo4j                                        |     a distributed TSDB
   |   beyond general graph DBMS ones. Ex:      | - Azure Cosmos DB                              |   - M3QL query language (with features
   |   SPARQL, SQL-like query lang. for         | - Datastax Enterprise                          |     not available in PromQL).
   |   RDF data, supported by most              | - OrientDB                                     |   - tagging of metrics.
   |   RDF stores.                              | - ArangoDB                                     |   - local/remote integration similar to
   |                                                                                             |     the Prometheus Thanos extension providing
   | *Examples*                                                                                  |     cross-cluster federation, unlimited
   | - MarkLogic                                                                                 |     storage and global querying across
   | - Jena                                                                                      |     clusters, works.
   | - Virtuoso                                                                                  |   - query engine: single global view
   | - Amazon Neptune                                                                            |     without cross region replication.
   | - GraphDB





|*Document Stores*                                   | *Wide Column Stores*                         |*Service Registration*
|- also called document-oriented DBMS                | (also called extensible record stores)       | *and Discovery*
|- schema-free:                                      | - store data in records                      |
|  - different records may have                      | - ability to hold very large numbers         | - Specialized key/value DBMS:
|    different columns                               |   of dynamic columns.                        |   -*two processes must exists*:
|  - values of individual columns                    |   - column names and record keys             |     -*Service registration process*
|    can have dif. types                             |    *are not fixed*                           |       storing final-app-service
|- Columns can be multi-value                        |     ^^^^^^^^^^^^^                            |       (host,port,...)
|- Records can have a nested structure               |     (schema-free)                            |     -*Service discovery process*
|- Often use internal notations,                     | - a record can have billions of              |       - let final-app-services query
|  mostly JSON.                                      |   columns.                                   |         the data
|- features:                                         | -*short of two-dimensional*                  |   - other aspects to consider:
|  - secondary indexes in (JSON) objects             |  *key-value stores.       *                  |     - auto-delete of non-available services
|                                                    | - not to be confused with                    |     - Support for replicated services
|*Examples*                                          |   column oriented storage of RDMS            |     - Remote API is provided
|- MongoDB                                           |   (last one is an internal concept           |
|  www.infoq.com/articles/Starting-With-MongoDB      |   for improving performance storing          | *Examples*
|  14 Things I Wish I’d Known When Starting with     |   table-data column-by-column vs             | - ZooKeeper
|  MongoDB                                           |   record-by-record)                          |   - originated from Hadoop ecosystem.
|- Amazon DynamoDB                                   | *Examples*                                   |   - data-format similar to file system.
|- Couchbase                                         | - Cassandra                                  |   - cluster mode.
|- Cosmos DB                                         |   - SQL-like SELECT, DML and DDL             |   - Disadvantages:
|- CouchDB                                           |     statements (CQL)                         |     - complex:
                                                     |   - Designed to handle large amounts         |     - Java plus big number of dependencies
                                                     |     of data across many commodity            |   - Still used by kafka for config but
                                                     |     servers, providing high availability     |     plans exists to replace it.
                                                     |     with no single point of failure.         |     issues.apache.org/jira/browse/KAFKA-6598
                                                     |   - robust support for clusters              | - etcd
                                                     |     spanning multiple datacenters,           |   - distributed key/value store
                                                     |     with asynchronous masterless             |   - HTTP remote API.
                                                     |     replication allowing low latency         |   - hierarchical config.
                                                     |     operations for all clients.              |   - Very easy to deploy, setup and use
                                                     |   - Related:                                 |   - reliable data persistence
                                                     |     www.infoq.com/news/2018/10/spotify-cstar |   - very good doc
                                                     |     Spotify Open Sources cstar,              |   - coreos.com/blog/introducing-zetcd
                                                     |     its Cassandra Orchestration Tool:        |   Disadvantages:
                                                     |     ... Cstar emerged from the necessity     |   - needs to be combined with few
                                                     |     of running shell commands in Cassandra   |     third-party tools for  serv.discover:
                                                     |     nodes                                    |     - etcd-registrator: keep updated  list
                                                     |   -*Integrated Managed Data    *             |                       of docker containers
                                                     |    *Layer Solutions with Spark,*             |     - etcd-registrator-confd: keep updated
                                                     |    *Kafka and Elasticsearch.   *             |                               config files
                                                     |                                              |     - ...
                                                     | - Scylla                                     |   - Used by Kubernetes for config
                                                     |   - compatible with Cassandra                |
                                                     |     (same CQL and Thrift protocols,          | - Consul
                                                     |      and same SSTable file formats)          |   - strongly consistent datastore
                                                     |     with  higher throughputs and             |   - multidatacenter gossip protocol
                                                     |     lower latencies (10x).                   |     for dynamic clusters
                                                     |   - C++14 (vs Cassandra Java)                |   - hierarchical key/value store
                                                     |   -*Seastar async lib replacing threads*     |   - adds the notion of app-service
                                                     |   - sharded design by node:                  |     (and app-service-data).
                                                     |     - each CPU core handles a data-subset    |     - "watches" can be used for:
                                                     |     - authors claim to achieve much better   |       - sending notifications of
                                                     |       performance on modern NUMA SMP archs,  |         data changes
                                                     |       and to scale very well with the number |       - (HTTP, TTLs , custom)
                                                     |       of cores:                              |         health checks and
                                                     |       -*Up to 2 million req/sec per machine* |         output-dependent
                                                     | - HBase                                      |         commands
                                                     | _ CosmosDB                                   |
                                                     | REF: Google bigTable-osdi06.pdf              |   - embedded service discovery:
                                                                                                    |     no need to use third-party one
                                                                                                    |     (like etcd). Discovery includes:
                                                                                                    |     - node         health checks
                                                                                                    |     - app-services health checks
                                                                                                    |     - ...
                                                                                                    |   - Consul provides a built in framework
                                                                                                    |     for service discovery.
                                                                                                    |     (vs etcd basic key/value + custom code)
                                                                                                    |     - Clients just register services and
                                                                                                    |       perform discovery using the DNS
                                                                                                    |       or HTTP interface.
                                                                                                    |   - out of the box native support for
                                                                                                    |     multiple datacenters.
                                                                                                    |   - template-support for config files.
                                                                                                    |   - Web UI: display all services and nodes,
                                                                                                    |     monitor health checks, switch
                                                                                                    |     from one datacenter to another.
                                                                                                    | - doozerd (TODO)
                                                                                                    | See also:
                                                                                                    | - Comparision chart:
                                                                                                    | coreos.com/etcd/docs/latest/learning/why.html










*Related*
- https://www.infoq.com/news/2018/09/pinterest-goku-timeseries-db
  Pinterest Switches from OpenTSDB to Their Own Time Series Database
- https://facebook.github.io/prophet/
  Prophet: TSDB forecasting library (wrapper around Stan), particularly
  approachable place to use Bayesian Inference for forecasting use cases
  general purpose.
  - Prophet is a procedure for forecasting time series data based on an
    additive model where non-linear trends are fit with yearly, weekly, and daily
    seasonality, plus holiday effects. It works best with time series that have
    strong seasonal effects and several seasons of historical data. Prophet is
    robust to missing data and shifts in the trend, and typically handles outliers well.




https:// technologyconversations.com/2015/09/08/service-discovery-zookeeper-vs-etcd-vs-consul/
https://www.infoq.com/news/2019/05/hashicorp-consul-1.5.0
</pre>
<td>
<pre zoom>
<span xsmall>Data(log)</span>
<span xsmall>collect</span>
*FluentD*                                     |*Logstash* 
 "Improved" logstat                           |- The*L* in ELK
 - https://www.fluentd.org/                   |-*OS data Collector
 - data collector for unified logging layer   |- TODO:
 - increasingly used Docker, GCP,             |  osquery.readthedocs.io/en/stable/
   and Elasticsearch communities              |- low-level instrumentation framework 
 - https://logz.io/blog/fluentd-logstash      |  with system analytics and monitoring
   FluentD vs Logstash compared               |  both performant and intuitive.
*Features*                                    |- osquery exposes an operating system
 - unify data collection and consumption      |  as a high-performance SQL RDMS:
   for better understanding of data.          |  - SQL tables represent concepts such
                                              |    as running processes, loaded kernel
                                              |    modules, open network connections,
Syslog                      Elasticsearch     |    browser plugins, hardware events
Apache/Nginx logs    → → →  MongoDB           |*Features:*
Mobile/Web app logs  → → →  Hadoop            |  - File Integrity Monitoring (FIM):
Sensors/IoT                 AWS, GCP, ...     |  - DNS
                                              |  - *1

*1: https://medium.com/palantir/osquery-across-the-enterprise-3c3c9d13ec55



|*Prometheus Node Exporter*                     |*Others*
|- https://github.com/prometheus/node_exporter  |- collectd
|- TODO:                                        |- Dynatrace OneAgent
                                                |- Datadog agent
                                                |- New Relic agent
                                                |- Ganglia gmond
                                                |- ...
</pre>
<pre zoom TODO>
<span xsmall>Logreduce</span>
<span xsmall> IA filter</span>
<a xsmall TODO href="https://opensource.com/article/18/9/quiet-log-noise-python-and-machine-learning">Logreduce IA filter</a>
  - <a href=https://pypi.org/project/logreduce/">logreduce@pypi</a>
  - Quiet log noise with Python and machine learning
</pre>
</td>
<td>
<pre zoom>
<span xsmall TODO>Streams</span>
Distributed (<a href="https://martinfowler.com/eaaDev/EventSourcing.html">Event</a>) Stream Processors
REF:
- <a href="https://en.wikipedia.org/wiki/Stream_processing">Stream_processing@Wikipedia</a>
- <a href="https://iwringer.wordpress.com/2015/08/03/patterns-for-streaming-realtime-analytics/">Patterns for streaming realtime anaylitics</a>
- <a href="https://www.infoq.com/streaming?utm_source=infoqEmail&utm_medium=editorial&utm_campaign=SpecialNL&utm_content=05182018">???</a>
- <a href="https://www.infoq.com/presentations/squbs?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming Reactive Systems & Data Pites w. Squbs</a>
- <a href="https://www.infoq.com/presentations/sql-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming SQL Foundations: Why I Love Streams+Tables </a>
- <a href="https://www.infoq.com/presentations/flink-stateful-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Next Steps in Stateful Streaming with Apache Flink</a>
- <a href="https://www.infoq.com/presentations/kafka-streams-spring-cloud?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Kafka Streams - from the Ground Up to the Cloud </a>
- <a href="https://www.infoq.com/presentations/facebook-stream-processing?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Data Decisions with Real-Time Stream Processing</a>
- <a href="https://www.infoq.com/presentations/beam-model-stream-table=theory?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Foundations of streamng SQL</a>
- <a href="https://www.infoq.com/presentations/distributed-stream-processing-flink?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">The Power of Distributed Snapshots in Apache Flink</a>
- <a href="https://www.infoq.com/presentations/sql-streams-panel?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Panel: SQL over Streams, Ask the Experts</a>
- <a href="https://www.infoq.com/presentations/hbc-digital-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Survival of the Fittest - Streaming Architectures</a>
- <a href="https://www.infoq.com/presentations/netflix-personalization-datasets-streaming?utm_source=presentations_about_Streaming&utm_medium=link&utm_campaign=Streaming">Streaming for Personalization Datasets at Netflix</a>
- < href="https://www.safaribooksonline.com/library/view/an-introduction-to/9781491934951/">An Introduction to Time Series with Team Apache </a>
""" Apache Cassandra evangelist Patrick McFadin shows how to solve time-series data
    problems with technologies from Team Apache: Kafka, Spark and Cassandra.
      - Kafka: handle real-time data feeds with this "message broker"
      - Spark: parallel processing framework that can quickly and efficiently
               analyze massive amounts of data
      - Spark Streaming: perform effective stream analysis by ingesting data 
               in micro-batches
      - Cassandra: distributed database where scaling and uptime are critical
      - Cassandra Query Language (CQL): navigate create/update your data and data-models
      - Spark+Cassandra: perform expressive analytics over large volumes of data

|*Kafka*@[./kafka_map.html]                             | *Spark* (TODO)
|-@[https://kafka.apache.org]                           | @[http://spark.apache.org/]
|- scalable,persistent and fault-tolerant               | - Zeppelin "Spark Notebook"(video):
|  real-time log/event processing cluster.              | @[https://www.youtube.com/watch?v=CfhYFqNyjGc]
|- It's NOT a real stream processor  but a              | 
|  broker/message-bus to store stream data              | 
|  for comsuption.                                      | 
|- "Kafka stream" can be use to add                     | 
|  data-stream-processor capabilities                   | 
|- Main use cases:                                      | 
|  - real-time reliable streaming data                  | *Flink* TODO
|    pipelines between applications                     | - Includes a powerful windowing system
|  - real-time streaming applications                   |   supports many types of windows:
|    that transform or react to the                     |   - Stream windows and win.aggregations are crucial
|    streams of data                                    |     building block for analyzing data streams.
|- Each node-broker in the cluster has an               |
|  identity which can be used to find other             |
|  brokers in the cluster. The brokers also             |
|  need some type of a database to store                |
|  partition logs.                                      |
|-@[http://kafka.apache.org/uses]                       |
|  (Popular) Use cases                                  |
|  b*Messaging*: good replacement for traditional       |
|    message brokers decoupling processing from         |
|    data producers, buffering unprocessed messages,    |
|    ...) with better throughput, built-in              |
|    partitioning, replication, and fault-tolerance     |
|  b*Website Activity Tracking*(original use case)      |
|    Page views, searches, ... are published            |
|    to central topics with one topic per activity      |
|    type.                                              |
|  b*Metrics* operational monitoring data.              |
|  b*Log Aggregation* replacement.                      |
|    - Group logs from different servers in a central   |
|      place.                                           |
|    - Kafka abstracts away the details of files and    |
|      gives a cleaner abstraction of logs/events as    |
|      a stream of messages allowing for lower-latency  |
|      processing and easier support for multiple data  |
|      sources and distributed data consumption.        |
|      When compared to log-centric systems like        |
|      Scribe or Flume, Kafka offers equally good       |
|      performance, stronger durability guarantees due  |
|      to replication, and much lower end-to-end        |
|      latency.                                         |
|  b*Stream Processing*: processing pipelines           |
|    consisting of multiple stages, where raw input     |
|    data is consumed from Kafka topics and then        |
|    aggregated/enriched/transformed into new           |
|    topics for further consumption.                    |
|    - Kafka 0.10.+ includes Kafka-Streams to           |
|      easify this pipeline process.                    |
|    - alternative open source stream processing        |
|      tools include Apache Storm and Samza.            |
|  b*Event Sourcing architecture*: state changes        |
|    are logged as a time-ordered sequence of           |
|    records.                                           |
|  b*External Commit Log for distributed systems*:      |
|    - The log helps replicate data between             |
|      nodes and acts as a re-syncing mechanism         |
|      for failed nodes to restore their data.          |

See also:
-Flink vs Spark Storm:
@[https://www.confluent.io/blog/apache-flink-apache-kafka-streams-comparison-guideline-users/]
Check also: <a href="https://data-artisans.com/blog/serializable-acid-transactions-on-streaming-data">Streaming Ledger</a>. Stream ACID TXs on top of Flink
</pre>
</td>
<td>
<pre zoom>
<span TODO xsmall>Text indexing</span>
<span TODO xsmall>Search</span>
*Elasticsearch*
@[https://www.elastic.co/products/elasticsearch]
- distributed, RESTful (all-document-type) search 
  and analytics engine
- Implemented on top of Lucene
- Developed alongside a data-collection and
  log-parsing engine called Logstash, and the 
  analytics and visualisation platform  Kibana.
  - The three products form the "Elastic Stack" 
    (formerly the "ELK stack"
  - At the heart of the ELK Stack, data is 
    stored centrally
</pre>
</td>
<td>
<pre zoom>
<span xsmall>Data Routing</span>
*Apache NiFi*
@[https://nifi.apache.org]
- Web-GUI data route+transform
- scalable directed graphs of data routing,
  transformation, and system mediation logic.
- Seamless experience between design, control,
  feedback, and monitoring
- Highly configurable:
  - Loss tolerant vs guaranteed delivery
  - Low latency vs high throughput
  - Dynamic prioritization
  - Flow can be modified at runtime
  - Back pressure
- Data Provenance
  - Track dataflow from beginning to end
- Designed for extension
  - Build your own processors and more
  - Enables rapid development and 
    effective testing
- Secure
  - SSL, SSH, HTTPS, encrypted content, etc...
  - Multi-tenant authorization and internal
    authorization/policy management
REFS:
- NiFi+Spark:
@[https://blogs.apache.org/nifi/entry/stream_processing_nifi_and_spark"]
</pre>
</td>
<td>
<pre zoom>
<span xsmall>Data</span>
<span xsmall>visualization</span>
|*Kibana* (TODO)
|@[https://www.elastic.co/products/kibana]
|- "A Picture's Worth a Thousand Log Lines"
|- visualize (Elasticsearch) data and navigate
|  the Elastic Stack, learning  understanding 
|  the impact rain might have on your quarterly
|  numbers

*Grafana* (TODO)
@[https://grafana.com/]
- time series analytics
- Integrates with Prometheus queries
@[https://logz.io/blog/grafana-vs-kibana/]
</pre>
</td>
</tr>
</table>
<br/>
<hr/>

<table>
<tr>

</tr>
</table>
<br/>
<hr/>
<br/>
<table>
<tr>
<td title>
    Distributed<br/>
    cache
</td>
<td>
<pre zoom>
<span xsmall>Memcached</span>
@[https://www.memcached.org/
- distributed memory object caching system
- Memcached servers are unaware of each other. There is no crosstalk, no
  syncronization, no broadcasting, no replication. Adding servers increases
  the available memory. Cache invalidation is simplified, as clients delete
  or overwrite data on the server which owns it directly
- initially intended to speed up dynamic web applications alleviating database load

*Memcached-session-manager*
@[https://github.com/magro/memcached-session-manager]
  tomcat HA/scalable/fault-tolerant session manager
- supports sticky and non-sticky configurations
- Failover is supported via migration of sessions
@[https://www.infoworld.com/article/3063161/why-redis-beats-memcached-for-caching.html]
</pre>
</td>
<td>
<pre zoom>
<a xsmall href="https://redis.io/">Redis</a>
- in-memory data structure store, used as a key-value database and cache 
- Since it can also notify listener of changes in its state it can
  also be used as message broker (this is the case for example 
  in Kubernetes, where etcd implement an asynchronous message system
  amongst its componentes).
- supports data structures such as strings, hashes, lists, sets, sorted sets
  with range queries, bitmaps, hyperloglogs and geospatial indexes with
  radius queries
- Redis has built-in replication, Lua scripting, LRU eviction, transactions
  and different levels of on-disk persistence, and provides high availability
  via Redis Sentinel and automatic partitioning with Redis Cluster
@[https://www.infoworld.com/article/3063161/why-redis-beats-memcached-for-caching.html]
@[https://www.infoq.com/news/2018/10/Redis-5-Released]
</pre>
<pre zoom>
<span xsmall>Hazelcast</span>
<span xsmall>in-memory</span>
<span xsmall>data grid</span>
@[https://en.wikipedia.org/wiki/Hazelcast]
-  based on Java
</pre>
</td>
</td>
<td>
<pre zoom>
<span xsmall>Ehcache</span>
<span xsmall>(terabyte)</span>
<span xsmall>cache</span>
@[http://www.ehcache.org/]
- Can be used as tcp service (distributed cache) or process-embedded
  TODO:  Same API for local and distributed objects?
- open source, standards-based cache that boosts performance, offloads I/O
- Integrates with other popular libraries and frameworks
- It scales from in-process caching, all the way to mixed 
  in-process/out-of-process deployments with*terabyte-sized caches*

*Example Ehcache 3 API*:
CacheManager cacheManager = 
  CacheManagerBuilder.newCacheManagerBuilder()
  .withCache("preConfigured",
    CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class,
      ResourcePoolsBuilder.heap(100))
  .build())
  .build(true);

Cache˂Long, String˃ preConfigured =
    = cacheManager.getCache("preConfigured", Long.class, String.class);

Cache˂Long, String˃ myCache = cacheManager.createCache("myCache",
    CacheConfigurationBuilder.newCacheConfigurationBuilder(Long.class, String.class,
                                  ResourcePoolsBuilder.heap(100)).build());

myCache.put(1L, "da one!");
String value = myCache.get(1L);

cacheManager.close();

(simpler/lighter solution but not so escalable could be to use Google Guava Cache)
</pre>

<pre zoom>
<span TODO xsmall>JBoss Cache</span>
@[http://jbosscache.jboss.org/]
</pre>
</td>
<td title>
    Local<br/>
    In-Memory<br/>
    Cache
<td>
<pre zoom>
<span xsmall>Guava Cache</span>
@[https://github.com/google/guava/wiki/CachesExplained]
- *non-distributed* easy-to-use Java library for data caching

- A Cache is similar to ConcurrentMap, but not quite the same. The most
  fundamental difference is that a ConcurrentMap persists all elements that
  are added to it until they are explicitly removed. A Cache on the other
  hand is generally configured to evict entries automatically, in order to
  constrain its memory footprint. In some cases a LoadingCache can be useful
  even if it doesn't evict entries, due to its automatic cache loading.
</pre>
</td>
</tr>
</table>
<br/>
<hr/>
<br/>
<table>
<td title>
    Messaging
</td>
<td>
<pre zoom>
<span xsmall>Summary</span>
Messaging traditionally has two models:
*queuing*
  - a pool of consumers may read from a server and 
    each record goes to one of them;
  - Pros: allows to divide up the processing of data
        over multiple consumer instances, which
        lets you scale your processing.
  - Cons: queues aren't multi-subscriber—once
        one process reads the data it's gone.

*publish-subscribe*
  - the record is broadcast to all consumers. 
  - Pros: let broadcast data to multiple processes,
  - Cons: no way of scaling processing since every message
          goes to every subscriber


*Message Queues*
Defined by
- message oriented architecture
- Persistence (or durability until comsuption)
- queuing
- Routing: point-to-point / publish-and-subscribe
- No processing/transformation of message/data

*Implementations and standards*
- AMQP
@[https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol]
  - Open standard network protocol
  - Often compared to JMS:
    - JMS defines API interfaces, AMQP defines network protocol
    - JMS has no requirement for how messages are formed and
      transmitted and thus every JMS broker can implement the 
      messages in a different (incompatible) format.
      AMQP publishes its specifications in a downloadable XML format,
      allowing library maintainers to generate APIs driven by
      the specs while also automating construction of algorithms to
      marshal and demarshal messages.
  - brokers implementations supporting it: 
    RabbitMQ, ActiveMQ, Qpid, Solace, ...
    @[https://www.amqp.org/about/examples]
    - Apache Qpid (TODO)
    @[http://qpid.apache.org/]
    - INETCO's AMQP protocol analyzer
    @[http://www.inetco.com/resource-library/technology-amqp/]
    - JORAM  JMS + AMPQ
    @[http://joram.ow2.org/] 100% pure Java implementation of JMS
    - Kaazing's AMQP*Web Client*
    @[http://kaazing.net/index.html]
    - Azure Service Bus+ AMPQ
- What's wrong with AMQP?
@[https://news.ycombinator.com/item?id=1657574]
- @[http://www.windowsazure.com/en-us/develop/net/how-to-guides/service-bus-amqp-overview/]
- JBoss A-MQ, built from @[http://qpid.apache.org/]
@[http://www.redhat.com/en/technologies/jboss-middleware/amq]
- IBM MQLight
@[https://developer.ibm.com/messaging/mq-light/]
- StormMQ
@[http://stormmq.com/]
  a cloud hosted messaging service based on AMQP
- RabbitMQ (by VMware Inc)
@[http://www.rabbitmq.com/];
  also supported by SpringSource
...


  <li>Java JMS</li>


</pre>
</td>
<td>
<pre zoom>
<span xsmall>Message Brokers</span>
- Routing
- (De-)Multiplexing of messages from/into multiple messages to different recipients
- Durability
- Transformation (translation of message between formats)
- "things usually get blurry - many solutions are both (message queue and message
  broker) - for example RabbitMQ or QDB.  Samples for message queues are
  Gearman, IronMQ, JMS, SQS or MSMQ."
  Message broker examples are, Qpid, Open AMQ or ActiveMQ.
- Kafka can also be used as message broker but is not its main intention
</pre>
</td>
<td>
<pre zoom>
<span xsmall>Enterprise Service Bus (ESB)</span>
- Can be defined by next feautes:
  - Monitoring of services/messages passed between them
  - wire Protocol bridge between HTTP, AMQP, SOAP, gRPC, CVS in Filesystem,...
  - Scheduling, mapping, QoS management, error handling, ..
  - Data transformation
  - Data pipelines
  - Mule, JBoss Fuse (Camel + "etc..."), BizTalk, Apache ServiceMix, ...
REF: https://en.wikipedia.org/wiki/Enterprise_service_bus#/media/File:ESB_Component_Hive.png
    ^   Special App. Services
    |
E   |   Process Automation                 BPEL, Workflow
n   |
t   |   Application Adapters               RFC, BABI, IDoc, XML-RPC, ...
e m |
r e |   Application Data Consolidation     MDM, OSCo, ...
p s |
r s |   Application Data Mapping           EDI, B2B
i a |   _______________________________
s g |   Business Application Monitoring
e e |   _______________________________
    |   Traffic Monitoring Cockpit
S c |
e h |   Special Message Services           Ex. Test Tools
r a |
v n |   Web Services                       WSDL, REST, CGI
i n |
c e |   Protocol Conversion                XML, XSL, DCOM, CORBA
e l |
    |   Message Consolidation              N.N (data locks, multi-submit,...)
B   |
u   |   Message Routing                    XI, WBI, BIZTALK, Seeburger
s   |
    |   Message Service                    MQ Series, MSMQ, ...
</pre>
</td>
<td colsep></td>
<td title>
    Distributed <br/>
    Storage.
</td>
<td>
<pre zoom>
<span xsmall>NFS</span>
<span xsmall>considered</span>
<span xsmall>harmful</span>
@[http://www.time-travellers.org/shane/papers/NFS_considered_harmful.html]
</pre>
<pre zoom>
<span xsmall>cluster-FS</span>
<span xsmall>comparative</span>
@[http://zgp.org/linux-tists/20040101205016.E5998@shaitan.lightconsulting.com.html]
</pre>
</td>
<td>
<pre zoom>
<span xsmall>Ceph</span>
<span xsmall>Up-to-exabytes</span>
@[http://ceph.com/ceph-storage/]
Ceph’s RADOS provides you with extraordinary data storage  scalability—
thousands of client hosts or KVMs accessing petabytes to
exabytes of data. Each one of your applications can use the object, block or
file system interfaces to the same RADOS cluster simultaneously, which means
your Ceph storage system serves as a  flexible foundation for all of your
data storage needs. You can use Ceph for free, and deploy it on economical
commodity hardware. Ceph is a  better way to store data.

By decoupling the namespace from the underlying hardware, object-based
storage systems enable you to build much larger storage clusters. You
can scale out object-based storage systems using economical commodity hardware
, and you can replace hardware easily when it malfunctions or fails.

Ceph’s CRUSH algorithm liberates storage clusters from the scalability and
performance limitations imposed by centralized data table mapping. It
replicates and re-balance data within the cluster dynamically—elminating this
tedious task for administrators, while delivering high-performance and
infinite scalability.

See more at: http://ceph.com/ceph-storage/#sthash.KNp2tGf5.dpuf
</pre>
</td>
<td>
<pre zoom>
<span TODO xsmall>GlusterFS</span>
</pre>
</td>
<td>
<pre zoom>
<span xsmall>Tachyon</span>
<span xsmall>memory-centric</span>
<span xsmall> distributed FS</span>
@[http://tachyon-project.org/index.html]
- memory-centric distributed file system enabling reliable file sharing at memory-speed
across cluster frameworks, such as Spark and MapReduce. It achieves high performance by leveraging
lineage information and using memory aggressively. Tachyon caches working set files in memory,
thereby avoiding going to disk to load datasets that are frequently read. This enables different
jobs/queries and frameworks to access cached files at memory speed.

Tachyon is Hadoop compatible. Existing Spark and MapReduce programs can run on top of it without
any code change. The project is open source (Apache License 2.0) and is deployed at multiple companies.
It has more than 40 contributors from over 15 institutions, including Yahoo, Intel, and Redhat.

The project is the storage layer of the Berkeley Data Analytics Stack (BDAS) and also part of the
Fedora distribution.
</pre>
</td>
<td>
<pre bgorange zoom>
<span xsmall>S3QL</span>
<span xsmall>FUSE FS</span>
<span xsmall>(Amazon S2, GCS, </span>
<span xsmall>OpenStack,...)</span>
- FUSE-based file system 
- backed by several cloud storages:
  - such as Amazon S2, Google Cloud Storage, Rackspace CloudFiles, or OpenStack
@[http://xmodulo.com/2014/09/create-cloud-based-encrypted-file-system-linux.html]
- S3QL is one of the most popular open-source cloud-based file systems.
- full featured file system:
  - unlimited capacity
  - up to 2TB file sizes
  - compression
  - UNIX attributes
  - encryption
  - snapshots with copy-on-write
  - immutable trees
  - de-duplication
  - hardlink/symlink support, etc.
- Any bytes written to an S3QL file system are compressed/encrypted
  locally before being transmitted to cloud backend.
- When you attempt to read contents stored in an S3QL file system, the
  corresponding objects are downloaded from cloud (if not in the local
  cache), and decrypted/uncompressed on the fly.
</pre>
</td>
</tr>
</table>
<br/>
<hr/>
<table>
<tr>
<td title>
    Example<br/>
    Architectures
</td>
<td>
<pre zoom>
<span xsmall>observability: </span>
<span xsmall>      loging</span>
<span xsmall>+ monitoring</span>
<span xsmall>+    tracing</span>
Ex:*File Integrity Monitoring at scale: (RSA Conf)*
@[https://www.rsaconference.com/writable/presentations/file_upload/csv-r14-fim-and-system-call-auditing-at-scale-in-a-large-container-deployment.pdf]
Auditing log to gain insights at scale:

                         ┌─→ Pagerduty
            ┌─→ Grafana ─┼─→ Email
   Elastic  │            └─→ Slack
   Search  ─┼─→ Kibana
            │
            └─→ Pre─processing ─→ TensorFlow

Alt1:
  User   │ go-audit-                          User space
  land   │ container                             app
  ───────├─────  Netlink ───── Syscall iface ───────────
  Kernel │        socket           ^
         │          ^              |
                    └─  Kauditd ───┘
</pre>
</td>
<td>
<pre zoom>
<span xsmall>https://zipkin.io/</span>
</pre>
</td>
<td title>
    Continuous<br/>
    Integration
</td>
<td>
<pre zoom>
<span TODO xsmall>Jenkins</span>
@[https://jenkins.io/doc/]
@[https://jenkins.io/solutions/pipeline/"


https://thenewstack.io/ibm-openstack-engineer-urges-cncf-consider-augmenting-jenkins-zuul/
</pre>

<pre zoom>
<span xsmall>Zuul</span>
@[https://zuul-ci.org/]
- Use the same Ansible playbooks to 
  deploy your system and run your tests.


REF:@[https://www.mediawiki.org/wiki/Continuous_integration/Zuul]
"""...Zuul is a python daemon which acts as a gateway between
Gerrit and Jenkins. It listens to Gerrit stream-events feed and
trigger jobs function registered by Jenkins using the Jenkins Gearman
plugin. The jobs triggering specification is written in YAML and
hosted in the git repository integration/config.git as /zuul/layout.yaml """

</pre>
</td>
<td>
<pre zoom>
<span TODO xsmall>Kayenta</span>
<span TODO xsmall>Canary</span>
<span TODO xsmall>Testing</span>
@[https://github.com/spinnaker/kayenta]
- Kayenta platform:  Automated Canary Analysis (ACA)
</pre>
</td>
<td>
<pre TODO zoom>
<span xsmall>SonarQube</span>
<span xsmall>Apply quality</span>
<span xsmall>metrics to</span>
<span xsmall>source-code</span>
</pre>
</td>
<td>
<pre TODO zoom>
<span xsmall>Selenium</span>
<span xsmall>Browser test</span>
<span xsmall>automation</span>

</pre>
</td>
</tr>
</table>
<hr/>
Non-classified<br/>
<pre TODO zoom>
<span xsmall>API Management</span>
https://www.datamation.com/applications/top-api-management-tools.html
</pre>
<pre TODO zoom>
<span xsmall>Behaviour</span>
<span xsmall>Driven</span>
<span xsmall>Development</span>
<span xsmall>(BDD)</span>
- Cucumber, ...
@[https://cucumber.io/docs/guides/10-minute-tutorial/]
</pre>

<pre zoom>
<span xsmall></span>
https://opensource.com/article/18/9/open-source-log-aggregation-tools
- ELK: 
  - Elasticsearch, Logstash, and Kibana
  - developed and maintained by Elastic.
  - Elasticsearch:
    - essentially a NoSQL, Lucene search engine implementation.
  - Logstash: log pipeline (ingest/transform/load it into a store 
              like Elasticsearch)
    (It is common to replace Logstash with Fluentd)
  - Kibana: visualization layer on top of Elasticsearch.
  - In productiona few other pieces might be included like:
    - Kafka, Redis, NGINX, ....

- Graylog
  - gaining popularity in the Go community with
    the introduction of the Graylog Collector Sidecar
    written in Go.
  - ... it still lags far behind the ELK stack.
  - Composed  under the hood of:
    - Elasticsearch
    - MongoDB
    - Graylog Server.
  - comes with alerting built into the open source version
    and streaming, message rewriting, geolocation, ....

- Fluentd
  - *It is not a log aggregation system.*
  - developed at Treasure Data, 
  - Adopted by the CNCF as Incubating project.
  - Recommended by AWS and Google Cloud.
  - Common replacement for Logstash 
    - It acts as a local aggregator to collect
      all node logs and send them off to central 
      storage systems.
  - 500+ plugins for  quick and easy integrations with
    different data input/outputs.
  - common choice in Kubernetes environments due to:
    - low memory requirements (tens of megabytes)
      (each pod has a Fluentd sidecar)
    - high throughput.
</pre>
<pre zoom>
<span xsmall></span>
*Solr*
@[http://lucene.apache.org/solr/]
- blazing-fast, search platform built on Apache Lucene
</pre>
<pre zoom>
<span xsmall>LodDevice</span>
<span xsmall>(Facebook)</span>
@[https://www.infoq.com/news/2018/09/logdevice-distributed-logstorage]

- LogDevice has been compared with other log storage systems
  like Apache BookKeeper and Apache Kafka. 
- The primary difference with Kafka 
(@[https://news.ycombinator.com/item?id=17975328] 
  seems to be the decoupling of computation and storage

- Underlying storage based on RocksDB, a key value store
  also open sourced by Facebook
</pre>


<pre zoom>
<span xsmall>Loggin@Coinbase</span>
https://www.infoq.com/news/2019/02/metrics-logging-coinbase
</pre>

<pre zoom>
<span xsmall>Loki</span>
https://grafana.com/loki
- logging backend, optimized for Prometheus and Kubernetes
- optimized to search, visualize and explore your logs natively in Grafana.
</pre>
<br/>

<pre zoom>
<span xsmall>FreeIPA</span>
https://www.reddit.com/r/linuxadmin/comments/apbjtc/freeipa_groups_and_linux_usernames/?utm_source=reddit-android
</pre>

<pre zoom>
<span xsmall>Nexenta</span>
@[https://nexenta.com/]
- Software-Defined Storage Product Family.
</pre>

<pre zoom>
<span xsmall>Data Lake</span>
https://en.wikipedia.org/wiki/Data_lake
</pre>

<pre zoom>
<span xsmall>Event Based</span>
<span xsmall>Architecture</span>
@[https://www.infoq.com/news/2017/11/jonas-reactive-summit-keynote]

Jonas Boner ... talked about event driven services (EDA) and 
event stream processing (ESP)... on distributed systems.

... background on EDA evolution over time:
- Tuxedo, Terracotta and Staged Event Driven Architecture (SEDA).

*events represent facts*
- Events drive autonomy in the system and help to reduce risk.
- increase loose coupling, scalability, resilience, and traceability.
- ... basically inverts the control flow in the system 
- ... focus on the behavior of systems as opposed to the
  structure of systems.

- TIP for developers:
 *Do not focus on just the "things" in the system*
 *(Domain Objects), but rather focus on what happens (Events)*
- Promise Theory:
  - proposed by Mark Burgess
  - use events to define the Bounded Context through
    the lense of promises.

quoting Greg Young:
"""Modeling events forces you to have a temporal focus on what’s going on in the 
system. Time becomes a crucial factor of the system."""
""" Event Logging allows us to model time by treating event as a snapshot in time 
   and event log as our full history. It also allows for time travel in the 
   sense that we can replay the log for historic debugging as well as for 
auditing and traceability. We can replay it on system failures and for data replication."""

Boner discussed the following patterns for event driven architecture:
- Event Loop
- Event Stream
- Event Sourcing
- CQRS for temporal decoupling
- Event Stream Processing

Event stream processing technologies like Apache Flink, Spark Streaming, 
Kafka Streams, Apache Gearpump and Apache Beam can be used to implement these 
design patterns.
</pre>
<pre zoom>
<span xsmall>Zookeeper</span>
<span xsmall>Internals</span>
https://zookeeper.apache.org/doc/r3.2.2/zookeeperInternals.html#sc_guaranteesPropertiesDefinitions
</pre>

<pre zoom>
<span xsmall>Zookeeper</span>
<span xsmall>vs etcd3</span>
https://loneidealist.wordpress.com/2017/07/12/apache-zookeeper-vs-etcd3/
</pre>

<pre zoom>
<span xsmall>Ambari</span>
<span xsmall>Hadoop cluster</span>
<span xsmall>provisioning</span>
https://projects.apache.org/project.html?ambari
Apache Ambari makes Hadoop cluster provisioning, managing, and monitoring dead simple.
</pre>

</body>
</html>

<!--
<td>
__________________________
https://www.infoq.com/presentations/graph-query-distributed-execution/?itm_source=infoq&itm_medium=popular_widget&itm_campaign=popular_content_list&itm_content=
Life of a Distributed Graph Database Query
__________________
https://projects.apache.org/project.html?hive
https://www.infoq.com/news/2019/04/hivemq-extension-kafka-mqtt/
________________________
https://docs.confluent.io/current/schema-registry/index.html
___________________________________
https://www.infoq.com/news/2019/07/nats-event-messaging-release/
-->

